---
title: "Merge eye-tracking data"
format: html
---

```{r}
library(tidyverse)
library(here)
library(assertthat)
```

Download data locally

```{r}

mb2_data <- osfr::osf_retrieve_node("p3txj")
files <- osfr::osf_ls_files(mb2_data)

PROCESSED_DATA_DIR = "processed_xy_data"

dir.create(here(PROCESSED_DATA_DIR), showWarnings = FALSE)

files |>
  mutate(idx = 1:n()) %>%
  base::split(.$idx) |>
  map(function(f) {
    print(f)
    osfr::osf_download(f, path = here(PROCESSED_DATA_DIR))
  })
```

Load local data

```{r}
cols <- c("lab_id", "participant_id", "media_name", 
          "x", "y", "t", "pupil_left", "pupil_right")

local_files <- dir(here("processed_xy_data"))

xy <- local_files |>
  map_df(function(x) {
    print(x)
    d <- read_csv(here("processed_xy_data",x),
                  col_types = list(
                    lab_id = col_character(),
                    participant_id = col_character(),
                    media_name = col_character(),
                    x = col_double(),
                    y = col_double(),
                    t = col_double(),
                    pupil_left = col_double(),
                    pupil_right = col_double()
                  ))
    
    # check that all columns are in the col list
    assert_that(all(cols %in% names(d)))
    
    # check that no extra cols
    assert_that(all(names(d) %in% cols))
    
    return(d)
  })
```
## Processing tasks that we will do centrally

Reconcile media names - Code done, renamings for new datasets still pending
Create trial numbers - Done
Standardize media names - Code done, renamings for new datasets still pending
Zero times within trials - Martin
Resample times - Marin
Clip XY outside of screen coordinates - Adrian
Create/process AOIs - Adrian
Standardize pupil sizes - ?


```{r standardize and validate data}

vec_renaming <- read.csv(here('metadata','media_renaming.csv')) %>%
  {setNames(as.character(.$target), .$original)}
media_deletion <- readLines(here('metadata','media_names_to_remove.txt'))
media_names_valid <- readLines(here('metadata','media_names_validate.txt'))

data <- xy |>
  mutate(media_name = tools::file_path_sans_ext(media_name)) %>%
  filter(!is.na(media_name) & !(media_name %in% media_deletion)) %>% 
  mutate(media_name = ifelse(media_name %in% names(vec_renaming), vec_renaming[as.character(media_name)], media_name)) %>% 
  group_by(lab_id, participant_id) %>% 
  mutate(media_index = cumsum(c(1, na.omit(media_name != lag(media_name))))) %>% 
  ungroup()


# Validate that the participant ids in the data line up with the ids from the demographic files
# TODO (Adrian)
  
# Validate media names
invalid_names <- setdiff(unique(data$media_name), media_names_valid)
# TODO check for new datasets, update the renaming/deletion file accordingly


# Extract media version information from media version string
data <- data %>% mutate(media_version = ifelse(grepl('_new', media_name),0,1),
         media_name = gsub("_new", "", media_name))


# Add trial numbers to the data
trial_orders <- data %>% filter(media_name %in% media_names_valid) %>%
  group_by(lab_id, participant_id) %>%
  mutate(trial_num = cumsum(c(1, na.omit(media_name != lag(media_name))))) %>%
  distinct(lab_id, participant_id, media_name, trial_num)

data <- data %>% left_join(trial_orders, by = join_by(lab_id, participant_id, media_name))

# Validate trial order
# TODO: get ground truth and demographic information in here for comparison (Adrian)

rm(trial_orders)

# Validate that the scale of timesteps is correct
# TODO once martin has taken care of the timepoints (Martin)
    # Mikes previous code: #assert_that(mean(diff(d$t),na.rm=TRUE) > 1 & mean(diff(d$t), na.rm=TRUE) < 100)
    
```



