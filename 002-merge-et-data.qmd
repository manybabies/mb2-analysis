---
title: "Merge eye-tracking data"
format: html
---

```{r}
library(tidyverse)
library(here)
library(assertthat)
FIRST_TIME = FALSE
```

Download data locally

```{r download, eval= FIRST_TIME}

mb2_data <- osfr::osf_retrieve_node("p3txj")
files <- osfr::osf_ls_files(mb2_data)

PROCESSED_DATA_DIR = "processed_xy_data"

dir.create(here(PROCESSED_DATA_DIR), showWarnings = FALSE)

files |>
  mutate(idx = 1:n()) %>%
  base::split(.$idx) |>
  map(function(f) {
    print(f)
    osfr::osf_download(f, path = here(PROCESSED_DATA_DIR))
  })
```

Load local data

```{r}
cols <- c("lab_id", "participant_id", "media_name", 
          "x", "y", "t", "pupil_left", "pupil_right")

local_files <- dir(here("processed_xy_data"))

xy <- local_files |>
  map_df(function(x) {
    print(x)
    d <- read_csv(here("processed_xy_data",x),
                  col_types = list(
                    lab_id = col_character(),
                    participant_id = col_character(),
                    media_name = col_character(),
                    x = col_double(),
                    y = col_double(),
                    t = col_double(),
                    pupil_left = col_double(),
                    pupil_right = col_double()
                  ))
    
    # check that all columns are in the col list
    assert_that(all(cols %in% names(d)))
    
    # check that no extra cols
    assert_that(all(names(d) %in% cols))
    
    d$age_cohort <- case_when(grepl('_adults_', x) ~ 'adults',
                              grepl('_toddlers_', x) ~ 'toddlers',
                              T ~ NA)
    
    return(d)
  })
```
## Processing tasks that we will do centrally

Reconcile media names - Code done, renamings for new datasets still pending
Create trial numbers - done
Standardize media names - Code done, renamings for new datasets still pending
Zero times within trials - done
Resample times - done
Clip XY outside of screen coordinates - done
Flip coordinate origin - Done
Create/process AOIs - Done

Standardize pupil sizes



```{r standardize and validate data}

vec_renaming <- read_csv(here('helper','metadata', 'media_renaming.csv')) %>%
  {setNames(as.character(.$target), .$original)}
media_deletion <- readLines(here('helper','metadata', 'media_names_to_remove.txt'))
media_names_valid <- readLines(here('helper','metadata', 'media_names_validate.txt'))

data <- xy |>
  mutate(media_name = tools::file_path_sans_ext(media_name)) %>%
  filter(!is.na(media_name) & !(media_name %in% media_deletion)) %>% 
  mutate(media_name = ifelse(media_name %in% names(vec_renaming), vec_renaming[as.character(media_name)], media_name)) %>% 
  group_by(lab_id, participant_id) %>% 
  mutate(event_num = cumsum(c(1, na.omit(media_name != lag(media_name))))) %>% 
  ungroup()

  
# Validate media names
invalid_names <- setdiff(unique(data$media_name), media_names_valid)
# TODO check for new datasets, update the renaming/deletion file accordingly


data <- data %>% 
  left_join(
    read.csv(here('helper', 'metadata', 'trial_details.csv')) %>%
      mutate(media_name = tools::file_path_sans_ext(trial_file_name)) %>% 
      rename(point_of_disambiguation = point_of_disambig_ms), 
    by=join_by(media_name))

# Extract media version information from media version string
data <- data %>% mutate(
  media_version = ifelse(grepl('_new', media_name),0,1),
  media_name = gsub("_new", "", media_name))

# Add trial numbers to the data
trial_orders <- data %>% 
  filter(media_name %in% media_names_valid) %>%
  group_by(lab_id, participant_id) %>%
  mutate(trial_num = cumsum(c(1, na.omit(media_name != lag(media_name))))) %>%
  distinct(lab_id, participant_id, media_name, trial_num)

data <- data %>% left_join(trial_orders, by = join_by(lab_id, participant_id, media_name))

# create a table containing some demographic data from both toddlers and adults to perform integrity checks
combined_demo <- adult_demo %>%
  select(labid, participant_id, test_order, pilot) %>% 
  bind_rows(
    toddler_demo %>%
      select(labid, participant_id, test_order, pilot)
    )

# Validate that the (lab specific) participant ids in the data line up with the ids from the (lab specific) demographic files
# This also triggers on mismatches in labid namings
id_orphans <- trial_orders %>% 
  distinct(lab_id, participant_id) %>% 
  mutate(xy_exists = T) %>%
  full_join(combined_demo, by=c('lab_id' = 'labid', 'participant_id')) %>%
  # pilot and teest order are used as a stand in to check if demographic data for this participant exists
  mutate(demo_exists = !is.na(pilot) | !is.na(test_order)) %>%
  select(-c('test_order','pilot')) %>% 
  filter(is.na(xy_exists) | !demo_exists)

#assert_that(nrow(id_orphans) == 0)
# TODO Have a close look at this once all of the data was collected

# Validate trial orders
trial_orders_wide <- trial_orders %>%
  pivot_wider(id_cols = c('lab_id', 'participant_id'), values_from=media_name, names_from=trial_num, names_prefix='trial_')

trial_orders_design <- read.csv(here('helper', 'metadata', 'trial_order.csv')) %>% 
  left_join(read.csv(here('helper','metadata', 'fam_order.csv')), by=join_by(fam_order))

invalid_trial_orders <- trial_orders_wide %>% 
  anti_join(trial_orders_design, by=paste0('trial_',1:6))
#assert_that(nrow(invalid_trial_orders) == 0)

trial_order_mismatches <- combined_demo %>%
  select(labid, participant_id, test_order) %>% 
  inner_join(trial_orders_wide %>% 
               inner_join(trial_orders_design, by=paste0('trial_',1:6)) # determine seen trials
    , by=c('labid' = 'lab_id', 'participant_id')) %>% 
  filter(test_order != trial_order)

#assert_that(nrow(trial_order_mismatches) == 0)
#rm(trial_orders, trial_orders_design)
```

Rezero and resample times


```{r}
source(here("helper","resampling_helper.R"))

#filter timepoints with NAs
data <- data %>%
  filter(!is.na(t))

#filter data without associated events
data <- data %>%
  filter(!is.na(event_num))

#rezero time
data_rezeroed <- data %>%
  rezero_times() # right now, rezeroing on event_num (NOT trial_num)


#"normalize" time according to a point of disambiguation
# Martin: normalizing isn't really relevant here (I don't think) but preserving for now in case we want to include any time normalization
# Adrian: TODO: I think this differs based on trial? - discuss later
data_normalized <- data_rezeroed %>%
  mutate(point_of_disambiguation = replace_na(point_of_disambiguation, 0)) %>% # TODO: check if this hits trial on accident
  normalize_times()

#Validate that time is provided in milliseconds
#assert_that(mean(diff(data_normalized$t_norm),na.rm=TRUE) > 1 & mean(diff(data_normalized$t_norm), na.rm=TRUE) < 100)
# TODO this still fails, have a closer look
  
# resample time to 40 Hz
data_resampled <- data_normalized %>%
  resample_times()
# TODO make this function agnostic to additional columns

```

```{r}

# add information about screen size and eyetracker coordinate origin
dataset_specs <- read.csv(here('helper', 'metadata', 'dataset_sheet.csv')) %>%
  select(data_id, screen_dimensions, point_zero) %>%
  separate(data_id, c("lab_id", "age_cohort"), sep="_") %>% 
  separate(screen_dimensions, c("screen_width", "screen_height"), sep=" x ") %>% 
  mutate(screen_width = as.numeric(str_trim(screen_width)),
         screen_height = as.numeric(str_trim(screen_height)))

# TODO: One lab is missing the zero coordinate
allowed_origins <- c('upper left','lower left','center')
invalid_origins <- dataset_specs %>% filter(!(point_zero %in% allowed_origins))

data_resampled_specs <- data_resampled %>% 
  left_join(dataset_specs, by=join_by(lab_id, age_cohort)) %>% 
  filter(point_zero %in% allowed_origins)


# Flip Coordinate Origin # TODO
data_corrected_origin <- data_resampled_specs  %>% 
    mutate(
      y = case_when(
        point_zero == 'upper_left' ~ screen_height - y,
        point_zero == 'center' ~ y + screen_height/2, # TODO: this assumes that up and right are "+" for the eyetracker - check this!
        T ~ x),
      x = case_when(
        point_zero == 'center' ~ x + screen_width/2, # TODO: this assumes that up and right are "+" for the eyetracker - check this!
        T ~ x),
    )

# trim xy that land outside of the screen
data_trimmed <- data_corrected_origin  %>% 
    mutate(x = ifelse(x >= 0 & x <= screen_width, x, NA),
           y = ifelse(y >= 0 & y <= screen_height, y, NA))

# add aois
source(here('helper', 'aoi_helper.R'))
data_with_aois <- data_trimmed %>%
  rename(target_side = target) %>% 
  create_aoi_timepoints()


# TODO: Visualize this data to double check?

```


Issues to deal with:

- Pipeline is glued together, but needs sanity checking/visualization to see if it is working correctly (it probably isn't right now)

- Repo needs cleanup
  - the following import scripts are outdated (folders also contain data) - people did not push their import scripts?
    - babylabTrento
    - gaugGÃ¶ttingen
    - jmuCDL
    - lmuMunich
    - socialcogUmiami
  - all R Code/ metadata files currently used reside in in 001 and 002 as well as the top level of 'helper' (what is up with 'metadata' and 'helper/unused'?)
  
- osf download still fails (?), having some trouble pulling the current version of the data from OSF 

- point of disambiguation usage?

- more integrity checking is needed in between operations to validate that data is not lost on accident(need to have a look at every step once more data is here)

- some timepoints are not being read in correctly (e.g. in careylabHarvard_adults_xy_timepoints), apparently because these are too large (10^12) - Martin: I think I fixed this now by removing invariant leading digits (on OSF)
- some residual import/ processing issues with some datasets
-- careylabHarvard_adults_xy_timepoints has some participant ids under lab_id - Martin: this is now fixed on OSF
-resampling pupil size??
- really need to be cautious about the definition of trials/ events/ etc. - currently fragile 
- passing the final/correct column names to resample_xy_trial - we could redesign the function to make it agnostic?

- How to standardize pupil sizes?

- cleanup the pipline (a lot of intermediat steps can be combined to make this more compact)



