---
title: "Merge eye-tracking data"
format: html
---

```{r}
library(tidyverse)
library(here)
library(assertthat)
FIRST_TIME = FALSE
```

Download data locally

```{r download, eval= FIRST_TIME}

mb2_data <- osfr::osf_retrieve_node("p3txj")
files <- osfr::osf_ls_files(mb2_data)

PROCESSED_DATA_DIR = "processed_xy_data"

dir.create(here(PROCESSED_DATA_DIR), showWarnings = FALSE)

files |>
  mutate(idx = 1:n()) %>%
  base::split(.$idx) |>
  map(function(f) {
    print(f)
    osfr::osf_download(f, path = here(PROCESSED_DATA_DIR))
  })
```

Load local data

```{r}
cols <- c("lab_id", "participant_id", "media_name", 
          "x", "y", "t", "pupil_left", "pupil_right")

local_files <- dir(here("processed_xy_data"))

xy <- local_files |>
  map_df(function(x) {
    print(x)
    d <- read_csv(here("processed_xy_data",x),
                  col_types = list(
                    lab_id = col_character(),
                    participant_id = col_character(),
                    media_name = col_character(),
                    x = col_double(),
                    y = col_double(),
                    t = col_double(),
                    pupil_left = col_double(),
                    pupil_right = col_double()
                  ))
    
    # check that all columns are in the col list
    assert_that(all(cols %in% names(d)))
    
    # check that no extra cols
    assert_that(all(names(d) %in% cols))
    
    d$age_cohort <- case_when(grepl('_adults_', x) ~ 'adults',
                              grepl('_toddlers_', x) ~ 'toddlers',
                              T ~ NA)
    
    return(d)
  })
```


Begin standardizing data.


```{r standardize and validate data}

vec_renaming <- read_csv(here('helper','metadata', 'media_renaming.csv')) %>%
  {setNames(as.character(.$target), .$original)}
media_deletion <- readLines(here('helper','metadata', 'media_names_to_remove.txt'))
media_names_valid <- readLines(here('helper','metadata', 'media_names_validate.txt'))

data <- xy |>
  mutate(media_name = tools::file_path_sans_ext(media_name)) %>%
  filter(!is.na(media_name) & !(media_name %in% media_deletion)) %>% 
  mutate(media_name = ifelse(media_name %in% names(vec_renaming), vec_renaming[as.character(media_name)], media_name)) %>% 
  group_by(lab_id, participant_id) %>% 
  mutate(event_num = cumsum(c(1, na.omit(media_name != lag(media_name))))) %>% 
  ungroup()

  
# Validate media names
invalid_names <- setdiff(unique(data$media_name), media_names_valid)
# TODO check for new datasets, update the renaming/deletion file accordingly
```


TODO: LOCAL SAVING
