---
title: "Add metadata and validate"
format: html
---

Load data from the cached datafile. 

```{r}
load(here("processed_data", "002-merged-et-data.Rds"))
```


## Processing tasks that we will do centrally

Reconcile media names - Code done, renamings for new datasets still pending
Create trial numbers - done
Standardize media names - Code done, renamings for new datasets still pending
Zero times within trials - done
Resample times - done
Clip XY outside of screen coordinates - done
Flip coordinate origin - Done
Create/process AOIs - Done

Standardize pupil sizes


```{r}

# TODO these labs are currently broken - investigate this
# (lab_id, participant_id, media_name) does not uniquely identify a trial_number
# (duplicate participant namings?)
data <- data %>% 
  filter(!(lab_id %in% c(
  'babylabNijmegen', # various participants affected
  'babylabAmsterdam' # UVA_127
  )))

data %>% group_by(lab_id, participant_id, media_name)

data <- data %>%
  # add point of disambiguation and target aoi to the data
  left_join(
    read.csv(here('metadata', 'trial_details.csv')) %>%
      mutate(media_name = tools::file_path_sans_ext(trial_file_name)) %>%
      rename(point_of_disambiguation = point_of_disambig_ms), 
    by=join_by(media_name)) %>%
  # Extract media version information from media version string
  mutate( 
    media_version = ifelse(grepl('_new', media_name),0,1),
    media_name = gsub("_new", "", media_name)
    )


# Add trial numbers to the data
trial_orders <- data %>% 
  filter(media_name != 'star_calib') %>% # remove calibration from numbering
  group_by(lab_id, participant_id) %>%
  mutate(trial_num = cumsum(c(1, na.omit(media_name != lag(media_name))))) %>%
  distinct(lab_id, participant_id, media_name, trial_num)

# validate trial_orders before joining them to the data
media_name_collisions <- trial_orders %>% 
  group_by(lab_id, participant_id, media_name) %>% 
  filter(n() > 1)

data <- data %>% left_join(trial_orders, by = join_by(lab_id, participant_id, media_name))

# TODO: Save the adult/toddler demographic data in 001 and read it into this script
# create a table containing some demographic data from both toddlers and adults to perform integrity checks
combined_demo <- adult_demo %>%
  select(labid, participant_id, test_order, pilot) %>% 
  bind_rows(
    toddler_demo %>%
      select(labid, participant_id, test_order, pilot)
    )

# Validate that the (lab specific) participant ids in the data line up with the ids from the (lab specific) demographic files
# This also triggers on mismatches in labid namings
id_orphans <- trial_orders %>% 
  distinct(lab_id, participant_id) %>% 
  mutate(xy_exists = T) %>%
  full_join(combined_demo, by=c('lab_id' = 'labid', 'participant_id')) %>%
  # pilot and test order are used as a stand in to check if demographic data for this participant exists
  mutate(demo_exists = !is.na(pilot) | !is.na(test_order)) %>%
  select(-c('test_order','pilot')) %>% 
  filter(is.na(xy_exists) | !demo_exists)

#assert_that(nrow(id_orphans) == 0)
# TODO Have a close look at this once all of the data was collected

# Validate trial orders
trial_orders_wide <- trial_orders %>%
  pivot_wider(id_cols = c('lab_id', 'participant_id'), values_from=media_name, names_from=trial_num, names_prefix='trial_')

trial_orders_design <- read.csv(here('metadata', 'trial_order.csv')) %>% 
  left_join(read.csv(here('metadata', 'fam_order.csv')), by=join_by(fam_order))

invalid_trial_orders <- trial_orders_wide %>% 
  anti_join(trial_orders_design, by=paste0('trial_',1:6))
#assert_that(nrow(invalid_trial_orders) == 0)

trial_order_mismatches <- combined_demo %>%
  select(labid, participant_id, test_order) %>% 
  inner_join(trial_orders_wide %>% 
               inner_join(trial_orders_design, by=paste0('trial_',1:6)) # determine seen trials
    , by=c('labid' = 'lab_id', 'participant_id')) %>% 
  filter(test_order != trial_order)

#assert_that(nrow(trial_order_mismatches) == 0)
#rm(trial_orders, trial_orders_design)
```



Issues to deal with:

- Pipeline is glued together, but needs sanity checking/visualization to see if it is working correctly (it probably isn't right now)

- Repo needs cleanup
  - the following import scripts are outdated (folders also contain data) - people did not push their import scripts?
    - babylabTrento
    - gaugGÃ¶ttingen
    - jmuCDL
    - lmuMunich
    - socialcogUmiami
  - all R Code/ metadata files currently used reside in in 001 and 002 as well as the top level of 'helper' (what is up with 'metadata' and 'helper/unused'?)
  
- osf download still fails (?), having some trouble pulling the current version of the data from OSF 

- point of disambiguation usage?

- more integrity checking is needed in between operations to validate that data is not lost on accident(need to have a look at every step once more data is here)

- some timepoints are not being read in correctly (e.g. in careylabHarvard_adults_xy_timepoints), apparently because these are too large (10^12) - Martin: I think I fixed this now by removing invariant leading digits (on OSF)
- some residual import/ processing issues with some datasets
-- careylabHarvard_adults_xy_timepoints has some participant ids under lab_id - Martin: this is now fixed on OSF
-resampling pupil size??
- really need to be cautious about the definition of trials/ events/ etc. - currently fragile 
- passing the final/correct column names to resample_xy_trial - we could redesign the function to make it agnostic?

- How to standardize pupil sizes?

- cleanup the pipline (a lot of intermediat steps can be combined to make this more compact)



