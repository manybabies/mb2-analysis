---
title: "AOI-based analysis"
format: html
---

```{r}
library(tidyverse)
library(here)
library(assertthat)
library(ggbeeswarm)
library(gghalves)
library(cowplot)
library(patchwork)
library(brms)
library(tidybayes)
library(knitr)
library(corrr)
library(ggpubr)
library(bayesplot)
library(broom.mixed)
library(metafor)

#FIT BAYESIAN MODELS
# parameter for controlling whether to fit the Bayesian models (or load from disk)
FIT_BAYES_MODELS = TRUE
# parameter for controlling whether to compute Bayes factors (ocomputationally expensive)
COMPUTE_BAYES_FACTORS = TRUE

source(here("helper", "ensure_repo_structure.R"))
plot_path <- here("plots")
paper_path <- here("paper")

load(here(INTERMEDIATE_FOLDER, INTERMEDIATE_006))
```

# Preliminaries

Inspecting the structure of the unique trials in the data. Check to see if we have the expected number of familiarization (4 trials) and test trials (2, one ignorance, one knowledge).

```{r}
distinct_trials <- data_preprocessed_post_exclusions %>%
  ungroup() %>%
  distinct(lab_id, participant_id, participant_lab_id, participant_trial_id, trial_file_name, media_name, condition)

trial_overview <- distinct_trials %>%
  filter(condition %in% c("familiarization", "knowledge", "ignorance")) %>%
  group_by(lab_id, participant_id, participant_lab_id, condition) %>%
  count()
# check distribution of trials
table(trial_overview$condition, trial_overview$n)

# look a little closer at the cases where we have more than one test trial
participants_w_additional_test_trials <- trial_overview %>%
  filter(condition == "knowledge", n > 1) %>%
  pull(participant_lab_id)

assert_that(length(participants_w_additional_test_trials) == 0)

# look a little closer at any cases where participants have too few familiarization trials
participants_w_fewer_familiarization_trials <- trial_overview %>%
  filter(condition == "familiarization", n < 3) %>%
  pull(participant_lab_id)

assert_that(length(participants_w_fewer_familiarization_trials) == 0)
```

Splitting the data into familiarization data and test data.

```{r}
fam_data <- data_preprocessed_post_exclusions %>%
  filter(condition %in% c("familiarization"))

test_data <- data_preprocessed_post_exclusions %>%
  filter(condition %in% c("knowledge", "ignorance"))
```

# AOI Proportion Looking

## Familiarization Data

### Summarizing Familiarization Data

```{r}
summarize_participant_familiarization <- fam_data %>%
  group_by(lab_id, age_cohort, condition, participant_lab_id, participant_id, participant_trial_id, trial_num, point_of_disambiguation, video_duration_ms, media_name) %>%
  filter(t_norm <= 120 & t_norm >= -3880) %>%
  mutate(
    aoi_diff = c(0, diff(as.numeric(as.factor(aoi))))
  ) %>%
  summarize(
    t_min = min(t_norm),
    t_max = max(t_norm),
    sum_target_general = sum(aoi == "target_general", na.rm = T),
    sum_distractor_general = sum(aoi == "distractor_general", na.rm = T),
    prop_general = sum_target_general / (sum_target_general + sum_distractor_general),
    sum_target_exit = sum(aoi == "target_exit", na.rm = T),
    sum_distractor_exit = sum(aoi == "distractor_exit", na.rm = T),
    prop_exit = sum_target_exit / (sum_target_exit + sum_distractor_exit),
    N_general = sum_target_general + sum_distractor_general,
    N_exit = sum_target_exit + sum_distractor_exit
  ) %>%
  group_by(lab_id, age_cohort, condition, participant_id) %>%
  mutate(familiarization_trial_num = rank(trial_num, ties.method = "first")) # check this

saveRDS(summarize_participant_familiarization,
  file = here(RESULTS_FOLDER, "summarize_participant_familiarization.rds")
)

summarize_participant_familiarization_overall <- summarize_participant_familiarization %>%
  group_by(lab_id, age_cohort, participant_lab_id, participant_id) %>%
  summarize(
    fam_trial_n = n(),
    fam_prop_exit = mean(prop_exit, na.rm = TRUE),
    fam_prop_general = mean(prop_general, na.rm = TRUE)
  )

saveRDS(summarize_participant_familiarization_overall, file = here(RESULTS_FOLDER, "summarize_participant_familiarization_overall.rds"))
```

Some quick checks on the resulting data

```{r}
# distribution of total looks
ggplot(summarize_participant_familiarization, aes(N_exit)) +
  geom_histogram() +
  facet_wrap(~age_cohort)
```

### Overall Plots

```{r}
# plot average proportion looking
overall_p_fam <- ggplot(
  #filter(summarize_participant_familiarization, N_exit >= 5),
  summarize_participant_familiarization,
  aes(x = as.factor(familiarization_trial_num), y = prop_exit, color = condition)
) +
  # geom_violin()+
  geom_boxplot() +
  # geom_beeswarm(alpha=0.5)+
  stat_summary(fun.data = "mean_cl_boot", size = 1.2, color = "black") +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  theme_cowplot() +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  facet_wrap(~age_cohort) +
  theme(legend.position = "none") +
  #ggtitle("Familiarization") +
  #theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  xlab("Trial Number") +
  ylab("Proportion DLS to Target Exit")
overall_p_fam
ggsave(here(plot_path, "familiarization_overall_proportion_target_exit_looking.png"),
  bg = "white", width = 9, height = 6
)
```

### Summary Statistics

```{r}
summarize_fam_aoi_overall <- summarize_participant_familiarization %>%
  group_by(age_cohort, lab_id, participant_lab_id, participant_id, condition) %>%
  summarize(
    n = n(),
    mean_subj_prop_exit = mean(prop_exit, na.rm = T)
  ) %>%
  group_by(age_cohort, condition) %>%
  summarize(
    participant_num = sum(!is.na(mean_subj_prop_exit)),
    mean_target_looking = mean(mean_subj_prop_exit, na.rm = T),
    sd_target_looking = sd(mean_subj_prop_exit, na.rm = T),
    t_test = list(broom::tidy(t.test(mean_subj_prop_exit, alternative = "two.sided", mu = 0.5)))
  ) %>%
  mutate(
    se_target_looking = sd_target_looking / sqrt(participant_num),
    lower_ci = mean_target_looking - qt(1 - (0.05 / 2), participant_num - 1) * se_target_looking,
    upper_ci = mean_target_looking + qt(1 - (0.05 / 2), participant_num - 1) * se_target_looking,
    p.value = purrr::map(t_test, ~ select(.x, c("p.value", "parameter", "statistic")))
  ) %>%
  dplyr::select(-t_test) %>%
  unnest(p.value) %>%
  rename(
    tval = statistic,
    df = parameter
  )

summarize_fam_aoi_overall %>%
  knitr::kable()

saveRDS(summarize_fam_aoi_overall, file = here(RESULTS_FOLDER, "summary_fam_aoi_overall.rds"))
```

By individual trial

```{r}
summarize_fam_aoi_by_trial <- summarize_participant_familiarization %>%
  group_by(age_cohort, condition, familiarization_trial_num) %>%
  summarize(
    participant_num = sum(!is.na(prop_exit)),
    mean_target_looking = mean(prop_exit, na.rm = T),
    sd_target_looking = sd(prop_exit, na.rm = T)
  ) %>%
  mutate(
    se_target_looking = sd_target_looking / sqrt(participant_num),
    lower_ci = mean_target_looking - qt(1 - (0.05 / 2), participant_num - 1) * se_target_looking,
    upper_ci = mean_target_looking + qt(1 - (0.05 / 2), participant_num - 1) * se_target_looking
  )

summarize_fam_aoi_by_trial %>%
  knitr::kable()
```

### Main Model

#### Toddlers

```{r, eval= FIT_BAYES_MODELS}
# set the prior
priors <- c(
  set_prior("uniform(-0.5, 0.5)", lb = -0.5, ub = 0.5, class = "Intercept"), # uniform distribution for intercept
  set_prior("normal(0, .1)", class = "b"), # normal distribution for fixed-effect coefficients
  set_prior("normal(0, .05)", class = "sd"), # normal distribution for sd/ random effects
  set_prior("lkj(2)", class = "L")
) # lkj distribution for covariance matrix/Cholesky Factor

# shift trial number coding
# From the RR:
# Our key question of interest is whether overall anticipation is higher than chance levels on the familiarization trial immediately before the test trials, in service of evaluating the evidence that participants are attentive and making predictive looks immediately prior to test. To evaluate this question across the four models, we will code trial number so that the last trial before the test trials (trial 4) is set to the intercept
summarize_participant_familiarization <- summarize_participant_familiarization %>%
  mutate(familiarization_trial_num_4 = familiarization_trial_num - 4) %>%
  unite(participant_lab_id, lab_id, participant_id, remove = F) %>% # making sure that participant ids are not accidentally combined across labs
  mutate(prop_exit_adj = prop_exit - 0.5) # adjusting for chance

bm_fam_aoi_toddlers <- brm(
  prop_exit_adj ~ 1 + familiarization_trial_num_4 +
    (1 + familiarization_trial_num_4 | lab_id) +
    (1 + familiarization_trial_num_4 | participant_lab_id),
  family = gaussian,
  prior = priors,
  save_pars = save_pars(all = TRUE),
  filter(summarize_participant_familiarization, age_cohort == "toddlers"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
bm_fam_aoi_toddlers_summary <- summary(bm_fam_aoi_toddlers)
# prior_summary(bm_fam_aoi_toddlers)

saveRDS(bm_fam_aoi_toddlers,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_aoi_toddlers.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_aoi_toddlers <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_aoi_toddlers.rds"))
```


Organize table in a tidy format

```{r}
bm_fam_aoi_toddlers_tidy_summary <- as_tibble(summary(bm_fam_aoi_toddlers)$fixed,rownames=NA) %>% 
  rownames_to_column("term") %>% 
  rename(
    estimate = Estimate,
    est_error = Est.Error,
    lower_ci = `l-95% CI`,
    upper_ci = `u-95% CI`,
    rhat=Rhat
  ) %>%
  select(term,estimate,est_error,lower_ci,upper_ci,rhat)

saveRDS(bm_fam_aoi_toddlers_tidy_summary,
  file = here(RESULTS_FOLDER, "bm_fam_aoi_toddlers_model_summary.rds")
)
```

Conduct model diagnostics

```{r}
#Is Rhat<1.1?
bm_fam_aoi_toddlers_tidy_summary$rhat
sum(bm_fam_aoi_toddlers_tidy_summary$rhat>=1.1)

#visual posterior predictive check
pp_check(bm_fam_aoi_toddlers) #one can clearly see that the model misses the zero-/one-inflation structure in the distribution
```

Summarize outcomes

Intercept

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_fam_aoi_toddlers_intercept_effect <- bm_fam_aoi_toddlers %>%
  spread_draws(b_Intercept, sigma) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_aoi_toddlers_intercept_effect,
  file = here(RESULTS_FOLDER, "bm_fam_aoi_toddlers_intercept_effect.rds")
)
```

Trial Number

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_fam_aoi_toddlers_trial_number_effect <- bm_fam_aoi_toddlers %>%
  spread_draws(b_familiarization_trial_num_4, sigma) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_aoi_toddlers_trial_number_effect,
  file = here(RESULTS_FOLDER, "bm_fam_aoi_toddlers_trial_number_effect.rds")
)
```

Compute the Bayes factor using bridge sampling

```{r, eval= FIT_BAYES_MODELS}
#fit the updated model
bm_fam_aoi_toddlers_null <- update(bm_fam_aoi_toddlers, formula = ~ . - 1) # remove intercept
summary(bm_fam_aoi_toddlers_null)

saveRDS(bm_fam_aoi_toddlers_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_aoi_toddlers_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_aoi_toddlers_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_aoi_toddlers_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
#compute Bayes factor
fam_m_comparision_PTL_toddlers <- brms::bayes_factor(
  bm_fam_aoi_toddlers, bm_fam_aoi_toddlers_null
)

saveRDS(fam_m_comparision_PTL_toddlers,
  file = here(RESULTS_FOLDER, "fam_m_comparison_PTL_toddlers.rds")
)
```

Remove the Bayes models from the environment (because the model objects are quite large).

```{r}
# remove Bayes model fits
rm(bm_fam_aoi_toddlers)
rm(bm_fam_aoi_toddlers_null)
```

#### Adults

```{r, eval = FIT_BAYES_MODELS}
bm_fam_aoi_adults <- brm(
  prop_exit_adj ~ 1 + familiarization_trial_num_4 +
    (1 + familiarization_trial_num_4 | lab_id) +
    (1 + familiarization_trial_num_4 | participant_lab_id),
  family = gaussian,
  prior = priors,
  save_pars = save_pars(all = TRUE),
  filter(summarize_participant_familiarization, age_cohort == "adults"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_fam_aoi_adults)
# prior_summary(bm_fam_aoi_adults)

saveRDS(bm_fam_aoi_adults,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_aoi_adults.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_aoi_adults <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_aoi_adults.rds"))
```

Organize table in a tidy format

```{r}
bm_fam_aoi_adults_tidy_summary <- as_tibble(summary(bm_fam_aoi_adults)$fixed,rownames=NA) %>% 
  rownames_to_column("term") %>% 
  rename(
    estimate = Estimate,
    est_error = Est.Error,
    lower_ci = `l-95% CI`,
    upper_ci = `u-95% CI`,
    rhat=Rhat
  ) %>%
  select(term,estimate,est_error,lower_ci,upper_ci,rhat)

saveRDS(bm_fam_aoi_adults_tidy_summary,
  file = here(RESULTS_FOLDER, "bm_fam_aoi_adults_model_summary.rds")
)
```

Summarize outcomes

Intercept

```{r}
# get main coefficient estimate and HDI
bm_fam_aoi_adults_intercept_effect <- bm_fam_aoi_adults %>%
  spread_draws(b_Intercept, sigma) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_aoi_adults_intercept_effect,
  file = here(RESULTS_FOLDER, "bm_fam_aoi_adults_intercept_effect.rds")
)
```

Trial Number

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_fam_aoi_adults_trial_number_effect <- bm_fam_aoi_adults %>%
  spread_draws(b_familiarization_trial_num_4, sigma) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_aoi_adults_trial_number_effect,
  file = here(RESULTS_FOLDER, "bm_fam_aoi_adults_trial_number_effect.rds")
)
```

Compute Bayes factor approach

```{r, eval = FIT_BAYES_MODELS}
bm_fam_aoi_adults_null <- update(bm_fam_aoi_adults, formula = ~ . - 1) # remove intercept
summary(bm_fam_aoi_adults_null)

saveRDS(bm_fam_aoi_adults_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_aoi_adults_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_aoi_adults_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_aoi_adults_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
fam_m_comparison_PTL_adults <- brms::bayes_factor(
  bm_fam_aoi_adults, bm_fam_aoi_adults_null
)

saveRDS(fam_m_comparison_PTL_adults,
  file = here(RESULTS_FOLDER, "fam_m_comparison_PTL_adults.rds")
)
```

```{r}
# remove Bayes model fits
rm(bm_fam_aoi_adults)
rm(bm_fam_aoi_adults_null)
```

## Test Data

### Summarizing Test Data (First Trial)

```{r}
# filter to first trials
test_data_first_trial <- test_data %>%
  # filter to first trial only
  filter(trial_num == 5)

# check to make sure we are filtering correctly
# e.g., no participants contribute multiple first trials
test_data_first_trial_overview <- test_data_first_trial %>%
  ungroup() %>%
  distinct(lab_id, participant_lab_id, participant_id, participant_trial_id, trial_num)

num_test_first_trials <- test_data_first_trial_overview %>%
  group_by(lab_id, participant_lab_id, participant_id) %>%
  count()
# make sure we only have one trial per participant
# the next two statements must both be true
assert_that(num_test_first_trials$n[1] == 1) # first element equals one
assert_that(length(unique(num_test_first_trials$n)) == 1) # all elements are equal
```

```{r}
# now summarize all data
summarize_participant_test_first_trial <- test_data_first_trial %>%
  group_by(
    lab_id, age_cohort, age_mo, age_years_n, participant_lab_id,
    participant_id, participant_trial_id, trial_file_name,
    bear_not_visible_ms, point_of_disambiguation, video_duration_ms,
    condition, data_type, trial_num
  ) %>%
  # filter to relevant anticipatory window
  # based on current format, t_norm == 0 is the point of disambiguation
  # so we want the 4000 ms leading up, minus 120 ms of saccade/ planning time
  # check this!!!
  filter(t_norm <= 120 & t_norm >= -3880) %>%
  mutate(
    aoi_diff = c(0, diff(as.numeric(as.factor(aoi))))
  ) %>%
  summarize(
    t_min = min(t_norm),
    t_max = max(t_norm),
    sum_target_general = sum(aoi == "target_general", na.rm = T),
    sum_distractor_general = sum(aoi == "distractor_general", na.rm = T),
    prop_general = sum_target_general / (sum_target_general + sum_distractor_general),
    sum_target_exit = sum(aoi == "target_exit", na.rm = T),
    sum_target_box = sum(aoi == "target_box", na.rm = T),
    sum_distractor_exit = sum(aoi == "distractor_exit", na.rm = T),
    sum_distractor_box = sum(aoi == "distractor_box", na.rm = T),
    prop_exit = sum_target_exit / (sum_target_exit + sum_distractor_exit),
    prop_box = sum_target_box / (sum_target_box + sum_distractor_box),
    N_general = sum_target_general + sum_distractor_general,
    N_exit = sum_target_exit + sum_distractor_exit,
    N_box = sum_target_box + sum_distractor_box
  ) %>%
  ungroup() %>%
  # center age, condition, and method
  mutate(
    age_mo_c = age_mo - mean(age_mo, na.rm = TRUE),
    condition_c = case_when(
      condition == "knowledge" ~ -0.5,
      condition == "ignorance" ~ 0.5
    ),
    method_c = case_when( # MSS: why do we have two variables for method/data_type?
      data_type == "web-based" ~ -0.5,
      data_type == "in-lab" ~ 0.5
    )
  )

saveRDS(summarize_participant_test_first_trial,
  file = here(RESULTS_FOLDER, "summarize_participant_test_first_trial.rds")
)
```

```{r}
# distribution of total looks
ggplot(summarize_participant_test_first_trial, aes(N_exit)) +
  geom_histogram() +
  facet_wrap(~age_cohort)
```

### Overall Plots

First look at the proportional looking measures, focusing on the target exit during the anticipatory window.

Alternative plot

```{r}
# plot average proportion looking
overall_p_test <- ggplot(
  summarize_participant_test_first_trial,
  aes(x = condition, y = prop_exit, color = condition)
) +
  # geom_violin()+
  # geom_boxplot()+
  #geom_beeswarm(alpha = 0.2, cex = 0.5) +
  geom_jitter(width=0.05,height=0.025,alpha=0.3,stroke=NA)+
  geom_half_violin(
    aes(fill = condition), side = "l", nudge = 0.2, width = 0.4, alpha = 0.2
  ) +
  stat_summary(fun.data = "mean_cl_boot", size = 1, position=position_nudge(x = .2, y = 0)) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  theme_cowplot() +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  facet_wrap(~age_cohort) +
  theme(legend.position = "none") +
  #ggtitle("Test") +
  #theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  ylab("Proportion DLS to Target Exit")
overall_p_test
ggsave(here(plot_path, "overall_proportion_first_trial_target_exit_looking.png"),
  bg = "white", width = 9, height = 6
)
```

Splitting plot by lab and age cohort

```{r}
adults_prop <- ggplot(
  filter(summarize_participant_test_first_trial, age_cohort == "adults"),
  aes(x = condition, y = prop_exit, color = condition)
) +
  geom_half_violin(
    aes(fill = condition), side = "l", nudge = 0.2, width = 0.4, alpha = 0.2
  ) +
  geom_jitter(width=0.05,height=0.025,alpha=0.3,stroke=NA)+
  stat_summary(fun.data = "mean_cl_boot", size = 0.8, position=position_nudge(x = .2, y = 0)) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  theme_cowplot() +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  facet_wrap(~ age_cohort + lab_id) +
  theme(legend.position = "none") +
  ylab("Proportion Looking to Exit\n(Anticipatory Window, First Trial)")
adults_prop
ggsave(here(plot_path, "adults_proportion_first_trial_target_exit_looking.png"),
  bg = "white", width = 16, height = 10
)

kids_prop <- ggplot(
  filter(summarize_participant_test_first_trial,age_cohort == "toddlers"),
  aes(x = condition, y = prop_exit, color = condition)
) +
  geom_half_violin(
    aes(fill = condition), side = "l", nudge = 0.2, width = 0.4, alpha = 0.2
  ) +
  geom_jitter(width=0.05,height=0.025,alpha=0.3,stroke=NA)+
  stat_summary(fun.data = "mean_cl_boot", size = 0.8, position=position_nudge(x = .2, y = 0)) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  theme_cowplot() +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  facet_wrap(~ age_cohort + lab_id) +
  theme(legend.position = "none") +
  ylab("Proportion Looking to Exit\n(Anticipatory Window, First Trial)")
kids_prop
ggsave(here(plot_path, "kids_proportion_first_trial_target_exit_looking.png"),
  bg = "white", width = 16, height = 10
)
```

Plot the effect by age

```{r}
# linear effect
kid_prop_by_age <- ggplot(
  filter(summarize_participant_test_first_trial, age_cohort == "toddlers"),
  aes(x = age_mo, y = prop_exit, color = condition)
) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm") +
  xlab("Age (in months)") +
  ylab("Proportion Looking to Exit\n(Anticipatory Window, First Trial)") +
  theme_cowplot() +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1")
kid_prop_by_age
ggsave(here(plot_path, "kids_proportion_first_trial_target_exit_looking_by_age.png"),
  bg = "white", width = 9, height = 6
)

#loess
kid_prop_by_age_loess <- ggplot(
  filter(summarize_participant_test_first_trial,age_cohort == "toddlers"),
  aes(x = age_mo, y = prop_exit, color = condition)
) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "loess") +
  xlab("Age (in months)") +
  ylab("Proportion Looking to Exit\n(Anticipatory Window, First Trial)") +
  theme_cowplot() +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1")
kid_prop_by_age_loess
ggsave(here(plot_path, "kids_proportion_first_trial_target_exit_looking_by_age_loess.png"),
  bg = "white", width = 9, height = 6
)
```

Effect of age after splitting by age bins.

```{r}
summarize_participant_test_first_trial <- summarize_participant_test_first_trial %>%
  mutate(
    age_bin_2m = case_when(
      age_cohort == "toddlers" & age_mo >= 18 & age_mo < 20 ~ "18-19 months",
      age_cohort == "toddlers" & age_mo >= 20 & age_mo < 22 ~ "20-21 months",
      age_cohort == "toddlers" & age_mo >= 22 & age_mo < 24 ~ "22-23 months",
      age_cohort == "toddlers" & age_mo >= 24 & age_mo < 26 ~ "24-25 months",
      age_cohort == "toddlers" & age_mo >= 26 & age_mo < 28 ~ ">26 months",
      TRUE ~ NA_character_
    )
  ) %>%
  mutate(
    age_bin = case_when(
      age_cohort == "toddlers" & age_mo >= 18 & age_mo < 19 ~ "18 mos",
      age_cohort == "toddlers" & age_mo >= 19 & age_mo < 20 ~ "19 mos",
      age_cohort == "toddlers" & age_mo >= 20 & age_mo < 21 ~ "20 mos",
      age_cohort == "toddlers" & age_mo >= 21 & age_mo < 22 ~ "21 mos",
      age_cohort == "toddlers" & age_mo >= 22 & age_mo < 23 ~ "22 mos",
      age_cohort == "toddlers" & age_mo >= 23 & age_mo < 24 ~ "23 mos",
      age_cohort == "toddlers" & age_mo >= 24 & age_mo < 25 ~ "24 mos",
      age_cohort == "toddlers" & age_mo >= 25 & age_mo < 26 ~ "25 mos",
      age_cohort == "toddlers" & age_mo >= 26 ~ "26 mos",
      TRUE ~ NA_character_
    )
  )

kids_prop_age_bin <- ggplot(
  filter(summarize_participant_test_first_trial,age_cohort == "toddlers"),
  aes(x = condition, y = prop_exit, color = condition)
) +
  geom_half_violin(
    aes(fill = condition), side = "l", nudge = 0.2, width = 0.4, alpha = 0.2
  ) +
  geom_jitter(width=0.05,height=0.025,alpha=0.3,stroke=NA)+
  stat_summary(fun.data = "mean_cl_boot", size = 0.8, position=position_nudge(x = .2, y = 0)) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  theme_cowplot() +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  facet_wrap(~ age_bin,ncol=3) +
  theme(legend.position = "none") +
  ylab("Proportion Looking to Exit\n(Anticipatory Window, First Trial)")
kids_prop_age_bin
ggsave(here(plot_path, "kids_proportion_first_trial_target_exit_looking_age_bins.png"),
  bg = "white", width = 16, height = 10
)
```


### Summary Statistics

```{r}
summarize_test_aoi <- summarize_participant_test_first_trial %>%
  group_by(age_cohort, lab_id, participant_lab_id, participant_id, condition) %>%
  summarize(
    n = n(),
    mean_subj_prop_exit = mean(prop_exit, na.rm = T)
  ) %>%
  group_by(age_cohort, condition) %>%
  summarize(
    participant_num = sum(!is.na(mean_subj_prop_exit)),
    mean_target_looking = mean(mean_subj_prop_exit, na.rm = T),
    sd_target_looking = sd(mean_subj_prop_exit, na.rm = T),
    t_test = list(broom::tidy(t.test(mean_subj_prop_exit, alternative = "two.sided", mu = 0.5)))
  ) %>%
  mutate(
    # 95% CIs
    lower_ci_target_looking = mean_target_looking -
      qt(1 - (0.05 / 2), participant_num - 1) * sd_target_looking / sqrt(participant_num),
    upper_ci_target_looking = mean_target_looking +
      qt(1 - (0.05 / 2), participant_num - 1) * sd_target_looking / sqrt(participant_num),
    # mean_target_looking_general = mean(prop_general, na.rm=T),
    # sd_target_looking_general=sd(prop_general,na.rm=T),
    lower_ci_target_looking_general = mean_target_looking -
      qt(1 - (0.05 / 2), participant_num - 1) * sd_target_looking / sqrt(participant_num),
    upper_ci_target_looking_general = mean_target_looking +
      qt(1 - (0.05 / 2), participant_num - 1) * sd_target_looking / sqrt(participant_num),
    p.value = purrr::map(t_test, ~ select(.x, c("p.value", "parameter", "statistic")))
  ) %>%
  select(-t_test) %>%
  unnest(p.value) %>%
  rename(
    tval = statistic,
    df = parameter
  )


summarize_test_aoi %>%
  knitr::kable()

saveRDS(summarize_test_aoi,
  file = here(RESULTS_FOLDER, "summary_test_aoi_overall.rds")
)
```

### Meta-analysis

First, we create a data frame computing effect sizes by lab and cohort

```{r}
avgs_by_lab <- summarize_participant_test_first_trial |>
  filter(!is.na(prop_exit)) |> 
   group_by(age_cohort, lab_id, condition) |>
  summarise(mean = mean(prop_exit, na.rm = TRUE),
            sd = sd(prop_exit, na.rm = TRUE),
            n = sum(!is.na(prop_exit)), .groups = "drop",
            mean_age_mo = mean(age_mo,na.rm=TRUE)) %>%
  pivot_wider(names_from = condition, values_from = c(mean, sd, n, mean_age_mo)) 

ds_by_lab <- avgs_by_lab %>%
  mutate(
    pooled_sd = sqrt(((n_ignorance - 1) * sd_ignorance^2 + (n_knowledge - 1) * sd_knowledge^2) /
                     (n_ignorance + n_knowledge - 2)),
    d = (mean_knowledge - mean_ignorance) / pooled_sd,
    d_var = (n_ignorance + n_knowledge) / (n_ignorance * n_knowledge) +
      (d^2) / (2 * (n_ignorance + n_knowledge)),
    mean_age = (mean_age_mo_ignorance*n_ignorance + mean_age_mo_knowledge*n_knowledge) / (n_ignorance + n_knowledge)
  )

#compute hedges g and variance
hedgesg_by_lab <- avgs_by_lab %>%
  transmute(
    age_cohort,
    lab_id,
    d_stats = pmap(
      list(
        m1i = .data[["mean_knowledge"]], 
        sd1i = .data[["sd_knowledge"]], 
        n1i = .data[["n_knowledge"]],
        m2i = .data[["mean_ignorance"]], 
        sd2i = .data[["sd_ignorance"]], 
        n2i = .data[["n_ignorance"]]
      ),
      \(...) escalc(measure = "SMD", ...) #note: set correct=FALSE here to compute cohen's d - yielding identical results to the by-hand calculations above
    )
  ) %>%
  unnest_wider(d_stats) %>%
  rename(hedgesg = yi, hedgesg_var = vi)

#join
effects_by_lab <- ds_by_lab %>%
  left_join(hedgesg_by_lab) %>%
  #filter labs for which we can't compute effects
  filter(!is.na(hedgesg))
```

Next, compute meta-analytic effect sizes and prepare a forest plot dataset for plotting

```{r meta-analytic effects}
# Next, we fit a meta-analytic model, including the moderator age_cohort, and prep the data for the forest plot.
# intercept-only model
intercept_mod <- metafor::rma(hedgesg ~ 1,
  vi = hedgesg_var, slab = lab_id, data = effects_by_lab,
  method = "REML"
)

# model including the moderator age_cohort
age_mod <- metafor::rma(hedgesg ~ age_cohort,
  vi = hedgesg_var, slab = lab_id, data = effects_by_lab, method = "REML"
)

s# get fitted estimates for all labs
f <- fitted(intercept_mod)
p <- predict(intercept_mod)

alpha <- .05

forest_data <- data.frame(
  effects = as.numeric(intercept_mod$yi.f),
  variances = intercept_mod$vi.f
) |>
  mutate(
    effects.cil = effects -
      qnorm(alpha / 2, lower.tail = FALSE) * sqrt(variances),
    effects.cih = effects +
      qnorm(alpha / 2, lower.tail = FALSE) * sqrt(variances),
    estimate = as.numeric(f),
    lab = factor(names(f)),
    estimate.cil = p$ci.lb,
    estimate.cih = p$ci.ub,
    inverse_vars = 1 / variances,
    identity = 1,
    lab = str_replace(lab, "\\.[1-9]", ""),
    index = 1:n()
  ) |>
  bind_cols(ungroup(effects_by_lab)  |> select(lab_id, age_cohort,hedgesg)) |>
  # reorder data
  arrange(effects)

# predict MA means for age cohort
mf <- fitted(age_mod)
mp <- predict(age_mod,
  newmods = c(0,1),
  intercept = TRUE
)

# Add meta-analytic estimate
forest_data <- bind_rows(
  forest_data,
  tibble(
    lab = "Meta-Analytic Estimate",
    age_cohort = "",
    effects = summary(intercept_mod)$b[1],
    effects.cil = summary(intercept_mod)$ci.lb,
    effects.cih = summary(intercept_mod)$ci.ub
  ),
  tibble(
    lab = "Meta-Analytic Estimate",
    age_cohort = c(
      "adults","toddlers"
    ),
    effects = mp$pred,
    effects.cil = mp$ci.lb,
    effects.cih = mp$ci.ub
  )
) |>
  mutate(
    age_cohort = fct_rev(fct_relevel(age_cohort, "")),
    lab = fct_relevel(lab, "Meta-Analytic Estimate")
  )

# determine order of labs based on effect size
forest_data <- forest_data |>
  # make lab names unique
  mutate(
    unique_lab = case_when(
      age_cohort=="" ~ lab,
      TRUE ~ paste0(lab,"-",age_cohort)
    )
  )
forest_data_lab_names_in_order <- unique(as.character(forest_data$unique_lab))
forest_data$unique_lab <- factor(forest_data$unique_lab, levels = rev(forest_data_lab_names_in_order))
```

Create a meta-analytic forest plot of the condition effect.

```{r}
color_list <- c("#1b9e77", "#C46F3EFF")
forest_plot <- ggplot(forest_data, aes(x = unique_lab, y = effects)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey") +
  geom_linerange(
    aes(
      ymin = effects - sqrt(variances) * 1.96,
      ymax = effects + sqrt(variances) * 1.96,
      group = index
    ),
    alpha = .5,
    position = position_dodge(width = .5)
  ) +
  geom_point(
    data = filter(forest_data, lab != "Meta-Analytic Estimate"),
    aes(
      y = effects, size = inverse_vars, col = age_cohort,
      group = index
    ),
    alpha = 1,
    position = position_dodge(width = .5)
  ) +
  geom_point(
    data = filter(forest_data, lab == "Meta-Analytic Estimate"),
    pch = 5
  ) +
  geom_linerange(
    data = filter(forest_data, lab == "Meta-Analytic Estimate"),
    aes(ymin = effects.cil, ymax = effects.cih),
    alpha = .5
  ) +
  facet_grid(age_cohort ~ ., scales = "free", space = "free") +
  coord_flip() +
  scale_size_continuous(guide = FALSE) +
  xlab("Lab") +
  ylab("Effect Size") +
  theme(axis.text.y = element_text(size = 15)) +
  theme_bw() +
  theme(
    strip.background = element_blank(),
    panel.grid = element_blank(),
    axis.title.x = element_text(face = "bold", size = 15),
    axis.text.x = element_text(size = 14),
    axis.title.y = element_text(face = "bold", size = 15),
    axis.text.y = element_text(size = 11),
    strip.text= element_text(size = 15, face = "bold") # was 15
  ) +
  scale_color_manual(values = color_list,guide = FALSE)

forest_plot
ggsave(here(plot_path, "forest_dls_condition_effect.png"),
  bg = "white", width = 9, height = 12
)
```


### Main Model

Fitting the main Bayesian hierarchical model testing the effect of condition (ignorance vs. knowledge) on first-trial proportion target looking during the anticipatory window.

#### Toddlers

```{r, eval = FIT_BAYES_MODELS}
# set the prior
priors <- c(
  set_prior("uniform(0, 1)", lb = 0, ub = 1, class = "Intercept"), # uniform distribution for intercept
  set_prior("normal(0, .1)", class = "b"), # normal distribution for fixed-effect coefficients
  set_prior("normal(0, .05)", class = "sd"), # normal distribution for sd/ random effects
  set_prior("lkj(2)", class = "L")
) # lkj distribution for covariance matrix/Cholesky Factor

bm_aoi_toddlers <- brm(
  prop_exit ~ 1 + condition_c + age_mo_c + condition_c * age_mo_c +
    (1 + condition_c + age_mo_c + condition_c * age_mo_c | lab_id),
  family = gaussian,
  prior = priors,
  save_pars = save_pars(all = TRUE),
  filter(summarize_participant_test_first_trial, age_cohort == "toddlers"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_aoi_toddlers)
# prior_summary(bm_aoi_toddlers)

saveRDS(bm_aoi_toddlers,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_toddlers.rds")
)

# Checking variance for lab_id
lab_variance <- as.numeric(VarCorr(bm_aoi_toddlers)$`lab_id`$sd[1]^2)
random_effects <- VarCorr(bm_aoi_toddlers)

lab_variance <- as.numeric(random_effects$lab_id$sd[1])^2
residual_variance <- as.numeric(random_effects$residual$sd[1])^2

icc <- lab_variance / (lab_variance + residual_variance)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_aoi_toddlers <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_toddlers.rds"))
```


Organize table in a tidy format

```{r}
bm_test_aoi_toddlers_tidy_summary <- as_tibble(summary(bm_aoi_toddlers)$fixed,rownames=NA) %>% 
  rownames_to_column("term") %>% 
  rename(
    estimate = Estimate,
    est_error = Est.Error,
    lower_ci = `l-95% CI`,
    upper_ci = `u-95% CI`,
    rhat=Rhat
  ) %>%
  select(term,estimate,est_error,lower_ci,upper_ci,rhat)

saveRDS(bm_test_aoi_toddlers_tidy_summary,
  file = here(RESULTS_FOLDER, "bm_test_aoi_toddlers_model_summary.rds")
)
```

Conduct model diagnostics

```{r}
#Is Rhat<1.1?
bm_test_aoi_toddlers_tidy_summary$rhat
sum(bm_test_aoi_toddlers_tidy_summary$rhat>=1.1)

#visual posterior predictive check
pp_check(bm_aoi_toddlers) #one can clearly see that the model misses the zero-/one-inflation structure in the distribution
```

Summarize outcomes

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_aoi_toddlers_condition_effect <- bm_aoi_toddlers %>%
  spread_draws(b_condition_c, sigma) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_aoi_toddlers_condition_effect,
  file = here(RESULTS_FOLDER, "bm_aoi_toddlers_condition_effect.rds")
)

bm_aoi_toddlers_age_effect <- bm_aoi_toddlers %>%
  spread_draws(b_age_mo_c, sigma) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_aoi_toddlers_age_effect,
  file = here(RESULTS_FOLDER, "bm_aoi_toddlers_age_effect.rds")
)

bm_aoi_toddlers_condition_age_interaction <- bm_aoi_toddlers %>%
  spread_draws(`b_condition_c:age_mo_c`, sigma) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_aoi_toddlers_condition_age_interaction,
  file = here(RESULTS_FOLDER, "bm_aoi_toddlers_condition_age_interaction.rds")
)
```

Visualize model coefficients

```{r}
bm_aoi_toddlers %>%
  spread_draws(b_condition_c, b_age_mo_c, `b_condition_c:age_mo_c`, sigma) %>%
  pivot_longer(cols = starts_with("b_"), names_to = "coefficient", values_to = "b") %>%
  ggplot(aes(x = coefficient, y = b)) +
  stat_halfeye() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  theme_cowplot() +
  scale_x_discrete(
    limits = c("b_condition_c:age_mo_c", "b_age_mo_c", "b_condition_c"),
    labels = c("Condition x Age", "Age", "Condition")
  ) +
  ylab("Model Coefficient Estimate") +
  xlab("Model Predictor") +
  coord_flip()
ggsave(here(plot_path, "test_toddlers_model_coefficients.png"),
  bg = "white", width = 9, height = 6
)
```

Compute Bayes Factor (bridge sampling approach) - Condition Effect

```{r, eval = FIT_BAYES_MODELS}
bm_aoi_toddlers_condition_null <- update(bm_aoi_toddlers, formula = ~ . - condition_c)
summary(bm_aoi_toddlers_condition_null)

saveRDS(bm_aoi_toddlers_condition_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_toddlers_condition_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_aoi_toddlers_condition_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_toddlers_condition_null.rds"))
```


```{r, eval = COMPUTE_BAYES_FACTORS}
test_m_comparison_PTL_toddlers <- brms::bayes_factor(
  bm_aoi_toddlers, bm_aoi_toddlers_condition_null
)

saveRDS(test_m_comparison_PTL_toddlers,
  file = here(RESULTS_FOLDER, "test_m_comparison_PTL_toddlers.rds")
)
```

Compute Bayes Factor (bridge sampling approach) - Condition*Age Interaction Effect

```{r, eval = FIT_BAYES_MODELS}
bm_aoi_toddlers_interaction_null <- update(bm_aoi_toddlers, formula = ~ . - condition_c * age_mo_c)
summary(bm_aoi_toddlers_interaction_null)

saveRDS(bm_aoi_toddlers_interaction_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_toddlers_interaction_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_aoi_toddlers_interaction_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_toddlers_interaction_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
test_m_comparison_PTL_toddlers_interaction <- brms::bayes_factor(
  bm_aoi_toddlers, bm_aoi_toddlers_interaction_null
)

saveRDS(test_m_comparison_PTL_toddlers_interaction,
  file = here(RESULTS_FOLDER, "test_m_comparison_PTL_toddlers_interaction.rds")
)

#Alternative approach to computing Bayes factor (just as a sanity check that we are using sufficient iterations - these Bayes factors should converge)
h_aoi_toddlers_interaction <- hypothesis(bm_aoi_toddlers, "condition_c*age_mo_c = 0", class = "b")
h_aoi_toddlers_interaction
plot(h_aoi_toddlers_interaction)
# evidence in favor of condition being different from zero
1 / h_aoi_toddlers_interaction$hypothesis$Evid.Ratio
```

Investigate robustness of the result using a model that better captures zero/1-inflation (preliminary investigation)

```{r, eval = FIT_BAYES_MODELS}
#preliminary attempt to fit a zero/one-inflated beta regression model
bm_aoi_toddlers_01inflation_formula <- bf(
  prop_exit ~ 1 +  condition_c + age_mo_c + condition_c * age_mo_c +
    (1 + condition_c + age_mo_c + condition_c * age_mo_c | lab_id),
  phi ~ 1 +  condition_c + age_mo_c + condition_c * age_mo_c +
    (1 + condition_c + age_mo_c + condition_c * age_mo_c | lab_id),
  zoi ~ 1 +  condition_c + age_mo_c + condition_c * age_mo_c +
    (1 + condition_c + age_mo_c + condition_c * age_mo_c | lab_id),
  coi ~ 1 +  condition_c + age_mo_c + condition_c * age_mo_c +
    (1 + condition_c + age_mo_c + condition_c * age_mo_c | lab_id),
  family = zero_one_inflated_beta())
bm_aoi_toddlers_01inflation <- brm(
  formula = bm_aoi_toddlers_01inflation_formula,
  save_pars = save_pars(all = TRUE),
  data = filter(summarize_participant_test_first_trial, age_cohort == "toddlers"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12))
summary(bm_aoi_toddlers_01inflation)
```

```{r}
# remove Bayes model fits
rm(bm_aoi_toddlers)
rm(bm_aoi_toddlers_condition_null)
rm(bm_aoi_toddlers_interaction_null)
```

#### Adults

```{r, eval = FIT_BAYES_MODELS}
bm_aoi_adults <- brm(
  prop_exit ~ 1 + condition_c + (1 + condition_c | lab_id),
  family = gaussian,
  prior = priors,
  save_pars = save_pars(all = TRUE),
  filter(summarize_participant_test_first_trial, age_cohort == "adults"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_aoi_adults)

saveRDS(bm_aoi_adults,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_adults.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_aoi_adults <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_adults.rds"))
```

Organize table in a tidy format

```{r}
bm_test_aoi_adults_tidy_summary <- as_tibble(summary(bm_aoi_adults)$fixed,rownames=NA) %>% 
  rownames_to_column("term") %>% 
  rename(
    estimate = Estimate,
    est_error = Est.Error,
    lower_ci = `l-95% CI`,
    upper_ci = `u-95% CI`,
    rhat=Rhat
  ) %>%
  select(term,estimate,est_error,lower_ci,upper_ci,rhat)

saveRDS(bm_test_aoi_adults_tidy_summary,
  file = here(RESULTS_FOLDER, "bm_test_aoi_adults_tidy_summary.rds")
)
```

```{r}
# get main coefficient estimate and HDI
bm_aoi_adults_condition_effect <- bm_aoi_adults %>%
  spread_draws(b_condition_c, sigma) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_aoi_adults_condition_effect,
  file = here(RESULTS_FOLDER, "bm_aoi_adults_condition_effect.rds")
)
```

Alternate Bayes factor approach

```{r, eval = FIT_BAYES_MODELS}
bm_aoi_adults_null <- update(bm_aoi_adults, formula = ~ . - condition_c)
summary(bm_aoi_adults_null)

saveRDS(bm_aoi_adults_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_adults_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_aoi_adults_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_aoi_adults_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
test_m_comparison_PTL_adults <- brms::bayes_factor(
  bm_aoi_adults, bm_aoi_adults_null
)

saveRDS(test_m_comparison_PTL_adults,
  file = here(RESULTS_FOLDER, "test_m_comparison_PTL_adults.rds")
)
```

Robustness: beta regression

```{r, eval = FIT_BAYES_MODELS}
# set the prior
priors_01inflation <- c(
  set_prior("uniform(0, 1)", lb = 0, ub = 1, class = "Intercept"), # uniform distribution for intercept
  set_prior("normal(0, .1)", class = "b"), # normal distribution for fixed-effect coefficients
  set_prior("normal(0, .05)", class = "sd"), # normal distribution for sd/ random effects
  set_prior("lkj(2)", class = "L")
) # lkj distribution for covariance matrix/Cholesky Factor
bm_aoi_adults_01inflation <- brm(
  prop_exit ~ 1 + condition_c + (1 + condition_c | lab_id),
  family = zero_one_inflated_beta,
  prior = priors_01inflation,
  save_pars = save_pars(all = TRUE),
  filter(summarize_participant_test_first_trial, age_cohort == "adults"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_aoi_adults_01inflation)

pp_check(bm_aoi_adults_01inflation)
```

Remove Bayes model fits

```{r}
rm(bm_aoi_adults)
rm(bm_aoi_adults_null)
```

# Timecourse extension

```{r}
mss_timecourse_test_first_trial <- test_data %>%
  # quick filter of the (extended duration) 2nd test trials
  group_by(
    lab_id, age_cohort, participant_lab_id, participant_id, participant_trial_id,
    trial_file_name,
    bear_not_visible_ms, point_of_disambiguation,
    video_duration_ms, condition
  ) %>%
  mutate(t_norm_downsampled = floor(t_norm / 250) * 250) |>
  # filter to relevant anticipatory window
  # based on current format, t_norm == 0 is the point of disambiguation
  # so we want the 4000 ms leading up, minus 120 ms of saccade/ planning time
  # check this!!!
  filter(t_norm <= 120 & t_norm >= -16880) %>%
  group_by(
    lab_id, age_cohort, participant_id, participant_trial_id,
    trial_file_name, condition, t_norm_downsampled
  ) |>
  summarize(
    on_target = mean(aoi == "target_exit", na.rm = TRUE),
    on_dist = mean(aoi == "distractor_exit", na.rm = TRUE)
  )

ms_timecourse_test_first_trial <- mss_timecourse_test_first_trial |>
  group_by(lab_id, age_cohort, trial_file_name, condition, t_norm_downsampled) |>
  summarize(
    mean_target_general = mean(on_target, na.rm = TRUE),
    mean_distractor_general = mean(on_dist, na.rm = TRUE),
    sum_target_general = sum(on_target, na.rm = TRUE),
    sum_distractor_general = sum(on_dist, na.rm = TRUE),
    prop_general = sum_target_general /
      (sum_target_general + sum_distractor_general)
  )
```

Check time-course lengths across videos.

```{r}
test_data |>
  group_by(trial_file_name) |>
  summarise(
    min_t = min(t_norm),
    max_t = max(t_norm)
  )
```

```{r}
ggplot(
  ms_timecourse_test_first_trial |>
    filter(age_cohort == "adults") |>
    pivot_longer(mean_target_general:mean_distractor_general,
      names_to = "trial_type", values_to = "mean_looking"
    ),
  aes(x = t_norm_downsampled, y = mean_looking, col = trial_type)
) +
  geom_point(alpha = .1) +
  geom_smooth() +
  facet_wrap(~trial_file_name, ncol = 4)

ggplot(
  ms_timecourse_test_first_trial |>
    filter(age_cohort == "toddlers") |>
    pivot_longer(mean_target_general:mean_distractor_general,
      names_to = "trial_type", values_to = "mean_looking"
    ),
  aes(x = t_norm_downsampled, y = mean_looking, col = trial_type)
) +
  geom_point(alpha = .1) +
  geom_smooth() +
  facet_wrap(trial_file_name ~ age_cohort, ncol = 4)
```

## Timecourse with all test trials

```{r}
mss_timecourse_test <- test_data %>%
  mutate(first_trial = (trial_num == 5)) %>%
  group_by(
    lab_id, age_cohort, participant_lab_id, participant_id, participant_trial_id,
    trial_file_name, first_trial,
    bear_not_visible_ms, point_of_disambiguation,
    video_duration_ms, condition
  ) %>%
  mutate(t_norm_downsampled = floor(t_norm / 100) * 100) |>
  # filter to relevant anticipatory window
  # based on current format, t_norm == 0 is the point of disambiguation
  filter(t_norm >= -16000, t_norm <= 10000) %>%
  # filter out sections of first_trial that are too long
  filter((first_trial & t_norm <= 1500) | !first_trial) %>%
  group_by(
    age_cohort, participant_lab_id, participant_id, participant_trial_id,
    condition, first_trial, t_norm_downsampled
  ) |>
  summarize(
    on_target = mean(aoi == "target_exit", na.rm = TRUE),
    on_dist = mean(aoi == "distractor_exit", na.rm = TRUE)
  )

ms_timecourse_test <- mss_timecourse_test |>
  ungroup() |>
  group_by(age_cohort, first_trial, condition, t_norm_downsampled) |>
  summarize(
    participant_num = n(),
    mean_target = mean(on_target, na.rm = TRUE),
    sd_target = sd(on_target, na.rm = TRUE),
    se_target = sd_target / sqrt(participant_num),
    ci_target = qt(1 - (0.05 / 2), participant_num - 1) * se_target,
    ci_targetLOW = mean_target - ci_target,
    ci_targetHI = mean_target + ci_target,
    mean_distractor = mean(on_dist, na.rm = TRUE),
    sd_distractor = sd(on_dist, na.rm = TRUE),
    se_distractor = sd_distractor / sqrt(participant_num),
    ci_distractor = qt(1 - (0.05 / 2), participant_num - 1) * se_distractor,
    ci_distractorLOW = mean_distractor - ci_distractor,
    ci_distractorHI = mean_distractor + ci_distractor,
    sum_target = sum(on_target, na.rm = TRUE),
    sum_distractor = sum(on_dist, na.rm = TRUE),
    prop = sum_target / (sum_target + sum_distractor)
  )
```

```{r}
ms_timecourse_test_long <- ms_timecourse_test |>
  # pivot mean and sd looking for target and distractor longer (separate mean and sd columns in long dataset)
  pivot_longer(c(mean_target, mean_distractor, se_target, se_distractor),
    names_to = c(".value", "aoi_type"), names_sep = "_"
  ) |>
  mutate(trial_number_name = if_else(first_trial, "First Trial", "Second Trial"))

ggplot(
  filter(ms_timecourse_test_long, t_norm_downsampled <= 0),
  aes(
    x = t_norm_downsampled, y = mean,
    col = aoi_type, lty = trial_number_name
  )
) +
  # geom_point(alpha = .1) +
  geom_line() +
  geom_ribbon(aes(ymin = mean - se, ymax = mean + se, fill = aoi_type),
    alpha = .2, color = NA
  ) +
  facet_grid(condition ~ age_cohort) +
  geom_vline(xintercept = -3880, lty = 3, col = "black") +
  geom_vline(xintercept = 120, lty = 3, col = "black") +
  ggthemes::theme_few() +
  scale_fill_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  scale_color_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  scale_linetype(name = "Trial Number") +
  theme(legend.position = "bottom") +
  xlab("Time") +
  ylab("Mean Proportion Looking")
ggsave(here(plot_path, "test_timecourse_plot.png"),
  bg = "white", width = 12, height = 6
)

timecourse_test_trials <- ggplot(
  filter(ms_timecourse_test_long, t_norm_downsampled > -5000 & t_norm_downsampled <= 120),
  aes(
    x = t_norm_downsampled, y = mean,
    col = aoi_type, lty = trial_number_name
  )
) +
  # geom_point(alpha = .1) +
  geom_line() +
  geom_ribbon(aes(ymin = mean - se, ymax = mean + se, fill = aoi_type),
    alpha = .2, color = NA
  ) +
  facet_grid(condition ~ age_cohort) +
  geom_vline(xintercept = -3880, lty = 3, col = "black") +
  geom_vline(xintercept = 120, lty = 3, col = "black") +
  ggthemes::theme_few() +
  scale_fill_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  scale_color_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  scale_linetype(name = "Trial Number") +
  theme(legend.position = "bottom") +
  xlab("Time") +
  ylab("Mean Proportion Looking")
timecourse_test_trials
ggsave(here(plot_path, "test_timecourse_plot_anticipation_phase.png"),
  bg = "white", width = 12, height = 6
)
```

### With Extension

```{r}
# continued timecourse
ggplot(
  ms_timecourse_test_long,
  aes(
    x = t_norm_downsampled, y = mean,
    col = aoi_type, lty = trial_number_name
  )
) +
  # geom_point(alpha = .1) +
  geom_line() +
  geom_ribbon(aes(ymin = mean - se, ymax = mean + se, fill = aoi_type),
    alpha = .2, color = NA
  ) +
  facet_grid(condition ~ age_cohort) +
  geom_vline(xintercept = -3880, lty = 3, col = "black") +
  geom_vline(xintercept = 120, lty = 3, col = "black") +
  ggthemes::theme_few() +
  scale_fill_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  scale_color_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  scale_linetype(name = "Trial Number") +
  theme(legend.position = "bottom") +
  xlab("Time") +
  ylab("Mean Proportion Looking")

## Focus on second trial, split by consistency
mss_timecourse_test <- test_data %>%
  mutate(first_trial = (trial_num == 5)) %>%
  group_by(
    lab_id, age_cohort, participant_lab_id, participant_id, participant_trial_id,
    trial_file_name, media_name, first_trial,
    bear_not_visible_ms, point_of_disambiguation,
    video_duration_ms, condition
  ) %>%
  mutate(t_norm_downsampled = floor(t_norm / 100) * 100) |>
  # filter to relevant anticipatory window
  # based on current format, t_norm == 0 is the point of disambiguation
  filter(t_norm >= -16000, t_norm <= 10000) %>%
  # filter out sections of first_trial that are too long
  filter((first_trial & t_norm <= 1500) | !first_trial) %>%
  group_by(
    age_cohort, participant_lab_id, participant_id, participant_trial_id,
    condition, media_name, first_trial, t_norm_downsampled
  ) |>
  summarize(
    on_target = mean(aoi == "target_exit", na.rm = TRUE),
    on_dist = mean(aoi == "distractor_exit", na.rm = TRUE)
  )

ms_timecourse_test_outcome <- mss_timecourse_test |>
  separate(media_name,
    into = c("condition_name", "location_pattern", "exit_location", "outcome"),
    remove = FALSE
  ) |>
  select(-condition_name, -location_pattern, -exit_location) |>
  filter(!is.na(outcome)) |>
  ungroup() |>
  group_by(age_cohort, first_trial, condition, outcome, t_norm_downsampled) |>
  summarize(
    participant_num = n(),
    mean_target = mean(on_target, na.rm = TRUE),
    sd_target = sd(on_target, na.rm = TRUE),
    se_target = sd_target / sqrt(participant_num),
    ci_target = qt(1 - (0.05 / 2), participant_num - 1) * se_target,
    ci_targetLOW = mean_target - ci_target,
    ci_targetHI = mean_target + ci_target,
    mean_distractor = mean(on_dist, na.rm = TRUE),
    sd_distractor = sd(on_dist, na.rm = TRUE),
    se_distractor = sd_distractor / sqrt(participant_num),
    ci_distractor = qt(1 - (0.05 / 2), participant_num - 1) * se_distractor,
    ci_distractorLOW = mean_distractor - ci_distractor,
    ci_distractorHI = mean_distractor + ci_distractor,
    sum_target = sum(on_target, na.rm = TRUE),
    sum_distractor = sum(on_dist, na.rm = TRUE),
    prop = sum_target / (sum_target + sum_distractor)
  )

ms_timecourse_test_outcome_long <- ms_timecourse_test_outcome |>
  # pivot mean and sd looking for target and distractor longer (separate mean and sd columns in long dataset)
  pivot_longer(c(mean_target, mean_distractor, se_target, se_distractor),
    names_to = c(".value", "aoi_type"), names_sep = "_"
  ) |>
  mutate(trial_number_name = if_else(first_trial, "First Trial", "Second Trial"))

ggplot(
  filter(ms_timecourse_test_outcome_long, !first_trial),
  aes(
    x = t_norm_downsampled, y = mean,
    col = aoi_type, lty = outcome
  )
) +
  # geom_point(alpha = .1) +
  geom_line() +
  geom_ribbon(aes(ymin = mean - se, ymax = mean + se, fill = aoi_type),
    alpha = .2, color = NA
  ) +
  facet_grid(condition ~ age_cohort) +
  geom_vline(xintercept = -3880, lty = 3, col = "black") +
  geom_vline(xintercept = 120, lty = 3, col = "black") +
  ggthemes::theme_few() +
  scale_fill_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  scale_color_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  scale_linetype(name = "Trial Number") +
  theme(legend.position = "bottom") +
  xlab("Time") +
  ylab("Mean Proportion Looking")
```

## Fam trials

```{r}
mss_fam <- fam_data %>%
  group_by(
    lab_id, age_cohort, participant_lab_id, participant_id, participant_trial_id,
    trial_file_name
  ) %>%
  mutate(t_norm_downsampled = floor(t_norm / 500) * 500) |>
  # filter to relevant anticipatory window
  # based on current format, t_norm == 0 is the point of disambiguation
  # so we want the 4000 ms leading up, minus 120 ms of saccade/ planning time
  # check this!!!
  filter(t_norm >= -16000, t_norm <= 10000) %>%
  group_by(
    age_cohort, participant_lab_id, participant_id, participant_trial_id,
    condition, t_norm_downsampled
  ) |>
  summarize(
    on_target = mean(aoi == "target_exit", na.rm = TRUE),
    on_dist = mean(aoi == "distractor_exit", na.rm = TRUE)
  )

ms_fam <- mss_fam |>
  group_by(participant_lab_id, age_cohort, condition, t_norm_downsampled) |>
  summarize(
    target_exit = mean(on_target, na.rm = TRUE),
    distractor_exit = mean(on_dist, na.rm = TRUE),
    prop_target_exit = target_exit / (target_exit + distractor_exit)
  ) |>
  ungroup() |>
  group_by(age_cohort, condition, t_norm_downsampled) |>
  summarize(
    participant_num = n(),
    mean_target = mean(target_exit, na.rm = TRUE),
    sd_target = sd(target_exit, na.rm = TRUE),
    se_target = sd_target / sqrt(participant_num),
    ci_target = qt(1 - (0.05 / 2), participant_num - 1) * se_target,
    ci_targetLOW = mean_target - ci_target,
    ci_targetHI = mean_target + ci_target,
    mean_distractor = mean(distractor_exit, na.rm = TRUE),
    sd_distractor = sd(distractor_exit, na.rm = TRUE),
    se_distractor = sd_distractor / sqrt(participant_num),
    ci_distractor = qt(1 - (0.05 / 2), participant_num - 1) * se_distractor,
    ci_distractorLOW = mean_distractor - ci_distractor,
    ci_distractorHI = mean_distractor + ci_distractor,
    prop = mean(prop_target_exit, na.rm = TRUE)
  )
```

```{r}
ms_fam_long <- ms_fam |>
  # pivot mean and sd looking for target and distractor longer (separate mean and sd columns in long dataset)
  pivot_longer(c(mean_target, mean_distractor, se_target, se_distractor),
    names_to = c(".value", "aoi_type"), names_sep = "_"
  )

ggplot(
  ms_fam_long,
  aes(x = t_norm_downsampled, y = mean, col = aoi_type)
) +
  # geom_point(alpha = .1) +
  geom_line() +
  geom_ribbon(aes(ymin = mean - se, ymax = mean + se, fill = aoi_type),
    alpha = .2, color = NA
  ) +
  facet_grid(. ~ age_cohort) +
  geom_vline(xintercept = -3880, lty = 3, col = "black") +
  geom_vline(xintercept = 120, lty = 3, col = "black") +
  ggthemes::theme_few() +
  theme(legend.position = "bottom") +
  scale_fill_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  scale_color_manual(name = "AOI", values = c("#440154FF", "#21908CFF")) +
  xlab("Time") +
  ylab("Mean Proportion Looking")
ggsave(here(plot_path, "familiarization_timecourse_plot.png"),
  bg = "white", width = 12, height = 6
)
```

# First Look Analysis

<!-- First saccades will be determined as the first change in gaze occurring within the anticipatory time window that is directed towards one of the AOIs. The first look is then the binary variable denoting the target of this first saccade (i.e., either the correct or incorrect AOI) and is defined as the first AOI where participants fixated at for at least 150 ms, as in Rayner et al. (2009). The rationale for this definition was that, if participants are looking at a location within the tunnel exit AOIs before the anticipation period, they might have been looking there for other reasons than action prediction. We therefore count only looks that start within the anticipation period because they more unambiguously reflect action predictions. This further prevents us from running into a situation where we would include a lot of fixations on regions other than the tunnel exit AOIs because participants are looking somewhere else before the anticipation period begins. -->

## Compute first looks

### Convert to run-length encoding format

```{r}
# convert to rle data
rle_fam_data <- fam_data %>%
  filter(t_norm <= 120 & t_norm >= -3880) %>% # only pass data in anticipatory window
  group_by(
    age_cohort, age_mo, age_years_n, participant_lab_id, lab_id,
    participant_id, participant_trial_id, trial_num, condition
  ) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

rle_test_data <- test_data %>%
  filter(t_norm <= 120 & t_norm >= -3880) %>% # only pass data in anticipatory window
  group_by(
    age_cohort, age_mo, age_years_n, participant_lab_id, lab_id,
    participant_id, participant_trial_id, trial_num, condition
  ) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )
```

### Compute the first looks/ anticipatory looking

Function for computing first look and RT

Summarizing a few key decisions: 
- We compute both a first look (first valid look to the target or distractor AOIs during the anticipatory window) and a first shift (consistent with the Registered Report: starting on the AOIs does not count, there must be evidence of a shift to the AOI during the anticipatory window) 
- We ignore NAs altogether in defining shifts (this also means that if there are a lot of NAs at the beginning of the window and then the infants' first look is to the target/ distractor AOI, this is counted the same (i.e., ignored - we still need to see a shift to the AOI) as if the infant started on the target/distractor AOI. 
- For RT computation, we compute all samples up to landing on the target/ distractor AOI look and multiply by the sampling rate.

```{r}
# takes rle_data dataframe (already rle'd)
get_first_look <- function(rle_data, SAMPLING_RATE = 40,
                           MINIMUM_ANTICIPATORY_LOOK_MS = 150) {
  # end if no data
  if (is.null(rle_data$values) | is.null(rle_data$lengths) |
    sum(rle_data$values != "NA_NA") == 0) {
    return(tibble(
      first_look = NA,
      first_look_rt = NA,
      first_shift = NA,
      first_shift_rt = NA,
      shift_type = NA,
      shift_type_all = NA
    ))
  }

  # minimum look duration
  # look must be a specific duration to count (e.g. 150 ms)
  min_look_length <- ceiling(MINIMUM_ANTICIPATORY_LOOK_MS / (1000 / SAMPLING_RATE))
  # any values we want to skip as a potential looking/ landing target
  values_to_skip <- c("NA_NA")

  rle_data_idx <- rle_data |>
    # create an overall index
    mutate(idx = seq_along(values)) |>
    # create an index that skips specific values (NA_NA)
    mutate(
      include = !(values %in% values_to_skip),
      cumulative_index_skipping_nas = cumsum(include)
    ) |>
    mutate(
      idx_skip_nas = if_else(include, cumulative_index_skipping_nas, NA)
    ) |>
    select(-include, -cumulative_index_skipping_nas)

  # determine onsets
  onset_aoi <- filter(rle_data_idx, idx == 1)$values
  onset_aoi_skip_nas <- filter(rle_data_idx, idx_skip_nas == 1)$values # zero point AOI, excluding NAs

  # find the first valid look within the rle data
  first_look_rle <- rle_data_idx |>
    # filter to valid looks to target or distractor
    filter(
      values %in% c("target_exit", "distractor_exit"),
      lengths >= min_look_length
    ) |>
    # get the first look
    slice(1)

  # finds the first valid "shift" within the rle data
  first_shift_landing_rle <- rle_data_idx |>
    filter(
      idx_skip_nas != 1, # first shift landing is post the initial look location, not counting NAs
      values %in% c("target_exit", "distractor_exit"),
      lengths >= min_look_length
    ) |>
    slice(1)

  # end if no anticipatory look to the AOIs
  if (nrow(first_look_rle) == 0) {
    return(tibble(
      first_look = NA,
      first_look_rt = NA,
      first_shift = NA,
      first_shift_rt = NA,
      shift_type = "no anticipatory look",
      shift_type_all = NA
    ))
  }

  # determine first look
  first_look <- first_look_rle$values

  # rt is the number of samples happening before arrival
  # (first sample of arrival)
  # times the length of a sample
  # need to keep NAs here for valid looking times
  # MZ: we used to add 1 here but I think that might be wrong? because the first sample is 0 ms, i.e. right at the start of the window
  first_look_rt <- ((rle_data_idx |>
    filter(idx < first_look_rle$idx) |>
    pull(lengths) |> sum())) * (1000 / SAMPLING_RATE)

  # if there are valid shifts, add them
  if (nrow(first_shift_landing_rle) == 0) {
    first_shift_landing <- NA
    landing_time_rt <- NA
    shift_type <- NA
    shift_type_all <- NA
  } else {
    # consolidate shift location information
    first_shift_landing <- first_shift_landing_rle$values
    shift_type <- paste0(onset_aoi_skip_nas, "_TO_", first_shift_landing)
    shift_type_all <- rle_data_idx |>
      filter(idx_skip_nas <= first_shift_landing_rle$idx_skip_nas) |>
      pull(values) |>
      paste(collapse = "_TO_")
    # compute RT
    landing_time_rt <- ((rle_data_idx |>
      filter(idx < first_shift_landing_rle$idx) |>
      pull(lengths) |> sum())) * (1000 / SAMPLING_RATE)
  }

  return(
    tibble(
      first_look = first_look, # first valid look location, regardless of whether there was a shift to the location
      first_look_rt = first_look_rt, # reaction time for first valid look location, regardless of whether there was a shift to the location
      first_shift = first_shift_landing, # first shift to a valid look location
      first_shift_rt = landing_time_rt, # reaction time for first shift to a valid look location
      shift_type = shift_type, # shift in locations (START_LOCATION_TO_LANDING_LOCATION) for first shift to a valid look location
      shift_type_all = shift_type_all
    ) # all shifts during the anticipatory window
  )
}
```

Now compute anticipatory looking/ first looks for every trial

```{r}
# compute RTs
d_anticipatory_fam <- rle_fam_data %>%
  group_by(
    age_cohort, age_mo, age_years_n, participant_lab_id, lab_id,
    participant_id, participant_trial_id, trial_num, condition
  ) %>%
  nest() %>%
  mutate(data = lapply(data, get_first_look)) %>%
  unnest(cols = c(data))

saveRDS(d_anticipatory_fam,
  file = here(RESULTS_FOLDER, "d_anticipatory_fam.rds")
)

d_anticipatory_test <- rle_test_data %>%
  group_by(
    age_cohort, age_mo, age_years_n, participant_lab_id, lab_id,
    participant_id, participant_trial_id, trial_num, condition
  ) %>%
  nest() %>%
  mutate(data = lapply(data, get_first_look)) %>%
  unnest(cols = c(data))

saveRDS(d_anticipatory_test,
  file = here(RESULTS_FOLDER, "d_anticipatory_test.rds")
)
```

## Plot

quick and dirty averaging of the first look proportions

### Familiarization Data

```{r}
summarize_participant_familiarization_first_look <- d_anticipatory_fam %>%
  group_by(age_cohort, participant_lab_id, lab_id, participant_id, trial_num) %>%
  summarize(
    N = n(),
    prop_correct_first_look = mean(first_look == "target_exit"),
    average_rt = mean(first_look_rt),
    average_rt_correct = mean(first_look_rt[first_look == "target_exit"])
  )
saveRDS(summarize_participant_familiarization_first_look,
  file = here(RESULTS_FOLDER, "summarize_participant_familiarization_first_look.rds")
)

# check N, SEs, CIs, might not be quite right yet
summarize_overall_familiarization_first_look <- summarize_participant_familiarization_first_look %>%
  group_by(age_cohort, trial_num) %>%
  summarize(
    N = sum(!is.na(prop_correct_first_look)),
    prop_target_first_look = mean(prop_correct_first_look, na.rm = T),
    sd_target_first_look = sd(prop_correct_first_look, na.rm = T),
    se_target_first_look = sd_target_first_look / sqrt(N),
    lower_ci = prop_target_first_look - qt(1 - (0.05 / 2), N - 1) * se_target_first_look,
    upper_ci = prop_target_first_look + qt(1 - (0.05 / 2), N - 1) * se_target_first_look
  )

ggplot(
  filter(d_anticipatory_fam, !is.na(first_look)),
  aes(trial_num, fill = first_look)
) +
  geom_bar(position = "fill") +
  facet_wrap(~age_cohort)

summarize_overall_familiarization_first_look %>%
  knitr::kable()

saveRDS(summarize_overall_familiarization_first_look,
  file = here(RESULTS_FOLDER, "summary_fam_fl_overall.rds")
)

# summarize across trials
summarize_participant_familiarization_first_look_across_trials <- d_anticipatory_fam %>%
  group_by(age_cohort, participant_lab_id, lab_id, participant_id) %>%
  summarize(
    N = n(),
    prop_correct_first_look = mean(first_look == "target_exit", na.rm = TRUE),
    average_rt = mean(first_look_rt, na.rm = TRUE),
    average_rt_correct = mean(first_look_rt[first_look == "target_exit"], na.rm = TRUE)
  )
saveRDS(summarize_participant_familiarization_first_look_across_trials,
  file = here(RESULTS_FOLDER, "summarize_participant_familiarization_first_look_across_trials.rds")
)

summarize_overall_familiarization_first_look_across_trials <- summarize_participant_familiarization_first_look_across_trials %>%
  group_by(age_cohort) %>%
  summarize(
    N = sum(!is.na(prop_correct_first_look)),
    prop_target_first_look = mean(prop_correct_first_look, na.rm = T),
    sd_target_first_look = sd(prop_correct_first_look, na.rm = T),
    se_target_first_look = sd_target_first_look / sqrt(N),
    lower_ci = prop_target_first_look - qt(1 - (0.05 / 2), N - 1) * se_target_first_look,
    upper_ci = prop_target_first_look + qt(1 - (0.05 / 2), N - 1) * se_target_first_look,
    t_test = list(broom::tidy(t.test(prop_correct_first_look, alternative = "two.sided", mu = 0.5)))
  ) %>%
  mutate(
    p.value = purrr::map(t_test, ~ select(.x, c("p.value", "parameter", "statistic")))
  ) %>%
  select(-t_test) %>%
  unnest(p.value) %>%
  rename(
    tval = statistic,
    df = parameter
  )

saveRDS(summarize_overall_familiarization_first_look_across_trials,
  file = here(RESULTS_FOLDER, "summarize_overall_familiarization_first_look_across_trials.rds")
)
```

```{r}
overall_fl_fam <- ggplot(
  summarize_overall_familiarization_first_look,
  aes(trial_num, prop_target_first_look)) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0) +
  geom_point(size = 5) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  facet_wrap(~age_cohort) +
  theme_cowplot() +
  ggtitle("Familiarization") +
  # theme(strip.background = element_blank(),
  # strip.text.x = element_blank())+
  geom_smooth(
    data = summarize_participant_familiarization_first_look,
    aes(y = prop_correct_first_look), method = "lm") +
  theme(legend.position = "none") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  xlab("Trial Number") +
  ylim(0, 1) +
  ylab("First Look to Target Exit")
overall_fl_fam
ggsave(here(plot_path, "overall_fam_trials_first_look.png"),
  bg = "white", width = 9, height = 6
)
```
### Test Data

```{r}
summarize_participant_test_first_look <- d_anticipatory_test %>%
  group_by(age_cohort, participant_lab_id, lab_id, participant_id, condition) %>%
  summarize(
    N = n(),
    prop_correct_first_look = mean(first_look == "target_exit"),
    average_rt = mean(first_look_rt),
    average_rt_correct = mean(first_look_rt[first_look == "target_exit"])
  )
saveRDS(summarize_participant_test_first_look,
  file = here(RESULTS_FOLDER, "summarize_participant_test_first_look.rds")
)

# check N, SEs, CIs, might not be quite right yet
summarize_overall_test_first_look <- summarize_participant_test_first_look %>%
  group_by(age_cohort, condition) %>%
  summarize(
    N = sum(!is.na(prop_correct_first_look)),
    prop_target_first_look = mean(prop_correct_first_look, na.rm = T),
    sd_target_first_look = sd(prop_correct_first_look, na.rm = T),
    se_target_first_look = sd_target_first_look / sqrt(N),
    lower_ci = prop_target_first_look - qt(1 - (0.05 / 2), N - 1) * se_target_first_look,
    upper_ci = prop_target_first_look + qt(1 - (0.05 / 2), N - 1) * se_target_first_look
  )

saveRDS(summarize_overall_test_first_look,
  file = here(RESULTS_FOLDER, "summary_test_fl_overall.rds")
)

ggplot(
  filter(d_anticipatory_test, !is.na(first_look)),
  aes(condition, fill = first_look)
) +
  geom_bar(position = "fill") +
  facet_wrap(~age_cohort)

ggplot(
  summarize_overall_test_first_look,
  aes(condition, prop_target_first_look, color = condition)
) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0) +
  geom_point(size = 3) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  facet_wrap(~age_cohort) +
  theme_cowplot() +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "none") +
  ylim(0, 1) +
  ylab("Proportion First Look to Target Exit")
```

#### First Trial Only

```{r}
summarize_participant_test_first_look_first_trial <- d_anticipatory_test %>%
  filter(trial_num == 5) %>%
  group_by(age_cohort, participant_lab_id, lab_id, participant_id,age_years_n,age_mo, condition) %>%
  summarize(
    N = n(),
    prop_correct_first_look = mean(first_look == "target_exit"),
    average_rt = mean(first_look_rt),
    average_rt_correct = mean(first_look_rt[first_look == "target_exit"])
  )

saveRDS(summarize_participant_test_first_look_first_trial,
  file = here(RESULTS_FOLDER, "summarize_participant_test_first_look_first_trial.rds")
)

# check N, SEs, CIs, might not be quite right yet
summarize_overall_test_first_look_first_trial <- summarize_participant_test_first_look_first_trial %>%
  group_by(age_cohort, condition) %>%
  summarize(
    N = sum(!is.na(prop_correct_first_look)),
    prop_target_first_look = mean(prop_correct_first_look, na.rm = T),
    sd_target_first_look = sd(prop_correct_first_look, na.rm = T),
    se_target_first_look = sd_target_first_look / sqrt(N),
    lower_ci = prop_target_first_look - qt(1 - (0.05 / 2), N - 1) * se_target_first_look,
    upper_ci = prop_target_first_look + qt(1 - (0.05 / 2), N - 1) * se_target_first_look
  )

saveRDS(summarize_overall_test_first_look_first_trial,
  file = here(RESULTS_FOLDER, "summarize_overall_test_first_look_first_trial.rds")
)


ggplot(
  filter(d_anticipatory_test, !is.na(first_look) & trial_num == 5),
  aes(condition, fill = first_look)
) +
  geom_bar(position = "fill") +
  facet_wrap(~age_cohort)

overall_fl_test <- ggplot(
  summarize_overall_test_first_look_first_trial,
  aes(condition, prop_target_first_look, color = condition)
) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0) +
  geom_point(size = 5) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  facet_wrap(~age_cohort) +
  theme_cowplot() +
  ggtitle("Test") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "none") +
  ylim(0, 1) +
  ylab("First Look to Target Exit\n(First Trial Only)")
overall_fl_test
ggsave(here(plot_path, "overall_test_trial_first_look_first_trial.png"),
  bg = "white", width = 9, height = 6
)
```

#### Plot by Toddler Age

##### Continuous Age

```{r}
ggplot(
  filter(summarize_participant_test_first_look_first_trial,age_cohort=="toddlers"),
  aes(age_mo,prop_correct_first_look, color = condition)
) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  geom_smooth(method="loess")+
  theme_cowplot() +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "none") +
  ylim(0, 1) +
  xlab("Age (months)")+
  ylab("First Look to Target Exit\n(First Trial Only)")
ggsave(here(plot_path, "overall_test_trial_first_look_first_trial_age_continuous.png"),bg = "white", width = 9, height = 6)
```

##### Age Bins

```{r}
summarize_participant_test_first_look_first_trial <- summarize_participant_test_first_look_first_trial %>%
  mutate(
    age_bin_2m = case_when(
      age_cohort == "toddlers" & age_mo >= 18 & age_mo < 20 ~ "18-19 months",
      age_cohort == "toddlers" & age_mo >= 20 & age_mo < 22 ~ "20-21 months",
      age_cohort == "toddlers" & age_mo >= 22 & age_mo < 24 ~ "22-23 months",
      age_cohort == "toddlers" & age_mo >= 24 & age_mo < 26 ~ "24-25 months",
      age_cohort == "toddlers" & age_mo >= 26 & age_mo < 28 ~ ">26 months",
      TRUE ~ NA_character_
    )
  ) %>%
  mutate(
    age_bin = case_when(
      age_cohort == "toddlers" & age_mo >= 18 & age_mo < 19 ~ "18 mos",
      age_cohort == "toddlers" & age_mo >= 19 & age_mo < 20 ~ "19 mos",
      age_cohort == "toddlers" & age_mo >= 20 & age_mo < 21 ~ "20 mos",
      age_cohort == "toddlers" & age_mo >= 21 & age_mo < 22 ~ "21 mos",
      age_cohort == "toddlers" & age_mo >= 22 & age_mo < 23 ~ "22 mos",
      age_cohort == "toddlers" & age_mo >= 23 & age_mo < 24 ~ "23 mos",
      age_cohort == "toddlers" & age_mo >= 24 & age_mo < 25 ~ "24 mos",
      age_cohort == "toddlers" & age_mo >= 25 & age_mo < 26 ~ "25 mos",
      age_cohort == "toddlers" & age_mo >= 26 ~ "26 mos",
      TRUE ~ NA_character_
    )
  )

summarize_overall_test_first_look_first_trial_age_bins <- summarize_participant_test_first_look_first_trial %>%
  group_by(age_cohort, age_bin, condition) %>%
  summarize(
    N = sum(!is.na(prop_correct_first_look)),
    prop_target_first_look = mean(prop_correct_first_look, na.rm = T),
    sd_target_first_look = sd(prop_correct_first_look, na.rm = T),
    se_target_first_look = sd_target_first_look / sqrt(N),
    lower_ci = prop_target_first_look - qt(1 - (0.05 / 2), N - 1) * se_target_first_look,
    upper_ci = prop_target_first_look + qt(1 - (0.05 / 2), N - 1) * se_target_first_look
  )

overall_fl_test_age_bin <- ggplot(
  filter(summarize_overall_test_first_look_first_trial_age_bins,age_cohort=="toddlers"),
  aes(condition, prop_target_first_look, color = condition)
) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0) +
  geom_point(size = 5) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  facet_wrap(~age_cohort) +
  theme_cowplot() +
  ggtitle("Test") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "none") +
  ylim(0, 1) +
  ylab("First Look to Target Exit\n(First Trial Only)")+
  facet_wrap(~age_bin,ncol=3)
overall_fl_test_age_bin
ggsave(here(plot_path, "overall_test_trial_first_look_first_trial_age_bins.png"),
  bg = "white", width = 9, height = 6
)
```

## Main Model

### Familiarization Data

#### Toddlers

```{r, eval = FIT_BAYES_MODELS}
# set the prior
priors <- c(
  set_prior("normal(0, 2)", class = "Intercept"), # uniform distribution for intercept
  set_prior("normal(0, 2)", class = "b"), # normal distribution for fixed-effect coefficients
  set_prior("normal(0, .1)", class = "sd"), # normal distribution for sd/ random effects
  set_prior("lkj(2)", class = "L")
) # lkj distribution for covariance matrix/Cholesky Factor

d_anticipatory_fam <- d_anticipatory_fam %>%
  mutate(familiarization_trial_num_4 = trial_num - 4)

bm_fam_first_look_toddlers <- brm(
  first_look ~ 1 + familiarization_trial_num_4 +
    (1 + familiarization_trial_num_4 | lab_id) +
    (1 + familiarization_trial_num_4 | participant_lab_id),
  family = bernoulli(link = "logit"),
  prior = priors,
  save_pars = save_pars(all = TRUE),
  filter(d_anticipatory_fam, age_cohort == "toddlers"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_fam_first_look_toddlers)
# prior_summary(bm_fam_first_look_toddlers)

saveRDS(bm_fam_first_look_toddlers,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_toddlers.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_first_look_toddlers <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_toddlers.rds"))
```

Organize table in a tidy format

```{r}
bm_fam_fl_toddlers_tidy_summary <- as_tibble(summary(bm_fam_first_look_toddlers)$fixed,rownames=NA) %>% 
  rownames_to_column("term") %>% 
  rename(
    estimate = Estimate,
    est_error = Est.Error,
    lower_ci = `l-95% CI`,
    upper_ci = `u-95% CI`,
    rhat=Rhat
  ) %>%
  select(term,estimate,est_error,lower_ci,upper_ci,rhat)

saveRDS(bm_fam_fl_toddlers_tidy_summary,
  file = here(RESULTS_FOLDER, "bm_fam_fl_toddlers_model_summary.rds")
)
```

Summarize outcomes

Intercept

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_fam_first_look_toddlers_intercept_effect <- bm_fam_first_look_toddlers %>%
  spread_draws(b_Intercept) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_first_look_toddlers_intercept_effect,
  file = here(RESULTS_FOLDER, "bm_fam_first_look_toddlers_intercept_effect.rds")
)
```

Trial Number

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_fam_first_look_toddlers_trial_number_effect <- bm_fam_first_look_toddlers %>%
  spread_draws(b_familiarization_trial_num_4) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_first_look_toddlers_trial_number_effect,
  file = here(RESULTS_FOLDER, "bm_fam_first_look_toddlers_trial_number_effect.rds")
)
```

Compute Bayes factor approach

```{r, eval = FIT_BAYES_MODELS}
bm_fam_first_look_toddlers_null <- update(bm_fam_first_look_toddlers, formula = ~ . - 1) # remove intercept
summary(bm_fam_first_look_toddlers_null)

saveRDS(bm_fam_first_look_toddlers_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_toddlers_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_first_look_toddlers_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_toddlers_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
fam_m_comparison_FL_toddlers <- brms::bayes_factor(
  bm_fam_first_look_toddlers, bm_fam_first_look_toddlers_null
)

saveRDS(fam_m_comparison_FL_toddlers,
  file = here(RESULTS_FOLDER, "fam_m_comparison_FL_toddlers.rds")
)
```

```{r}
# remove Bayes model fits
rm(bm_fam_first_look_toddlers)
rm(bm_fam_first_look_toddlers_null)
```


Because the BF is sensitive to the choice of prior, we will also run a secondary analysis with a less informative prior: fixed effect coefficients chosen from a normal distribution with mean 0 and SD of 3, and random effect standard deviations drawn from a normal prior with a mean of 0 and SD of 0.5. 


```{r, eval = FIT_BAYES_MODELS}
# 2nd set of priors
priors_less_informative <- c(
  set_prior("normal(0, 3)", class = "Intercept"), # uniform distribution for intercept
  set_prior("normal(0, 3)", class = "b"), # normal distribution for fixed-effect coefficients
  set_prior("normal(0, .5)", class = "sd"), # normal distribution for sd/ random effects
  set_prior("lkj(2)", class = "L")
) # lkj distribution for covariance matrix/Cholesky Factor

bm_fam_first_look_toddlers_less_inf_prior <- brm(
  first_look ~ 1 + familiarization_trial_num_4 +
    (1 + familiarization_trial_num_4 | lab_id) +
    (1 + familiarization_trial_num_4 | participant_lab_id),
  family = bernoulli(link = "logit"),
  prior = priors_less_informative,
  save_pars = save_pars(all = TRUE),
  filter(d_anticipatory_fam, age_cohort == "toddlers"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_fam_first_look_toddlers_less_inf_prior)
# prior_summary(bm_fam_first_look_toddlers_less_inf_prior)

saveRDS(bm_fam_first_look_toddlers_less_inf_prior,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_toddlers_less_inf_prior.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_first_look_toddlers_less_inf_prior <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_toddlers_less_inf_prior.rds"))
```

Summarize outcomes

Intercept

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_fam_first_look_toddlers_less_inf_prior_intercept_effect <- bm_fam_first_look_toddlers_less_inf_prior %>%
  spread_draws(b_Intercept) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_first_look_toddlers_less_inf_prior_intercept_effect,
  file = here(RESULTS_FOLDER, "bm_fam_first_look_toddlers_less_inf_prior_intercept_effect.rds")
)
```

Trial Number

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_fam_first_look_toddlers_less_inf_prior_trial_number_effect <- bm_fam_first_look_toddlers_less_inf_prior %>%
  spread_draws(b_familiarization_trial_num_4) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_first_look_toddlers_less_inf_prior_trial_number_effect,
  file = here(RESULTS_FOLDER, "bm_fam_first_look_toddlers_less_inf_prior_trial_number_effect.rds")
)
```

Compute Bayes factor approach

```{r, eval = FIT_BAYES_MODELS}
bm_fam_first_look_toddlers_less_inf_prior_null <- update(bm_fam_first_look_toddlers_less_inf_prior, formula = ~ . - 1) # remove intercept
summary(bm_fam_first_look_toddlers_less_inf_prior_null)

saveRDS(bm_fam_first_look_toddlers_less_inf_prior_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_toddlers_less_inf_prior_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_first_look_toddlers_less_inf_prior_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_toddlers_less_inf_prior_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
fam_m_comparison_FL_toddlers_less_inf_prior <- brms::bayes_factor(
  bm_fam_first_look_toddlers_less_inf_prior,
  bm_fam_first_look_toddlers_less_inf_prior_null
)

saveRDS(fam_m_comparison_FL_toddlers_less_inf_prior,
  file = here(RESULTS_FOLDER, "fam_m_comparison_FL_toddlers_less_inf_prior.rds")
)
```

```{r}
# remove Bayes model fits
rm(bm_fam_first_look_toddlers_less_inf_prior)
rm(bm_fam_first_look_toddlers_less_inf_prior_null)
```

#### Adults

```{r, eval = FIT_BAYES_MODELS}
bm_fam_first_look_adults <- brm(
  first_look ~ 1 + familiarization_trial_num_4 +
    (1 + familiarization_trial_num_4 | lab_id) +
    (1 + familiarization_trial_num_4 | participant_lab_id),
  family = bernoulli(link = "logit"),
  prior = priors,
  save_pars = save_pars(all = TRUE),
  filter(d_anticipatory_fam, age_cohort == "adults"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_fam_first_look_adults)
# prior_summary(bm_fam_first_look_adults)

saveRDS(bm_fam_first_look_adults,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_adults.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_first_look_adults <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_adults.rds"))
```

Organize table in a tidy format

```{r}
bm_fam_fl_adults_tidy_summary <- as_tibble(summary(bm_fam_first_look_adults)$fixed,rownames=NA) %>% 
  rownames_to_column("term") %>% 
  rename(
    estimate = Estimate,
    est_error = Est.Error,
    lower_ci = `l-95% CI`,
    upper_ci = `u-95% CI`,
    rhat=Rhat
  ) %>%
  select(term,estimate,est_error,lower_ci,upper_ci,rhat)

saveRDS(bm_fam_fl_adults_tidy_summary,
  file = here(RESULTS_FOLDER, "bm_fam_fl_adults_model_summary.rds")
)
```

Summarize outcomes

Intercept

```{r}
# get main coefficient estimate and HDI
bm_fam_first_look_adults_intercept_effect <- bm_fam_first_look_adults %>%
  spread_draws(b_Intercept) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_first_look_adults_intercept_effect,
  file = here(RESULTS_FOLDER, "bm_fam_first_look_adults_intercept_effect.rds")
)
```

Trial Number

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_fam_first_look_adults_trial_number_effect <- bm_fam_first_look_adults %>%
  spread_draws(b_familiarization_trial_num_4) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_first_look_adults_trial_number_effect,
  file = here(RESULTS_FOLDER, "bm_fam_first_look_adults_trial_number_effect.rds")
)
```

Compute Bayes factor approach

```{r, eval = FIT_BAYES_MODELS}
bm_fam_first_look_adults_null <- update(bm_fam_first_look_adults, formula = ~ . - 1) # remove intercept
summary(bm_fam_first_look_adults_null)

saveRDS(bm_fam_first_look_adults_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_adults_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_first_look_adults_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_adults_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
fam_m_comparison_FL_adults <- brms::bayes_factor(
  bm_fam_first_look_adults, bm_fam_first_look_adults_null
)

saveRDS(fam_m_comparison_FL_adults,
  file = here(RESULTS_FOLDER, "fam_m_comparison_FL_adults.rds")
)
```

```{r}
# remove Bayes model fits
rm(bm_fam_first_look_adults)
rm(bm_fam_first_look_adults_null)
```

Less informative prior as a robustness check

```{r, eval = FIT_BAYES_MODELS}
bm_fam_first_look_adults_less_inf_prior <- brm(
  first_look ~ 1 + familiarization_trial_num_4 +
    (1 + familiarization_trial_num_4 | lab_id) +
    (1 + familiarization_trial_num_4 | participant_lab_id),
  family = bernoulli(link = "logit"),
  prior = priors_less_informative,
  save_pars = save_pars(all = TRUE),
  filter(d_anticipatory_fam, age_cohort == "adults"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_fam_first_look_adults_less_inf_prior)
# prior_summary(bm_fam_first_look_adults_less_inf_prior)

saveRDS(bm_fam_first_look_adults_less_inf_prior,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_adults_less_inf_prior.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_first_look_adults_less_inf_prior <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_adults_less_inf_prior.rds"))
```

Summarize outcomes

Intercept

```{r}
# get main coefficient estimate and HDI
bm_fam_first_look_adults_less_inf_prior_intercept_effect <- bm_fam_first_look_adults_less_inf_prior %>%
  spread_draws(b_Intercept) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_first_look_adults_less_inf_prior_intercept_effect,
  file = here(RESULTS_FOLDER, "bm_fam_first_look_adults_less_inf_prior_intercept_effect.rds")
)
```

Trial Number

```{r}
# get main coefficient estimate and HDI
bm_fam_first_look_adults_less_inf_prior_trial_number_effect <- bm_fam_first_look_adults_less_inf_prior %>%
  spread_draws(b_familiarization_trial_num_4) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_fam_first_look_adults_less_inf_prior_trial_number_effect,
  file = here(RESULTS_FOLDER, "bm_fam_first_look_adults_less_inf_prior_trial_number_effect.rds")
)
```

Compute Bayes factor approach

```{r, eval = FIT_BAYES_MODELS}
bm_fam_first_look_adults_less_inf_prior_null <- update(bm_fam_first_look_adults_less_inf_prior, formula = ~ . - 1) # remove intercept
summary(bm_fam_first_look_adults_less_inf_prior_null)

saveRDS(bm_fam_first_look_adults_less_inf_prior_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_adults_less_inf_prior_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_fam_first_look_adults_less_inf_prior_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_fam_first_look_adults_less_inf_prior_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
fam_m_comparison_FL_adults_less_inf_prior <- brms::bayes_factor(
  bm_fam_first_look_adults_less_inf_prior,
  bm_fam_first_look_adults_less_inf_prior_null
)

saveRDS(fam_m_comparison_FL_adults_less_inf_prior,
  file = here(RESULTS_FOLDER, "fam_m_comparison_FL_adults_less_inf_prior.rds")
)
```

```{r}
# remove Bayes model fits
rm(bm_fam_first_look_adults_less_inf_prior)
rm(bm_fam_first_look_adults_less_inf_prior_null)
```

### Test Data

Fitting the main Bayesian hierarchical model testing the effect of condition (ignorance vs. knowledge) on first-trial first looks during the anticipatory window.

```{r}
# select first test trial
test_first_look_first_trial <- d_anticipatory_test %>%
  filter(trial_num == 5) %>%
  group_by(age_cohort, age_mo, age_years_n, participant_lab_id, lab_id, participant_id, condition) %>%
  summarize(
    N = n(),
    correct_first_look = mean(first_look == "target_exit")
  ) %>%
  ungroup() %>%
  # center age and condition
  mutate(
    age_mo_c = age_mo - mean(age_mo, na.rm = TRUE),
    condition_c = case_when(
      condition == "knowledge" ~ -0.5,
      condition == "ignorance" ~ 0.5
    )
  )

# both test trials
d_anticipatory_test <- d_anticipatory_test %>%
  mutate(correct_first_look = mean(first_look == "target_exit")) %>%
  ungroup() %>%
  # center age and condition
  mutate(
    age_mo_c = age_mo - mean(age_mo, na.rm = TRUE),
    condition_c = case_when(
      condition == "knowledge" ~ -0.5,
      condition == "ignorance" ~ 0.5
    )
  )
```

#### Toddlers

```{r, eval = FIT_BAYES_MODELS}
# set the prior
priors <- c(
  set_prior("normal(0, 2)", class = "Intercept"), # uniform distribution for intercept
  set_prior("normal(0, 2)", class = "b"), # normal distribution for fixed-effect coefficients
  set_prior("normal(0, .1)", class = "sd"), # normal distribution for sd/ random effects
  set_prior("lkj(2)", class = "L")
) # lkj distribution for covariance matrix/Cholesky Factor?

bm_test_first_look_toddlers <- brm(
  correct_first_look ~ 1 + condition_c + age_mo_c + condition_c * age_mo_c +
    (1 + condition_c + age_mo_c + condition_c * age_mo_c | lab_id),
  family = bernoulli(link = "logit"),
  prior = priors,
  save_pars = save_pars(all = TRUE),
  filter(test_first_look_first_trial, age_cohort == "toddlers"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_test_first_look_toddlers)
# prior_summary(bm_test_first_look_toddlers)

saveRDS(bm_test_first_look_toddlers,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_test_first_look_toddlers <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers.rds"))
```

```{r}
# quick and dirty binomial test just for exploratory purposes
sum_correct_first_looks_knowledge <- sum(test_first_look_first_trial$correct_first_look[test_first_look_first_trial$age_cohort == "toddlers" & test_first_look_first_trial$condition == "knowledge"], na.rm = TRUE)
sum_total_first_looks_knowledge <- sum(!is.na(test_first_look_first_trial$correct_first_look[test_first_look_first_trial$age_cohort == "toddlers" & test_first_look_first_trial$condition == "knowledge"]))
binom.test(sum_correct_first_looks_knowledge, sum_total_first_looks_knowledge, alternative = "two.sided", p = 0.5)
```

Organize table in a tidy format

```{r}
bm_test_fl_toddlers_tidy_summary <- as_tibble(summary(bm_test_first_look_toddlers)$fixed,rownames=NA) %>% 
  rownames_to_column("term") %>% 
  rename(
    estimate = Estimate,
    est_error = Est.Error,
    lower_ci = `l-95% CI`,
    upper_ci = `u-95% CI`,
    rhat=Rhat
  ) %>%
  select(term,estimate,est_error,lower_ci,upper_ci,rhat)

saveRDS(bm_test_fl_toddlers_tidy_summary,
  file = here(RESULTS_FOLDER, "bm_test_fl_toddlers_model_summary.rds")
)
```

Summarize outcomes

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_test_first_look_toddlers_condition_effect <- bm_test_first_look_toddlers %>%
  spread_draws(b_condition_c) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_test_first_look_toddlers_condition_effect,
  file = here(RESULTS_FOLDER, "bm_test_first_look_toddlers_condition_effect.rds")
)

bm_test_first_look_toddlers_age_effect <- bm_test_first_look_toddlers %>%
  spread_draws(b_age_mo_c) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_test_first_look_toddlers_age_effect,
  file = here(RESULTS_FOLDER, "bm_test_first_look_toddlers_age_effect.rds")
)

bm_test_first_look_toddlers_condition_age_interaction <- bm_test_first_look_toddlers %>%
  spread_draws(`b_condition_c:age_mo_c`) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_test_first_look_toddlers_condition_age_interaction,
  file = here(RESULTS_FOLDER, "bm_test_first_look_toddlers_condition_age_interaction.rds")
)
```

Compute Bayes Factor (bridge sampling approach) - Condition Effect

```{r, eval = FIT_BAYES_MODELS}
bm_test_first_look_toddlers_null <- update(bm_test_first_look_toddlers, formula = ~ . - condition_c)
summary(bm_test_first_look_toddlers_null)

# cache
saveRDS(bm_test_first_look_toddlers_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_test_first_look_toddlers_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
test_m_comparison_FL_toddlers <- brms::bayes_factor(
  bm_test_first_look_toddlers, bm_test_first_look_toddlers_null
)

saveRDS(test_m_comparison_FL_toddlers,
  file = here(RESULTS_FOLDER, "test_m_comparison_FL_toddlers.rds")
)
```

Compute Bayes Factor (bridge sampling approach) - Condition*Age Interaction Effect

```{r, eval = FIT_BAYES_MODELS}
bm_test_first_look_toddlers_interaction_null <- update(bm_test_first_look_toddlers, formula = ~ . - condition_c * age_mo_c)
summary(bm_test_first_look_toddlers_interaction_null)

saveRDS(bm_test_first_look_toddlers_interaction_null, file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers_interaction_null.rds"))
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_test_first_look_toddlers_interaction_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers_interaction_null.rds"))
```


```{r, eval = COMPUTE_BAYES_FACTORS}
test_m_comparison_FL_toddlers_interaction <- brms::bayes_factor(
  bm_test_first_look_toddlers,
  bm_test_first_look_toddlers_interaction_null
)

saveRDS(test_m_comparison_FL_toddlers_interaction, file = here(RESULTS_FOLDER, "test_m_comparison_FL_toddlers_interaction.rds"))
```

```{r}
# remove Bayes model fits
rm(bm_test_first_look_toddlers)
rm(bm_test_first_look_toddlers_null)
rm(bm_test_first_look_interaction_null)
```

Less informative priors

```{r, eval = FIT_BAYES_MODELS}
bm_test_first_look_toddlers_less_inf_prior <- brm(
  correct_first_look ~ 1 + condition_c + age_mo_c + condition_c * age_mo_c +
    (1 + condition_c + age_mo_c + condition_c * age_mo_c | lab_id),
  family = bernoulli(link = "logit"),
  prior = priors_less_informative,
  save_pars = save_pars(all = TRUE),
  filter(test_first_look_first_trial, age_cohort == "toddlers"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_test_first_look_toddlers_less_inf_prior)
# prior_summary(bm_test_first_look_toddlers_less_inf_prior)

saveRDS(bm_test_first_look_toddlers_less_inf_prior,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers_less_inf_prior.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_test_first_look_toddlers_less_inf_prior <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers_less_inf_prior.rds"))
```

```{r}
# quick and dirty binomial test just for exploratory purposes
sum_correct_first_looks_knowledge <- sum(test_first_look_first_trial$correct_first_look[test_first_look_first_trial$age_cohort == "toddlers" & test_first_look_first_trial$condition == "knowledge"], na.rm = TRUE)
sum_total_first_looks_knowledge <- sum(!is.na(test_first_look_first_trial$correct_first_look[test_first_look_first_trial$age_cohort == "toddlers" & test_first_look_first_trial$condition == "knowledge"]))
binom.test(sum_correct_first_looks_knowledge, sum_total_first_looks_knowledge, alternative = "two.sided", p = 0.5)
```


Summarize outcomes

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_test_first_look_toddlers_less_inf_prior_condition_effect <- bm_test_first_look_toddlers_less_inf_prior %>%
  spread_draws(b_condition_c) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_test_first_look_toddlers_less_inf_prior_condition_effect,
  file = here(RESULTS_FOLDER, "bm_test_first_look_toddlers_less_inf_prior_condition_effect.rds")
)
```

Alternate Bayes factor approach

```{r, eval = FIT_BAYES_MODELS}
bm_test_first_look_toddlers_less_inf_prior_null <- update(bm_test_first_look_toddlers_less_inf_prior, formula = ~ . - condition_c)
summary(bm_test_first_look_toddlers_less_inf_prior_null)

saveRDS(bm_test_first_look_toddlers_less_inf_prior_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers_less_inf_prior_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_test_first_look_toddlers_less_inf_prior_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_toddlers_less_inf_prior_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
test_m_comparison_FL_toddlers_less_inf_prior <- brms::bayes_factor(
  bm_test_first_look_toddlers_less_inf_prior,
  bm_test_first_look_toddlers_less_inf_prior_null
)

saveRDS(test_m_comparison_FL_toddlers_less_inf_prior,
  file = here(RESULTS_FOLDER, "test_m_comparison_FL_toddlers_less_inf_prior.rds")
)
```

```{r}
# remove Bayes model fits
rm(bm_test_first_look_toddlers_less_inf_prior)
rm(bm_test_first_look_toddlers_less_inf_prior_null)
```


#### Adults

```{r, eval = FIT_BAYES_MODELS}
bm_test_first_look_adults <- brm(
  correct_first_look ~ 1 + condition_c + (1 + condition_c | lab_id),
  family = bernoulli(link = "logit"),
  prior = priors,
  save_pars = save_pars(all = TRUE),
  filter(test_first_look_first_trial, age_cohort == "adults"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_test_first_look_adults)
# prior_summary(bm_test_first_look_adults)

saveRDS(bm_test_first_look_adults,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_adults.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_test_first_look_adults <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_adults.rds"))
```

Organize table in a tidy format

```{r}
bm_test_fl_adults_tidy_summary <- as_tibble(summary(bm_test_first_look_adults)$fixed,rownames=NA) %>% 
  rownames_to_column("term") %>% 
  rename(
    estimate = Estimate,
    est_error = Est.Error,
    lower_ci = `l-95% CI`,
    upper_ci = `u-95% CI`,
    rhat=Rhat
  ) %>%
  select(term,estimate,est_error,lower_ci,upper_ci,rhat)

saveRDS(bm_test_fl_adults_tidy_summary,
  file = here(RESULTS_FOLDER, "bm_test_fl_adults_model_summary.rds")
)
```
Summarize outcomes

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_test_first_look_adults_condition_effect <- bm_test_first_look_adults %>%
  spread_draws(b_condition_c) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_test_first_look_adults_condition_effect,
  file = here(RESULTS_FOLDER, "bm_test_first_look_adults_condition_effect.rds")
)
```

Compute Bayes Factor (bridge sampling approach) - Condition Effect

```{r, eval = FIT_BAYES_MODELS}
bm_test_first_look_adults_null <- update(bm_test_first_look_adults, formula = ~ . - condition_c)
summary(bm_test_first_look_adults_null)

saveRDS(bm_test_first_look_adults_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_adults_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_test_first_look_adults_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_adults_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
test_m_comparison_FL_adults <- brms::bayes_factor(
  bm_test_first_look_adults, bm_test_first_look_adults_null
)

saveRDS(test_m_comparison_FL_adults,
  file = here(RESULTS_FOLDER, "test_m_comparison_FL_adults.rds")
)
```

```{r}
# remove Bayes model fits
rm(bm_test_first_look_adults)
rm(bm_test_first_look_adults_null)
```

Less informative priors

```{r, eval = FIT_BAYES_MODELS}
bm_test_first_look_adults_less_inf_prior <- brm(
  correct_first_look ~ 1 + condition_c + (1 + condition_c | lab_id),
  family = bernoulli(link = "logit"),
  prior = priors_less_informative,
  save_pars = save_pars(all = TRUE),
  filter(test_first_look_first_trial, age_cohort == "adults"),
  warmup = 1000,
  iter = 10000,
  chains = 4,
  cores = 4,
  seed = 123,
  sample_prior = TRUE,
  control = list(adapt_delta = 0.99, stepsize = .1, max_treedepth = 12)
)
summary(bm_test_first_look_adults_less_inf_prior)
# prior_summary(bm_test_first_look_adults_less_inf_prior)

saveRDS(bm_test_first_look_adults_less_inf_prior,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_adults_less_inf_prior.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_test_first_look_adults_less_inf_prior <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_adults_less_inf_prior.rds"))
```

Summarize outcomes

```{r}
# get_variables(bm_aoi_toddlers)
# get main coefficient estimate and HDI
bm_test_first_look_adults_less_inf_prior_condition_effect <- bm_test_first_look_adults_less_inf_prior %>%
  spread_draws(b_condition_c) %>%
  mean_hdi(.width = 0.95)

# cache
saveRDS(bm_test_first_look_adults_less_inf_prior_condition_effect,
  file = here(RESULTS_FOLDER, "bm_test_first_look_adults_less_inf_prior_condition_effect.rds")
)
```

Compute Bayes Factor (bridge sampling approach) - Condition Effect

```{r, eval = FIT_BAYES_MODELS}
bm_test_first_look_adults_less_inf_prior_null <- update(bm_test_first_look_adults_less_inf_prior, formula = ~ . - condition_c)
summary(bm_test_first_look_adults_less_inf_prior_null)

saveRDS(bm_test_first_look_adults_less_inf_prior_null,
  file = here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_adults_less_inf_prior_null.rds")
)
```

```{r, eval = !FIT_BAYES_MODELS}
# if model is not fit, load from disk
bm_test_first_look_adults_less_inf_prior_null <- readRDS(here(RESULTS_FOLDER, "bayes_model_fits", "bm_test_first_look_adults_less_inf_prior_null.rds"))
```

```{r, eval = COMPUTE_BAYES_FACTORS}
test_m_comparison_FL_adults_less_inf_prior <- brms::bayes_factor(
  bm_test_first_look_adults_less_inf_prior,
  bm_test_first_look_adults_less_inf_prior_null
)

saveRDS(test_m_comparison_FL_adults_less_inf_prior,
  file = here(RESULTS_FOLDER, "test_m_comparison_FL_adults_less_inf_prior.rds")
)
```

```{r}
# remove Bayes model fits
rm(bm_test_first_look_adults_less_inf_prior)
rm(bm_test_first_look_adults_less_inf_prior_null)
```

# Plotting PTL and First Look for familiarization and test

```{r}
figure_fam_test_p_fl <- ggarrange(
  overall_fl_fam, overall_fl_test, overall_p_fam, overall_p_test, 
  labels = c("A", "B", "C", "D"),
  ncol = 2, nrow = 2
)

figure_fam_test_p_fl

figure_fam_test_p_fl <- cowplot::plot_grid(
  overall_fl_fam +
    theme(
      axis.text.x = element_blank(),
      axis.ticks.x = element_blank(),
      axis.title.x = element_blank()
    ),
  overall_fl_test +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      axis.title.y = element_blank(),
      axis.text.x = element_blank(),
      axis.ticks.x = element_blank(),
      axis.title.x = element_blank()
    ),
  overall_p_fam, 
  overall_p_test +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      axis.title.y = element_blank()
    ),
  nrow = 2,
  align = "v"
)

ggsave(here(paper_path, "Figure5.png"),
  bg = "white", width = 14, height = 8
)
```

# Creating results tables for Bayesian mixed effects models of PTL and First Look for familiarization and test

## Familiarization

```{r}
table_names_fam <- c("bm_fam_fl_toddlers_tidy_summary", "bm_fam_fl_adults_tidy_summary", "bm_fam_aoi_toddlers_tidy_summary", "bm_fam_aoi_adults_tidy_summary")

# Create a function to extract age cohort and test phase from the table names
extract_metadata_fam <- function(table_names_fam) {
  parts <- strsplit(table_names_fam, "_")[[1]]
  list(
    measure = parts[3], # e.g., "test"
    age_cohort = parts[4]  # e.g., "adults"
  )
}

# Combine all tables into one
combined_brm_results_fam <- table_names_fam %>%
  map_df(~ {
    metadata <- extract_metadata_fam(.x)
    get(.x) %>% 
      mutate(
        measure = metadata$measure,
        age_cohort = metadata$age_cohort,
        model = paste(measure, age_cohort, sep = " ")
      )
  }) %>%
  select(model, everything()) %>% # Reorder columns 
  select(-measure, -age_cohort) %>% 
  mutate(term = term %>%
    str_replace_all("condition_c", "Condition") %>%
    str_replace_all("prev_location_c", "Location") %>% 
    str_replace_all("location_c", "Location") %>%
    str_replace_all("familiarization_trial_num_4", "Trial Number"))


# View the combined table
print(combined_brm_results_fam)

saveRDS(combined_brm_results_fam,
  file = here(RESULTS_FOLDER, "combined_brm_results_fam.rds")
)
```

## Test

```{r}
table_names_test <- c("bm_test_fl_toddlers_tidy_summary", "bm_test_fl_adults_tidy_summary", "bm_test_aoi_toddlers_tidy_summary", "bm_test_aoi_adults_tidy_summary")

# Create a function to extract age cohort and test phase from the table names
extract_metadata_test <- function(table_names_test) {
  parts <- strsplit(table_names_test, "_")[[1]]
  list(
    measure = parts[3], # e.g., "test"
    age_cohort = parts[4]  # e.g., "adults"
  )
}

# Combine all tables into one
combined_brm_results_test <- table_names_test %>%
  map_df(~ {
    metadata <- extract_metadata_test(.x)
    get(.x) %>% 
      mutate(
        measure = metadata$measure,
        age_cohort = metadata$age_cohort,
        model = paste(measure, age_cohort, sep = " ")
      )
  }) %>%
  select(model, everything()) %>% # Reorder columns 
  select(-measure, -age_cohort) %>% 
  mutate(term = term %>%
    str_replace_all("condition_c", "Condition") %>%
    str_replace_all("age_mo_c", "Age"))


# View the combined table
print(combined_brm_results_test)

saveRDS(combined_brm_results_test,
  file = here(RESULTS_FOLDER, "combined_brm_results_test.rds")
)
```
