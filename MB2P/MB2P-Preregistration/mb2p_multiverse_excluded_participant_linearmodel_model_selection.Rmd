---
title: "MB2-P - Multiverse Data Simulation and Statistical Analysis"
author: "Rmarkdown by Giulia Calignano, Alvin Tan, Melli S. Schreiner  "
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    css: styles.css
  pdf_document: default
  word_document: default
  theme: united
---

```{r setup, include=FALSE}
# Clear workspace:
rm(list = ls())

knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(zoo)
library(lme4)
library(mgcv)
library(here)
library(dplyr)
library(tidyverse)
library(stringi)
library(gridExtra)
```

```{r setup2, include=FALSE}
set.seed(123) # for reproducibility
source(here("helper", "ensure_repo_structure.R"))
theme_set(theme_classic())

# load pupillometry data
load(here(INTERMEDIATE_FOLDER, INTERMEDIATE_008))
#data_pupillometry <- read.csv2("mb2p.csv",sep=",")
#data_pupillometry$outcome = as.factor(data_pupillometry$outcome)
#data_pupillometry$condition = as.factor(data_pupillometry$condition)
#data_pupillometry$age_cohort = as.factor(data_pupillometry$age_cohort)
```

## The Data 

- **participant_id**: A unique identifier for each participant, generated as a random string. Each participant has a unique ID to distinguish them in the dataset.
- **age_cohort**: A randomly generated string intended to categorize participants into different age cohorts.
- **t**: A numeric variable representing a timestamp or duration, generated within a specified range and with a possibility of missing values (NA).
- **x and y**: Numeric variables generated within specified ranges, intended to represent coordinates or other measurements, with a possibility of missing values.
- **pupil_left and pupil_right**: Numeric variables representing measurements of the left and right pupil sizes, respectively. These variables are generated with a specified correlation and then rescaled to a specific range.
- **lab_id**: A randomly generated string serving as a unique identifier for the lab or testing location.
- **conditions**: A categorical variable with two levels, i.e. "knowledge" and "ignorance"
- **outcomes**: A categorical variable with two levels, i.e. "incongruent" and "congruent"

## The Multiverse forking paths of pupillometry preprocessing 

The following script specifies the preprocessing and analysis steps of the multiverse approach applied to the MB2-P (see Calignano, Girardi, and AltoÃ©, 2023).

Let's assume that we have 10s worth of data per participant which starts at 1s before the resolution until 9s after the resolution. The crucial time-window for our analyses is the 5s after the bear exits the tubes, i.e,. from 1s to 6s in this dataset.

```{r preprocess}
# Check Nijmegen-lab
data.ni <- data_pupillometry |> 
  filter(lab_id == "babylabNijmegen",
  trial_num == 6,                   
  t_norm >= -1000 & t_norm < 5000)
 #hist(data.ni$pupil_right)
 #head(data.ni$pupil_left)
# -> Looks like values need to be divided by 100 to transform to mm.

data_pupillometry <- data_pupillometry |> 
  filter(eyetracker_type == "Tobii",       # pending resolution for Eyelink
         lab_id != "babylabNijmegen",      # Nijmegen has pupil values in the 100s
         trial_num == 6,                   # filter to second test trial only (data reduction)
         t_norm >= -1000 & t_norm < 5000)  # filter to window of interest only (data reduction)

data_pupillometry <- data_pupillometry |> 
  mutate(age_cohort <- as.factor(age_cohort)) |> 
  rowwise() |> 
  mutate(average = mean(c(pupil_left, pupil_right), na.rm = TRUE)) |> # switched to liberal avg
  ungroup()

# Merging in AL data (variable prop_exit)

#summarize_participant_test_both_trials <- readRDS(here(RESULTS_FOLDER,"summarize_participant_test_both_trials.rds"))

#data_pupillometry <- data_pupillometry %>% left_join(summarize_participant_test_both_trials %>% dplyr::select("participant_lab_id", "trial_num", "prop_exit"), by = c( "participant_lab_id", "trial_num"))

#rm(summarize_participant_test_both_trials)
```

# First Degree of freedom: Filtering of extreme yet plausible pupil values, i.e.<2mm, >8mm  

```{r DF1 extreme tonic values, echo=TRUE, include=TRUE, out.width='90%'}
data_pupillometry <- data_pupillometry |> 
  mutate(pupil_left = ifelse(pupil_left < 0, NA, pupil_left),
         pupil_right = ifelse(pupil_right < 0, NA, pupil_right))


data_pupillometry$pupil_left = as.numeric(as.character(data_pupillometry$pupil_left))
data_pupillometry$pupil_right = as.numeric(as.character(data_pupillometry$pupil_right))

### The following is a temporary workaround to include the Eyelink-data by calculating those values which would correspond to 2mm and 8mm, i.e., the mm-values for the first degree of freedom in the multiverse.

data_plausible <- data_pupillometry |> 
  filter(eyetracker_type != "EyeLink")

#pupil.vector <- data_plausible.SMI.Tobii[!is.na(data_plausible.SMI.Tobii$average),]$average
#sum(pupil.vector<=2)/length(pupil.vector)
#sum(pupil.vector>8)/length(pupil.vector)
#range(pupil.vector)
#quantile(pupil.vector)
# -> 2mm and 8mm correspond to 0.001568934 and 1
data_plausible.Eyelink <- data_pupillometry |> 
 filter(eyetracker_type == "EyeLink")

pupil.vector <- data_plausible.Eyelink[!is.na(data_plausible.Eyelink$average),]$average
range(pupil.vector)
quantile(pupil.vector, probs=c(0.001568934, 1))
# -> corresponds to 52 and 3008

###

# plausible data range ]2, 8[ for SMI and Tobii
data_plausible.SMI.Tobii <- data_pupillometry |> 
 filter(eyetracker_type != "EyeLink") |>
  mutate(average = ifelse(average < 2 | average > 8, NA, average))

# plausible data range ]52, 3008[ for Eyelink
data_plausible.Eyelink <- data_pupillometry |> 
  filter(eyetracker_type == "EyeLink") |>
    mutate(average = ifelse(average < 52 | average > 3008, NA, average))


data_plausible <- bind_rows(data_plausible.SMI.Tobii, data_plausible.Eyelink)

data_df1 <- bind_rows(
  data_pupillometry |> 
    mutate(df1_extreme_values = "implausible"),
  data_plausible |> 
    mutate(df1_extreme_values = "plausible")
) |> nest(data = -df1_extreme_values)

# scatterplot
data_pupillometry |> 
  #filter(eyetracker_type != "EyeLink") |>
  mutate(plausibility = ifelse(pupil_left <= 2 | pupil_left >= 8 | 
                                 pupil_right <= 2 | pupil_right >= 8,
                               "implausible", "plausible")) |> 
  ggplot(aes(x = pupil_left, y = pupil_right, col = plausibility)) +
  geom_point(alpha = .1) +
  labs(x = "Pupil size left eye (mm)",
       y = "Pupil size right eye (mm)") +
  scale_color_manual(values = c("indianred", "royalblue")) +
  facet_wrap("age_cohort")
```

# Second degree of freedom: fixation within the screen vs outside the screen

```{r DF2 area of interest, echo=TRUE, include=TRUE, out.width='90%'}
data_within <- data_df1 |> 
  mutate(data = map(data, \(d) {
    d |> 
      mutate(x = ifelse(x <= 0 | x >= 1280, NA, x),
             y = ifelse(y <= 0 | y >= 960, NA, y))
  }))

data_df2 <- bind_rows(
  data_df1 |> mutate(df2_screen_fixation = "outside", .before = "data"),
  data_within |> mutate(df2_screen_fixation = "within", .before = "data")
)

data_pupillometry |> 
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = .1)
```
# Third degree of freedom: moving average filtered vs unfiltered data

```{r DF3 moving average, echo=TRUE, include=TRUE, out.width='90%'}
WINDOW_SIZE = 5

data_avg <- data_df2 |> 
  mutate(data = map(data, \(d) {
    d |> 
      group_by(participant_id, trial_num) |> 
      mutate(pupil_left = rollapply(pupil_left, width = WINDOW_SIZE, 
                                    FUN = mean, na.rm = TRUE, 
                                    fill = NA, align = "right"),
             pupil_right = rollapply(pupil_right, width = WINDOW_SIZE, 
                                     FUN = mean, na.rm = TRUE, 
                                     fill = NA, align = "right")) |> 
      rowwise() |> 
      mutate(average = mean(c(pupil_left, pupil_right), na.rm = TRUE)) |> # NEW: need to update average after applying rolling average; switched to liberal avg
      ungroup() 
  }))

data_df3 <- bind_rows(
  data_df2 |> mutate(df3_moving_average = "unfiltered", .before = "data"),
  data_avg |> mutate(df3_moving_average = "filtered", .before = "data")
)
```

# Fourth degree of freedom: 1s, 0.5s, or 0.25s before the bear resolution.

We consider three possible baseline correction all performed by subtracting the average pupil diameter from all subsequent values between, dividing those values by the average baseline, and averaging the baseline-corrected values vector.

```{r DF4 baseline correction, echo=TRUE, include=TRUE, out.width='90%'}
### 3 median baselines, i.e., initial time window for each trial_num ,id, lab_id
### i.e. 1s, 0.5s, or 0.25s before resolution.
# MSS: According to the current data set, the resolution is at 0 ms for t_norm!
# FIXME: note suggests median, but actual code uses mean
baseline_correct <- function(data, TIME_WINDOW = 1000) {
  data |> 
    group_by(participant_id, condition, outcome, lab_id) |> 
    mutate(average = {
      avg_filtered <- average[t_norm >= -TIME_WINDOW & t_norm < 0]
      avg_mean <- mean(avg_filtered, na.rm = TRUE)
      (average - avg_mean)/avg_mean # Changed to calculate relative change.
    })
}

data_baseline_1 <- data_df3 |> 
  mutate(data = map(data, partial(baseline_correct, TIME_WINDOW = 1000)),
         df4_baseline_correction = "1s", .before = "data")
data_baseline_0.5 <- data_df3 |> 
  mutate(data = map(data, partial(baseline_correct, TIME_WINDOW = 500)),
         df4_baseline_correction = "0.5s", .before = "data")
data_baseline_0.25 <- data_df3 |> 
  mutate(data = map(data, partial(baseline_correct, TIME_WINDOW = 250)),
         df4_baseline_correction = "0.25s", .before = "data")

data_df4 <- bind_rows(
  data_baseline_1,
  data_baseline_0.5,
  data_baseline_0.25
)

# plotting
# RH: Changed the color and facet to show condition within panel.

data_df4 |> 
  pull(data) |> 
  (`[`)(value = c(3,7)) |> # arbitrarily select three universes to visualise
  map(\(d) {
    ggplot(d |> filter(!is.na(average),
                       t_norm >= 0 & t_norm < 5000), 
           aes(x = t_norm, y = average, col = outcome, linetype = age_cohort)) +
      labs(x = "Time (ms)",
           y = "Pupil size (mm)") +
      geom_vline(xintercept = 0) +
      geom_hline(yintercept = 0) +
      geom_smooth(se = TRUE) 
      #facet_grid(condition ~ eyetracker_type)
  })
```

# Fifth degree of freedom: Participant exclusion (following the criteria of MB2) at the level of the 1st vs 2nd trial. 

Here we use two strings to exclude participants who provided valid data only on the second test trial (remove_ids_1) or who provided valid data on both test trials (remove_ids_2).

```{r DF5 participant exclusion, echo=TRUE, include=TRUE, out.width='90%'}

no_exclusions <- data_pupillometry |> 
  filter(pilot == "no",
      session_error == "noerror",
      age_exclusion == "no",
      sufficient_fam_trials == 1) |> 
  pull(participant_id) |> 
  unique()
valid_second_ids <- data_pupillometry |> 
  filter(pilot == "no",
      session_error == "noerror",
      age_exclusion == "no",
      sufficient_fam_trials == 1,
      valid_second_test_trial == 1) |> 
  pull(participant_id) |> 
  unique()
valid_both_ids <- data_pupillometry |> 
  filter(pilot == "no",
      session_error == "noerror",
      age_exclusion == "no",
      sufficient_fam_trials == 1,
      valid_second_test_trial == 1,
      valid_first_test_trial == 1) |> 
  pull(participant_id) |> 
  unique()

data_no_exclusions <- data_df4 |> 
  mutate(data = map(data, \(d) {
    d |> filter(participant_id %in% no_exclusions)
  }))
data_valid_second <- data_df4 |> 
  mutate(data = map(data, \(d) {
    d |> filter(participant_id %in% valid_second_ids)
  }))
data_valid_both <- data_df4 |> 
  mutate(data = map(data, \(d) {
    d |> filter(participant_id %in% valid_both_ids)
  }))

data_df5 <- bind_rows(
  data_no_exclusions |> mutate(df5_ppt_exclusion = "no exclusion", .before = "data"),
  data_valid_second |> mutate(df5_ppt_exclusion = "second test trial valid", .before = "data"),
  data_valid_both |> mutate(df5_ppt_exclusion = "both test trials valid", .before = "data")
)
```

As a final step, we investigated (1) the averaged interaction effect Condition x Outcome, (2) the time-course of the interaction effect Condition x Outcome and (3) the non linear interaction effect of Condition x Outcome considering the time-course of the effect. This approach provided an exploration of whether and how smoothing time enhances the plausibility of statistical modeling of pupil dilation across the datasets we created.

```{r modelling, echo=TRUE, include=TRUE, out.width='90%'}
# Assuming `data_df5$data` is a list of dataframes:
data_df5_list <- data_df5$data

# Run your model function on each dataframe in data_df5_list
library(dplyr)
library(purrr)

# Define the custom modeling function
run_model_lm <- function(df) {
  if (is.data.frame(df) && n_distinct(df$condition) > 1 & 
      n_distinct(df$outcome) > 1 & n_distinct(df$age_cohort) > 1) {
    # Fit the model if conditions are met
    lm(average ~ condition * outcome * age_cohort, data = df)
  } else {
    # Return NULL if conditions aren't met
    NULL
  }
}

run_model_lmer <- function(df) {
  if (is.data.frame(df) && n_distinct(df$condition) > 1 & 
      n_distinct(df$outcome) > 1 & n_distinct(df$age_cohort) > 1) {
    # Fit the model if conditions are met
    lmer(average ~ condition * outcome * age_cohort + (1|participant_id), data = df)
  } else {
    # Return NULL if conditions aren't met
    NULL
  }
}
# Apply the model function across the list of dataframes in the list-column
results_lm <- map(data_df5_list, run_model_lm)
results_lmer <- map(data_df5_list, run_model_lmer)

# Filter out NULL values (dataframes that didn't meet the condition)
lm_results <- compact(results_lm)
lmer_results <- compact(results_lmer)


```

```{r model parameters, echo=TRUE, include=TRUE, out.width='90%'}
# Load required packages
library(purrr)
library(broom)
library(dplyr)

# Define the extraction function with improved error handling
extract_model_metrics <- function(model) {
  if (!is.null(model)) {
    # Calculate R-squared
    rsq <- summary(model)$r.squared
    
    # Get AIC and BIC
    aic <- AIC(model)
    bic <- BIC(model)
    
    # Extract coefficients and standard errors (using tidy output)
    coef_df <- broom::tidy(model)
    coef_df <- coef_df %>%
      filter(term %in% c("condition", "outcome", "age_cohort")) %>%
      select(term, estimate, std.error)
    
    # If coefficients are missing, create empty placeholders
    if (nrow(coef_df) == 0) {
      coef_df <- tibble(term = NA, estimate = NA, std.error = NA)
    }
    
    # Add the AIC, BIC, and R-squared as additional columns for consistency
    coef_df <- coef_df %>%
      mutate(AIC = aic, BIC = bic, R_squared = rsq)
    
    return(coef_df)
  } else {
    NULL
  }
}

library(broom.mixed)
LMER_model_metrics <- map(lmer_results, function(model) {
  broom.mixed::tidy(model)
})

library(lme4)
library(performance)

extract_model_metrics_LMER <- function(model) {
  r2 <- performance::r2(model)  # Extract R^2 values
  data.frame(
    AIC = AIC(model),
    BIC = BIC(model),
    logLik = logLik(model),
    marginal_R2 = r2$R2_marginal,   # Marginal R^2
    conditional_R2 = r2$R2_conditional,  # Conditional R^2
    fixed_effects = paste(names(fixef(model)), round(fixef(model), 3), collapse = ", ")
  )
}

# Apply the extraction function across all models and filter out NULL results
LM_model_metrics <- map(lm_results, extract_model_metrics)
LM_model_metrics <- compact(LM_model_metrics)  # Remove any NULL elements


LMER_model_metrics <- map(lmer_results, extract_model_metrics_LMER)
LMER_model_metrics <- map(lmer_results, extract_model_metrics_LMER)  # Remove any NULL elements

# Convert to a tidy dataframe
LMmodel_metrics_df <- bind_rows(LM_model_metrics, .id = "model_id")
LMERmodel_metrics_df <- bind_rows(LMER_model_metrics, .id = "model_id")


# Check the structure of model_metrics_df to confirm columns are present
str(LMmodel_metrics_df)
str(LMERmodel_metrics_df)
# Plot the specification curve
library(ggplot2)

# Add a model order for plotting
LMmodel_metrics_df <- LMmodel_metrics_df %>%
  group_by(term) %>%
  mutate(model_order = row_number()) %>%
  ungroup()

LMERmodel_metrics_df <- LMERmodel_metrics_df %>%
  group_by(fixed_effects) %>%
  mutate(model_order = row_number()) %>%
  ungroup()


```

```{r model parameters plot, echo=TRUE, include=TRUE, out.width='90%'}
# Create the plot
# BIC LM
ggplot(LMmodel_metrics_df, aes(x = model_order, y = BIC, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = BIC - std.error, ymax = BIC + std.error), 
            #    width = 0.2) +                  # Error bars
  #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for BIC",
       x = "Model Order",
       y = "BIC") +
      # color = "Predictor") +
  theme_minimal()
#BIC LMER
ggplot(LMERmodel_metrics_df, aes(x = model_order, y = BIC, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = BIC - std.error, ymax = BIC + std.error), 
            #    width = 0.2) +                  # Error bars
  #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for BIC",
       x = "Model Order",
       y = "BIC") +
      # color = "Predictor") +
  theme_minimal() 

#AIC LM
ggplot(LMmodel_metrics_df, aes(x = model_order, y = AIC, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = AIC - std.error, ymax = AIC + std.error), 
            #    width = 0.2) +                  # Error bars
  #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for AIC",
       x = "Model Order",
       y = "AIC") +
      # color = "Predictor") +
  theme_minimal() 

#AIC LMER
ggplot(LMERmodel_metrics_df, aes(x = model_order, y = AIC, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = AIC - std.error, ymax = AIC + std.error), 
            #    width = 0.2) +                  # Error bars
  #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for AIC",
       x = "Model Order",
       y = "AIC") +
      # color = "Predictor") +
  theme_minimal()

#R2 LM
ggplot(LMmodel_metrics_df, aes(x = model_order, y = R_squared, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = R_squared - std.error, ymax = R_squared + std.error), 
            #    width = 0.2) +                  # Error bars
  facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for R_squared",
       x = "Model Order",
       y = "R_squared") +
      # color = "Predictor") +
  theme_minimal() 

#R2 CONDITIONAL LMER
ggplot(LMERmodel_metrics_df, aes(x = model_order, y = conditional_R2, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = R_squared - std.error, ymax = R_squared + std.error), 
            #    width = 0.2) +                  # Error bars
#  facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for R_squared",
       x = "Model Order",
       y = "R_squared") +
      # color = "Predictor") +
  theme_minimal()

```

