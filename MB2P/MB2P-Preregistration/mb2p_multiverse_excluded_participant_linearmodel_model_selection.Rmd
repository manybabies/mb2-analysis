---
title: "MB2P - Multiverse Data Simulation and Statistical Analysis"
author: "Rmarkdown by Giulia Calignano, Melanie S. Schreiner, Alvin Tan, and Robert Hepach"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    css: styles.css
  pdf_document: default
  word_document: default
  theme: united
---

```{r setup, include=FALSE}
# Clear workspace:
rm(list = ls())

knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(zoo)
library(mgcv)
library(here)
#make sure here is set to the mb2-analysis root folder
library(dplyr)
library(tidyverse)
library(stringi)
library(gridExtra)
library(purrr)
library(broom)
library(broom.mixed)
library(lme4)
library(performance)
library(ggthemes)
```

```{r load data, include=FALSE}
set.seed(123) # for reproducibility
source(here("helper", "ensure_repo_structure.R"))
theme_set(theme_classic())

# load pupillometry data
load(here(INTERMEDIATE_FOLDER, INTERMEDIATE_008))
rm(list = setdiff(ls(), c("data_pupillometry", "INTERMEDIATE_FOLDER", "INTERMEDIATE_008", "RESULTS_FOLDER")))

# param controlling whether all plots get recreated in Part 3; set to TRUE to regenerate all plots
CREATE_INDIVIDUAL_MULTIVERSE_PLOTS = FALSE
#model output path
model_output_path <- here("MB2P","MB2P-Preregistration","model_outputs")
# Check if the directory exists
if (!dir.exists(model_output_path)) {
  # If it doesn't exist, create it
  dir.create(model_output_path, showWarnings = FALSE)
  message("Directory created successfully.")
} else {
  message("Directory already exists.")
}
plot_output_path <- here("MB2P","MB2P-Preregistration","plots")
# Check if the directory exists
if (!dir.exists(plot_output_path)) {
  # If it doesn't exist, create it
  dir.create(plot_output_path, showWarnings = FALSE)
  message("Directory created successfully.")
} else {
  message("Directory already exists.")
}
```

## The Multiverse forking paths of pupillometry preprocessing 
The following script specifies the preprocessing and analysis steps of the multiverse approach applied to the MB2P dataset (see Calignano, Girardi, and AltoÃ©, 2023).


# PART 1 PREPROCESSING (z-transformation)

The initial preprocessing merges the data across eyetracking systems by performing a z-transformation.
```{r preprocess}
data_pupillometry <- data_pupillometry |> 
  dplyr::filter(trial_num == 6) |>  # filter to second test trial only (data reduction)
  dplyr::select(participant_id, participant_lab_id, lab_id, age_cohort, t, x, y, pupil_left, pupil_right, condition, t_norm, trial_num, participant_gender, eyetracker_type, outcome, pilot, session_error, age_exclusion, sufficient_fam_trials, valid_second_test_trial, valid_first_test_trial) |>
  mutate(pupil_left = ifelse(pupil_left < 0 | pupil_right < 0, NA, pupil_left),
         pupil_right = ifelse(pupil_left < 0 | pupil_right < 0, NA, pupil_right)
         ) |>
  mutate(age_cohort = as.factor(age_cohort)) |> 
  rowwise() |> 
  mutate(average = mean(c(pupil_left, pupil_right), na.rm = TRUE)) |> # switched to liberal avg
  ungroup() |>
  group_by(participant_lab_id) |> # Scale pupil-value 
  mutate(average_z = (average - mean(average, na.rm = TRUE)) / sd(average, na.rm = TRUE)) |>
  ungroup() |>  
  filter(t_norm >= -1000 & t_norm < 5000)  

hist(data_pupillometry$average) # Skewed given different unites across systems.
hist(data_pupillometry$average_z) # Looks evenly distributed.

# centering of age_cohort, condition, and outcome
  data_pupillometry <- data_pupillometry |>
    mutate(
    age_cohort_c = case_when(
      age_cohort == "adults" ~ -0.5,
      age_cohort == "toddlers" ~ 0.5
    ),
    condition_c = case_when(
      condition == "knowledge" ~ -0.5,
      condition == "ignorance" ~ 0.5
    ),
    outcome_c = case_when(
      outcome == "congruent" ~ -0.5,
      outcome == "incongruent" ~ 0.5)
    )
  
# Merging in AL data (variable prop_exit)
summarize_participant_test_both_trials <- readRDS(here(RESULTS_FOLDER,"summarize_participant_test_both_trials.rds"))
data_pupillometry <- data_pupillometry %>% left_join(summarize_participant_test_both_trials %>% dplyr::select("participant_lab_id", "trial_num", "prop_exit"), by = c( "participant_lab_id", "trial_num"))
rm("summarize_participant_test_both_trials")

# # For the subsequent step, i.e., first degree, identify those z-values that correspond to 2mm and 8mm (according to Tobii).
# data_smaller2mm <- data_pupillometry |> 
#   dplyr::filter(eyetracker_type != "EyeLink") |> 
#   group_by(participant_lab_id) |>
#   dplyr::filter(average <= 2) |>
#   dplyr::select(participant_lab_id, average, average_z) |>
#   arrange(average_z) |>
#   ungroup()
# #
# data_smaller2mm |>
#   summarise(ZMean.2mm = mean(average_z, na.rm = T), ZMedian.2mm = median(average_z, na.rm = T), Min.2mm = min(average, na.rm = T), Max.2mm = max(average, na.rm = T),
#             ZMin.2mm = min(average_z, na.rm = T), ZMax.2mm = max(average_z, na.rm = T))
# 
# ## -> Lower bound: z = 0.8000874
# hist(data_smaller2mm$average_z)
# rm("temp")
# ##
# temp <- data_pupillometry |> 
#   filter(eyetracker_type != "EyeLink") |>
#   group_by(participant_lab_id) |>
#   filter(average >= 8) |>
#   select(participant_lab_id, average, average_z) |>
#   arrange(average_z) |>
#   ungroup()
# #
# temp |>
#   summarise(Min.8mm = min(average, na.rm = T), Max.8mm = max(average, na.rm = T),
#             ZMin.8mm = min(average_z, na.rm = T), ZMax.8mm = max(average_z, na.rm = T))
# 
# ## -> There are no samples with pupil_size ?> 8mm
```


# PART 2 FITTING THE MULTIVERSE

## First Degree of freedom: Filtering of extreme yet plausible pupil values, i.e.<2mm, >8mm  

This results in 2 datasets; (plausible vs. implausible values)

```{r DF1 extreme tonic values, echo=TRUE, include=TRUE, out.width='90%'}
# data_plausible <- data_pupillometry |> 
#     mutate(average = ifelse(average_z < 0.8000874 , NA, average)) |>
#     mutate(average_z = ifelse(average_z < 0.8000874, NA, average_z))

#check on Tobii data distributions
ggplot(filter(data_pupillometry,eyetracker_type == "Tobii"),aes(average))+
  geom_histogram() +
  facet_wrap(~lab_id)
#Trento, Heidelberg, Munich, Goettingen all have different scales from the rest

data_plausible <- data_pupillometry |> 
  mutate(average = ifelse(eyetracker_type != "EyeLink" & average <= 2 , NA, average),
         average = ifelse(eyetracker_type != "EyeLink" & average >= 8 , NA, average),
         average_z = ifelse(eyetracker_type != "EyeLink" & average <= 2 , NA, average_z),
         average_z = ifelse(eyetracker_type != "EyeLink" & average >= 8 , NA, average_z)
         )

data_df1 <- bind_rows(
  data_pupillometry |> 
    mutate(df1_extreme_values = "implausible"),
  data_plausible |> 
    mutate(df1_extreme_values = "plausible")
) |> nest(data = -df1_extreme_values) 

# Scatterplot.
# data_pupillometry |> 
#   filter(eyetracker_type != "EyeLink") |>
#   mutate(plausibility = ifelse(pupil_left <= 2 | pupil_left >= 8 | 
#                                  pupil_right <= 2 | pupil_right >= 8,
#                                "implausible", "plausible")) |> 
#   ggplot(aes(x = pupil_left, y = pupil_right, col = plausibility)) +
#   geom_point(alpha = .1) +
#   labs(x = "Pupil size left eye (mm)",
#        y = "Pupil size right eye (mm)") +
#   scale_color_manual(values = c("indianred", "royalblue")) +
#   facet_wrap("age_cohort")

# Check to see  whether any changes were made.
data_df1 |> 
  pull(data) |> 
  map(\(d) {
  d |>
  group_by(eyetracker_type) |>
  summarise(AVE = mean(average_z, na.rm =T))
  })  # Makes sense that only Tobii-data were adjusted.
```

# Second degree of freedom: gaze within the screen vs outside the screen
This results in 4 datasets; 2 (plausible vs. implausible values) * 2 (on-screen vs. off-screen).

```{r DF2 area of interest, echo=TRUE, include=TRUE, out.width='90%'}
#! Does the following actually affect the cols average or average_z?
data_within <- data_df1 |> 
  mutate(data = map(data, \(d) {
    d |> 
      mutate(x = ifelse(x <= 0 | x >= 1280, NA, x),
             y = ifelse(y <= 0 | y >= 960, NA, y),
            average = ifelse(is.na(x) | is.na(y), NA, average),
            average_z = ifelse(is.na(x) | is.na(y), NA, average_z)
            )
  }))

data_df2 <- bind_rows(
  data_df1 |> mutate(df2_screen_fixation = "outside", .before = "data"),
  data_within |> mutate(df2_screen_fixation = "within", .before = "data")
)

# Scatterplot to visualize.
data_pupillometry |> 
  mutate(screen_fixation = ifelse(x <= 0 | x >= 1280 | y <= 0 | y >= 960,
                               "outside", "within")) |>
  ggplot(aes(x = x, y = y, col = screen_fixation)) +
    scale_color_manual(name = "screen fixation", values = c("indianred", "royalblue")) +
    facet_wrap("age_cohort") +
    geom_point(alpha = .1)

data_df2 |> 
  pull(data) |> 
  map(\(d) {
  d |>
  group_by(eyetracker_type) |>
  summarise(AVE = mean(average_z, na.rm =T))
  }) # Adjustments across all eyetracking systems. Makes sense. 
```

```{r}
#remove previous datasets to free up memory
rm(data_df1)
gc()
```

# Third degree of freedom: moving average filtered vs unfiltered data
This results in 8 datasets; 2 (plausible vs. implausible values) * 2 (on-screen vs. off-screen) * 2 (filtered or not).

```{r DF3 moving average, echo=TRUE, include=TRUE, out.width='90%'}
WINDOW_SIZE = 5

data_avg <- data_df2 |> 
  mutate(data = map(data, \(d) { 
    d |> 
      group_by(participant_lab_id, trial_num) |> 
      mutate(average = rollapply(average, width = WINDOW_SIZE, 
                                     FUN = mean, na.rm = TRUE, 
                                     fill = NA, align = "right"),
              average_z = rollapply(average_z, width = WINDOW_SIZE, 
                                      FUN = mean, na.rm = TRUE, 
                                      fill = NA, align = "right")) |>
      ungroup() 
  }))

data_df3 <- bind_rows(
  data_df2 |> mutate(df3_moving_average = "unfiltered", .before = "data"),
  data_avg |> mutate(df3_moving_average = "filtered", .before = "data")
)

# # Plotting to check. Commenting out here.
# data_df3 |> 
#   pull(data) |> 
#   #(`[`)(value = c(1:8)) |>
#   map(\(d) {
#     ggplot(d |> filter(!is.na(average_z),
#                        t_norm >= -1000 & t_norm < 5000), 
#            aes(x = t_norm, y = average_z, col = outcome, linetype = age_cohort)) +
#       labs(x = "Time (ms)",
#            y = "Pupil size (z-score, relative change)") +
#       geom_smooth(se = TRUE) +
#       facet_grid(condition ~ age_cohort)
#   })

#! Why is average pupil size for adults *smaller* than for children?!

data_df3 |> 
  pull(data) |> 
  map(\(d) {
  d |>
  group_by(eyetracker_type) |>
  summarise(AVE = mean(average_z, na.rm =T))
  })  

```

```{r}
#remove previous datasets to free up memory
rm(data_df2)
gc()
```

# Fourth degree of freedom: 1s, 0.5s, or 0.25s before the bear resolution.

We consider three possible baseline correction all performed by subtracting the average pupil diameter from all subsequent values between, dividing those values by the average baseline, and averaging the baseline-corrected values vector.

This results in 24 datasets; 2 (plausible vs. implausible values) * 2 (on-screen vs. off-screen) * 2 (filtered or not) * 3 (1s, 0.5s, or 0.25s baseline).

```{r DF4 baseline correction, echo=TRUE, include=TRUE, out.width='90%'}
### 3 mean baselines, i.e., initial time window for each trial_num ,id, lab_id
### i.e. 1s, 0.5s, or 0.25s before resolution.
# MSS: According to the current data set, the resolution is at 0 ms for t_norm!

baseline_correct <- function(data, TIME_WINDOW = 1000) {
  data |>
    group_by(participant_lab_id, condition, outcome, lab_id) |>
    mutate(average = {
      avg_filtered <- average[t_norm >= -TIME_WINDOW & t_norm < 0]
      avg_mean <- mean(avg_filtered, na.rm = TRUE)
      (average - avg_mean)#/avg_mean # Changed to calculate relative change.
    })
}
#
baseline_correctZ <- function(data, TIME_WINDOW = 1000) {
  data |>
    group_by(participant_lab_id, condition, outcome, lab_id) |>
    mutate(average_z = {
      avg_filtered <- average_z[t_norm >= -TIME_WINDOW & t_norm < 0]
      avg_mean <- mean(avg_filtered, na.rm = TRUE)
      (average_z - avg_mean)#/avg_mean # Changed to calculate relative change.
    })
}

data_baseline_1 <- data_df3 |> 
  mutate(data = map(data, partial(baseline_correct, TIME_WINDOW = 1000)),
         df4_baseline_correction = "1s", .before = "data") |>
    mutate(data = map(data, partial(baseline_correctZ, TIME_WINDOW = 1000))) # Z-score
#
data_baseline_0.5 <- data_df3 |>
  mutate(data = map(data, partial(baseline_correct, TIME_WINDOW = 500)),
         df4_baseline_correction = "0.5s", .before = "data") |>
  mutate(data = map(data, partial(baseline_correctZ, TIME_WINDOW = 500))) # Z-score
#
data_baseline_0.25 <- data_df3 |> 
  mutate(data = map(data, partial(baseline_correct, TIME_WINDOW = 250)),
         df4_baseline_correction = "0.25s", .before = "data") |>
    mutate(data = map(data, partial(baseline_correctZ, TIME_WINDOW = 250))) # Z-score
      
data_df4 <- bind_rows(
  data_baseline_1,
  data_baseline_0.5,
  data_baseline_0.25
)

# # Plotting to check. Commenting out here.
# data_df4 |> 
#   pull(data) |> 
#  # (`[`)(value = c(1:4)) |> 
#   map(\(d) {
#     ggplot(d |> filter(!is.na(average_z),
#                        t_norm >= 0 & t_norm < 5000), 
#            aes(x = t_norm, y = average_z, col = outcome, linetype = age_cohort)) +
#       labs(x = "Time (ms)",
#            y = "Pupil size (z-score change)") +
#       geom_vline(xintercept = 0) +
#       geom_hline(yintercept = 0) +
#       geom_smooth(se = TRUE) +
#       facet_grid(condition ~ age_cohort)
#   })


data_df4 |> 
  pull(data) |> 
  map(\(d) {
  d |>
  group_by(eyetracker_type) |>
  summarise(AVE = mean(average_z, na.rm =T))
  })  

```

```{r}
#remove previous datasets to free up memory
rm(data_df3)
gc()
```

## Fifth degree of freedom: Participant exclusion (following the criteria of MB2) at the level of the 1st vs 2nd trial. 
Here we use two strings to exclude participants who provided valid data only on the second test trial (remove_ids_1) or who provided valid data on both test trials (remove_ids_2).

This results in 72 datasets; 2 (plausible vs. implausible values) * 2 (on-screen vs. off-screen) * 2 (filtered or not) * 3 (1s, 0.5s, or 0.25s baseline) * 3 (no exclusions, valid trial 2 or valid trial 1 AND 2).

```{r DF5 participant exclusion, echo=TRUE, include=TRUE, out.width='90%'}
no_exclusions <- data_pupillometry |> 
  filter(pilot == "no",
      session_error == "noerror",
      age_exclusion == "no",
      sufficient_fam_trials == 1) |> 
  pull(participant_lab_id) |> 
  unique()
valid_second_ids <- data_pupillometry |> 
  filter(pilot == "no",
      session_error == "noerror",
      age_exclusion == "no",
      sufficient_fam_trials == 1,
      valid_second_test_trial == 1) |> 
  pull(participant_lab_id) |> 
  unique()
valid_both_ids <- data_pupillometry |> 
  filter(pilot == "no",
      session_error == "noerror",
      age_exclusion == "no",
      sufficient_fam_trials == 1,
      valid_second_test_trial == 1,
      valid_first_test_trial == 1) |> 
  pull(participant_lab_id) |> 
  unique()

data_no_exclusions <- data_df4 |> 
  mutate(data = map(data, \(d) {
    d |> filter(participant_lab_id %in% no_exclusions)
  }))
data_valid_second <- data_df4 |> 
  mutate(data = map(data, \(d) {
    d |> filter(participant_lab_id %in% valid_second_ids)
  }))
data_valid_both <- data_df4 |> 
  mutate(data = map(data, \(d) {
    d |> filter(participant_lab_id %in% valid_both_ids)
  }))

data_df5 <- bind_rows(
  data_no_exclusions |> mutate(df5_ppt_exclusion = "no exclusion", .before = "data"),
  data_valid_second |> mutate(df5_ppt_exclusion = "second test trial valid", .before = "data"),
  data_valid_both |> mutate(df5_ppt_exclusion = "both test trials valid", .before = "data")
)

data_df5 |> 
  pull(data) |> 
  map(\(d) {
  d |>
  group_by(eyetracker_type) |>
  summarise(AVE = mean(average_z, na.rm =T))
  })  

```

```{r}
#remove previous datasets to free up memory
rm(data_df4)
gc()
```

# PART 3 MAKING SENSE OF THE MULTIVERSE (visual)

```{r}
# work-around for different time points for now: rounding to the nearest 25ms; Need to check this again.
data_df5 <- data_df5 |> 
  mutate(data = map(data, ~ .x |> mutate(t_norm_downsampled = floor(t_norm / 25) * 25)))

# reorder exclusion levels to be more intuitive
data_df5$df5_ppt_exclusion <- factor(data_df5$df5_ppt_exclusion, levels = c("no exclusion", "second test trial valid", "both test trials valid"))

```


```{r Ploting all 72 datasets and grand average, echo=TRUE, include=TRUE, eval=CREATE_INDIVIDUAL_MULTIVERSE_PLOTS,out.width='90%'}
# (1) Generate and store all plots for each of the 72 datasets.
plots <- data_df5 |> 
  pull(data) |> 
  map(\(d) {
    ggplot(d |> filter(!is.na(average_z),
                       t_norm >= 0 & t_norm < 5000), 
           aes(x = t_norm_downsampled, y = average_z, col = outcome, linetype = age_cohort)) +
      labs(x = "Time (ms)",
           y = "Pupil size (z-score, relative change)") +
      geom_vline(xintercept = 0) +
      geom_hline(yintercept = 0) +
      geom_smooth(se = TRUE) +
      facet_grid(condition ~ age_cohort)
  })

# Extract labels for filenames
labels <- data_df5 |> 
  dplyr::select(1:5) |>  # Select first 5 columns
  apply(1, paste, collapse = "_") # Combine column values into a string

# Add numbers before labels
labels <- paste0(seq_along(labels), "_", labels)

# Save each plot with a meaningful filename
walk2(plots, labels, ~ ggsave(
  filename = file.path(output_dir, paste0(.y, ".png")),
  plot = .x,
  width = 8, height = 6, dpi = 300
))
```

```{r}
#remove the large plots element
rm(plots)
gc()
```

```{r Ploting grand average, echo=TRUE, include=TRUE,out.width='90%'}
# (2) Generate grand average plot across all 72 datasets.
# MZ: issue: this does not first group by lab before averaging within each dataset of the multiverse
grand_avg <- data_df5 |> 
  pull(data) |> 
  bind_rows(.id = "dataset_id") |>  # Keep dataset ID.
  dplyr::filter(!is.na(average_z), t_norm >= 0 & t_norm < 5000) |>  
  group_by(t_norm_downsampled, dataset_id, condition, outcome, age_cohort) |>  
  #
  summarize(
    grand_averageZ = mean(average_z, na.rm = TRUE), .groups = "drop"
  ) |>
  #
  group_by(t_norm_downsampled, condition, outcome, age_cohort) |>  
    summarize(
    grand_average = mean(grand_averageZ, na.rm = TRUE),  
    sd = sd(grand_averageZ, na.rm = TRUE), N = n_distinct(dataset_id), gMax = max(grand_averageZ, na.rm = TRUE) , gMin = min(grand_averageZ, na.rm = TRUE), .groups = "drop"
  )
##
ggplot(grand_avg, aes(x = t_norm_downsampled, y = grand_average, col = outcome, linetype = age_cohort)) +
      labs(x = "Time (ms)",
           y = "Pupil size (z-score, relative change)") +
      geom_vline(xintercept = 0) +
      geom_hline(yintercept = 0) +
      geom_line() +
      geom_ribbon(aes(ymin = gMin, ymax = gMax, fill = outcome), 
             alpha = 0.25, color = NA) +
      scale_color_ptol() +
      scale_fill_ptol() +
      facet_grid(condition ~ age_cohort)
```

## Part 3.1. Visualizations of the multiverse data

### Create dataset for plotting
```{r}
data_for_plotting_df5 <- data_df5 |> 
  unite("multiverse_label",  df1_extreme_values,df2_screen_fixation,df3_moving_average,df4_baseline_correction,df5_ppt_exclusion, sep = "_", remove = FALSE) |>  # Combine first 5 column values into a string tracking the multiverse combination
  unnest(data) |> 
  dplyr::filter(!is.na(average_z), t_norm >= 0 & t_norm < 5000) 
```

### Summarize data

#### No averaging within lab

```{r}
#summarize by lab within each multiverse dataset
summarized_data_by_dataset_id <- data_for_plotting_df5 |> 
    group_by(t_norm_downsampled, multiverse_label, condition, outcome, age_cohort) |>  
  summarize(
    participant_num = n(),
    mean_pupil_z = mean(average_z, na.rm = TRUE),
    sd_pupil_z = sd(average_z, na.rm = TRUE),
    se_pupil_z = sd_pupil_z / sqrt(participant_num),
    ci_pupil_z = qt(1 - (0.05 / 2), participant_num - 1) * se_pupil_z
  ) |> 
  unite("multiverse_id_wcond", multiverse_label,condition, outcome, age_cohort, sep = "_", remove = FALSE)
 

summarized_data_by_dataset_id_mins <- summarized_data_by_dataset_id |> 
  group_by(t_norm_downsampled, condition, outcome, age_cohort) |>  
  summarize(
    N=n(),
    avg_pupil_z = mean(mean_pupil_z, na.rm = TRUE),
    min_pupil_z = min(mean_pupil_z, na.rm = TRUE),
    max_pupil_z = max(mean_pupil_z, na.rm = TRUE)
  )
```

#### Averaging within lab

```{r}
#summarize by lab within each multiverse dataset
summarized_data_by_lab_and_dataset_id <- data_for_plotting_df5 |> 
    group_by(t_norm_downsampled, multiverse_label, lab_id,condition, outcome, age_cohort) |>  
  summarize(
    grand_averageZ = mean(average_z, na.rm = TRUE), .groups = "drop"
  )
#summarize across labs within each multiverse dataset
summarize_data_across_lab_by_multiverse_label <- summarized_data_by_lab_and_dataset_id |> 
    group_by(t_norm_downsampled, multiverse_label, condition, outcome, age_cohort) |>  
  summarize(
    lab_num = n(),
    mean_pupil_z = mean(grand_averageZ, na.rm = TRUE),
    sd_pupil_z = sd(grand_averageZ, na.rm = TRUE),
    se_pupil_z = sd_pupil_z / sqrt(lab_num),
    ci_pupil_z = qt(1 - (0.05 / 2), lab_num - 1) * se_pupil_z
  ) |> 
  ungroup() |> 
  unite("multiverse_id_wcond", multiverse_label,condition, outcome, age_cohort, sep = "_", remove = FALSE)

summarized_data_by_lab_and_dataset_id_mins <- summarize_data_across_lab_by_multiverse_label |> 
  group_by(t_norm_downsampled, condition, outcome, age_cohort) |>  
  summarize(
    N=n(),
    avg_pupil_z = mean(mean_pupil_z, na.rm = TRUE),
    min_pupil_z = min(mean_pupil_z, na.rm = TRUE),
    max_pupil_z = max(mean_pupil_z, na.rm = TRUE)
  )
```

### Plots

#### Min-Max plot without first averagining within lab (same as above)

```{r}
ggplot(summarized_data_by_dataset_id_mins, aes(x = t_norm_downsampled, y = avg_pupil_z, col = outcome, linetype = age_cohort)) +
      labs(x = "Time (ms)",
           y = "Pupil size (z-score, relative change)") +
      geom_vline(xintercept = 0) +
      geom_hline(yintercept = 0) +
      geom_line() +
      geom_ribbon(aes(ymin = min_pupil_z, ymax = max_pupil_z, fill = outcome), 
             alpha = 0.25, color = NA) +
      scale_color_ptol() +
      scale_fill_ptol() +
      facet_grid(condition ~ age_cohort)
```

#### New Min-Max plot after first averagining within lab

```{r}
# create equivalent min-max plot as above to demonstrate the effect of first averaging within lab
ggplot(summarized_data_by_lab_and_dataset_id_mins, aes(x = t_norm_downsampled, y = avg_pupil_z, col = outcome, linetype = age_cohort)) +
      labs(x = "Time (ms)",
           y = "Pupil size (z-score, relative change)") +
      geom_vline(xintercept = 0) +
      geom_hline(yintercept = 0) +
      geom_line() +
      geom_ribbon(aes(ymin = min_pupil_z, ymax = max_pupil_z, fill = outcome), 
             alpha = 0.25, color = NA) +
      scale_color_ptol() +
      scale_fill_ptol() +
      facet_grid(condition ~ age_cohort)
```

#### Spaghetti plot to show effect for each multiverse dataset,no within lab averaging

```{r}
#spaghetti plot
ggplot(summarized_data_by_dataset_id,aes(t_norm_downsampled,y=mean_pupil_z))+
  geom_line(aes(group=multiverse_id_wcond,color=outcome),alpha=0.05)+
  facet_wrap(condition ~ age_cohort)+
  scale_color_ptol() +
  scale_fill_ptol()+
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  labs(x = "Time (ms)",
           y = "Pupil size (z-score, relative change)")

ggsave(filename = here(plot_output_path,"mv_timecourse_spaghetti.png"),width = 10, height = 6, dpi = 300)
```

```{r}
#"best" variant
#filter (node 1), filter (node 2), filter (node 3), baseline-correction 0.5s (node 4) and valid second test trial only (node 5)
best_multiverse_variant <- summarized_data_by_dataset_id |> 
  filter(multiverse_label == "plausible_within_filtered_0.5s_second test trial valid") 

ggplot(summarized_data_by_dataset_id,aes(t_norm_downsampled,y=mean_pupil_z))+
  geom_line(aes(group=multiverse_id_wcond,color=outcome),alpha=0.05)+
  geom_line(data=best_multiverse_variant,aes(x=t_norm_downsampled,y=mean_pupil_z,group=outcome,color=outcome),size=1.2)+
  geom_ribbon(data=best_multiverse_variant,aes(ymin = mean_pupil_z - se_pupil_z, ymax = mean_pupil_z + se_pupil_z,fill=outcome),
    alpha = .2
  )+
  facet_wrap(condition ~ age_cohort)+
  scale_color_ptol() +
  scale_fill_ptol()+
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  labs(x = "Time (ms)",
           y = "Pupil size (z-score, relative change)")

ggsave(filename = here(plot_output_path,"mv_timecourse_spaghetti_final_combination_overlay.png"),width = 10, height = 6, dpi = 300)
```

#### Spaghetti plot to show effect for each multiverse dataset, averaging within lab

```{r}
#spaghetti plot
ggplot(summarize_data_across_lab_by_multiverse_label,aes(t_norm_downsampled,y=mean_pupil_z))+
  geom_line(aes(group=multiverse_id_wcond,color=outcome),alpha=0.05)+
  facet_wrap(condition ~ age_cohort)+
  scale_color_ptol() +
  scale_fill_ptol()+
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  labs(x = "Time (ms)",
           y = "Pupil size (z-score, relative change)")
ggsave(filename = here(plot_output_path,"mv_timecourse_spaghetti_firstaveragewithinlab.png"),width = 10, height = 6, dpi = 300)
```

Create a spaghetti plot with the "best" variant overlayed

```{r}
#"best" variant
#filter (node 1), filter (node 2), filter (node 3), baseline-correction 0.5s (node 4) and valid second test trial only (node 5)
best_multiverse_variant_across_lab <- summarize_data_across_lab_by_multiverse_label |> 
  filter(multiverse_label == "plausible_within_filtered_0.5s_second test trial valid") 

ggplot(summarize_data_across_lab_by_multiverse_label,aes(t_norm_downsampled,y=mean_pupil_z))+
  geom_line(aes(group=multiverse_id_wcond,color=outcome),alpha=0.05)+
  geom_line(data=best_multiverse_variant_across_lab,aes(x=t_norm_downsampled,y=mean_pupil_z,group=outcome,color=outcome),size=1.2)+
  geom_ribbon(data=best_multiverse_variant_across_lab,aes(ymin = mean_pupil_z - se_pupil_z, ymax = mean_pupil_z + se_pupil_z,fill=outcome),
    alpha = .2
  )+
  facet_wrap(condition ~ age_cohort)+
  scale_color_ptol() +
  scale_fill_ptol()+
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  labs(x = "Time (ms)",
           y = "Pupil size (z-score, relative change)")

ggsave(filename = here(plot_output_path,"mv_timecourse_spaghetti_final_combination_overlay_firstaveragewithinlab.png"),width = 10, height = 6, dpi = 300)
```

```{r}
rm(data_for_plotting_df5)
gc()
```


# PART 4 MAKING SENSE OF THE MULTIVERSE (staistical modelling) - original

As a final step, we investigate (1) the averaged interaction effect Condition x Outcome, (2) the time-course of the interaction effect Condition x Outcome and (3) the non-linear interaction effect of Condition x Outcome considering the time-course of the effect. This approach provides an exploration of whether and how smoothing time enhances the plausibility of statistical modeling of pupil dilation across datasets.

## (1) The averaged interaction effect Condition x Outcome.
The first bit of code stores the results of 72 analyses (3 types of models fitted) into three containers: lm_results,lmer_results, and TIMElmer_results. The first two containers are need to address (1).

```{r modelling, echo=FALSE, include=TRUE, out.width='90%', message=FALSE}
# Assuming `data_df5$data` is a list of dataframes:
data_df5_list <- data_df5$data

# Run your model function on each dataframe in data_df5_list.
# Define the custom modeling function.

run_model_lm <- function(df) {
  if (is.data.frame(df) && n_distinct(df$condition_c) > 1 & 
      n_distinct(df$outcome_c) > 1 & n_distinct(df$age_cohort_c) > 1) {

    # Fit the model if conditions are met
    df.short <- df |>
      filter(t_norm >= 0 & t_norm < 5000) |>
      group_by(participant_lab_id, condition_c, outcome_c, age_cohort_c) |>
      summarize(Average = mean(average_z, na.rm=T)) |>
      ungroup()
    
    # Fit model.
    lm(Average ~ condition_c * outcome_c * age_cohort_c, data = df.short)
  } else {
    # Return NULL if conditions aren't met
    NULL
  }
}

run_model_lmer <- function(df) {
  if (is.data.frame(df) && n_distinct(df$condition_c) > 1 & 
      n_distinct(df$outcome_c) > 1 & n_distinct(df$age_cohort_c) > 1) {

    # Fit the model if conditions are met
    df.short <- df |>
      filter(t_norm >= 0 & t_norm < 5000) |>      
      group_by(participant_lab_id, condition_c, outcome_c, age_cohort_c, lab_id) |>
      summarize(Average = mean(average_z, na.rm=T)) |>
      ungroup()
    
    lmer(Average ~ condition_c * outcome_c * age_cohort_c + (1|lab_id), data = df.short)
  } else {
    # Return NULL if conditions aren't met
    NULL
  }
}

#MZ commenting out the time model evaluation because I do not think this model is appropriate
# run_model_TIMElmer <- function(df) {
#   if (is.data.frame(df) && n_distinct(df$condition_c) > 1 & 
#       n_distinct(df$outcome_c) > 1 & n_distinct(df$age_cohort_c) > 1) {
#     # Fit the model if conditions are met
#     
#     #! Reduce dataset to average across the 5 seconds, i.e., 1 value per participant per trial? 
#     df.short <- df |>
#       filter(t_norm > 0) |>
#       group_by(participant_lab_id, condition_c, t_norm, outcome_c, age_cohort_c, lab_id) |>
#       summarize(Average = mean(average_z, na.rm=T)) |>
#       ungroup()
#     
#     lmer(Average ~ t_norm*condition_c * outcome_c * age_cohort_c + (1|lab_id), data = df.short) #! Pending vote; include lab-id here. too! This is where we can include AL as fixed effect.
#   } else {
#     # Return NULL if conditions aren't met
#     NULL
#   }
# }



# Apply the model function across the list of dataframes in the list-column
results_lm <- map(data_df5_list, run_model_lm)
results_lmer <- map(data_df5_list, run_model_lmer)
#MZ commenting out the time model evaluation because I do not think this model is appropriate
#results_TIMElmer <- map(data_df5_list, run_model_TIMElmer)
# Filter out NULL values (dataframes that didn't meet the condition)
lm_results <- compact(results_lm)
lmer_results <- compact(results_lmer)
#MZ commenting out the time model evaluation because I do not think this model is appropriate
#TIMElmer_results <- compact(results_TIMElmer)
```


```{r model parameters, echo=TRUE, include=TRUE, out.width='90%', message=FALSE}
# Define the extraction function with improved error handling
extract_model_metrics <- function(model) {
  if (!is.null(model)) {
    # Calculate R-squared
    rsq <- summary(model)$adj.r.squared
    tval <- summary(model)$coefficients[,3] 
    # Get AIC and BIC
    aic <- AIC(model)
    bic <- BIC(model)
    
    # Extract coefficients and standard errors (using tidy output)
#<<<<<<< Updated upstream
   coef_df <- broom::tidy(model) %>%
  dplyr::filter(term == "condition_c:outcome_c:age_cohort_c") %>%  # Only the 3-way interaction
  dplyr::select(term, estimate, std.error, p.value)
#=======
    coef_df <- broom::tidy(model)
    coef_df <- coef_df %>%
      dplyr::filter(term %in% c("condition_c", "outcome_c", "age_cohort_c")) %>% 
      dplyr::select(term, estimate, std.error)
##>>>>>>> Stashed changes
    
    # If coefficients are missing, create empty placeholders
    if (nrow(coef_df) == 0) {
      coef_df <- tibble(term = NA, estimate = NA, std.error = NA, p.value = NA)
    }
    
    # Add the AIC, BIC, and R-squared as additional columns for consistency
    coef_df <- coef_df %>%
      mutate(AIC = aic, BIC = bic, R_squared = rsq)
    
    return(coef_df)
  } else {
    NULL
  }
}

LMER_model_metrics <- map(lmer_results, function(model) {
  broom.mixed::tidy(model)
})

extract_model_metrics_LMER <- function(model) {
  r2 <- performance::r2(model)  # Extract R^2 values
  data.frame(
    AIC = AIC(model),
    BIC = BIC(model),
    logLik = logLik(model),
    marginal_R2 = r2$R2_marginal,   # Marginal R^2
    conditional_R2 = r2$R2_conditional,  # Conditional R^2
    fixed_effects = paste(names(fixef(model)), round(fixef(model), 3), collapse = ", ")
  )
}

#MZ commenting out the time model evaluation because I do not think this model is appropriate
# timeLMER_model_metrics <- map(TIMElmer_results, function(model) {
#   broom.mixed::tidy(model)
# })

#MZ commenting out the time model evaluation because I do not think this model is appropriate
# extract_model_metrics_timeLMER <- function(model) {
#   r2 <- performance::r2(model)  # Extract R^2 values
#   data.frame(
#     AIC = AIC(model),
#     BIC = BIC(model),
#     logLik = logLik(model),
#     marginal_R2 = r2$R2_marginal,   # Marginal R^2
#     conditional_R2 = r2$R2_conditional,  # Conditional R^2
#     fixed_effects = paste(names(fixef(model)), round(fixef(model), 3), collapse = ", ")
#   )
# }

# Apply the extraction function across all models and filter out NULL results
LM_model_metrics <- map(lm_results, extract_model_metrics)
LM_model_metrics <- compact(LM_model_metrics)  # Remove any NULL elements

LMER_model_metrics <- map(lmer_results, extract_model_metrics_LMER)
LMER_model_metrics <-compact(LMER_model_metrics) # Remove any NULL elements

#MZ commenting out the time model evaluation because I do not think this model is appropriate
#timeLMER_model_metrics <- map(TIMElmer_results, extract_model_metrics_timeLMER)
#timeLMER_model_metrics <- compact(LMER_model_metrics)  # Remove any 

# Convert to a tidy dataframe
LMmodel_metrics_df <- bind_rows(LM_model_metrics, .id = "model_id")
LMERmodel_metrics_df <- bind_rows(LMER_model_metrics, .id = "model_id")
#MZ commenting out the time model evaluation because I do not think this model is appropriate
#timeLMERmodel_metrics_df <- bind_rows(timeLMER_model_metrics, .id = "model_id")

# Check the structure of model_metrics_df to confirm columns are present
str(LMmodel_metrics_df)
str(LMERmodel_metrics_df)
#MZ removing the time model evaluation because I do not think this model is appropriate
#str(timeLMERmodel_metrics_df)

# Plot the specification curve (preparatory step):

# Add a model order for plotting
LMmodel_metrics_df <- LMmodel_metrics_df %>%
  group_by(term) %>%
  mutate(model_order = row_number()) %>%
  ungroup() #|>
  #filter()
#
LMERmodel_metrics_df <- LMERmodel_metrics_df %>%
  group_by(fixed_effects) %>%
  mutate(model_order = row_number()) %>%
  ungroup()
#
#MZ removing the time model evaluation because I do not think this model is appropriate
# timeLMERmodel_metrics_df <- timeLMERmodel_metrics_df %>%
#   group_by(fixed_effects) %>%
#   mutate(model_order = row_number()) %>%
#   ungroup()
```

## Distribution of key statistics
Building a table to help look at the distribution of key statistics to address the following question: Would we have reached different conclusions given the dataset (as part of the multiverse)?

```{r table key parameters, echo=TRUE, include=TRUE, out.width='90%', message=FALSE}

# Start building the dataframe with key information already gathered in previous steps"
# The goal is to have all the information at hand to address the preregistered analyses (https://osf.io/wt79h).

# Merge info from LMER:
dataStats.temp <- data_df5 |>
  dplyr::select(-"data")

dataStatsLMER.df <- LMERmodel_metrics_df |>
  dplyr::select(-c("fixed_effects", "model_order")) |>
  rename(LMER.AIC = AIC, LMER.BIC = BIC, LMER.logLik = logLik, LMER.margR2 = marginal_R2, LMER.condR2 = conditional_R2)

dataStats.df <- bind_cols(dataStats.temp, dataStatsLMER.df) |>
  relocate(model_id)

rm("dataStats.temp", "dataStatsLMER.df")

# Merge info from LM:
dataStats.LM <- LMmodel_metrics_df |>
  dplyr::filter(term == "condition_c") |>
  dplyr::select(-c("term", "model_order", "model_id")) |>
  rename(LM.CondEstimate = estimate, LM.CondSE = std.error, LM.AIC = AIC, LM.BIC = BIC, LM.R2 = R_squared)

dataStats.df <- bind_cols(dataStats.df, dataStats.LM)

rm("dataStats.LM")

# Get descriptives.
get_descriptives <- function(df) {

   df.short <- df |>
      dplyr::filter(t_norm > 0 & t_norm < 5000 & !is.na(average_z)) |>
      group_by(participant_lab_id, condition_c, outcome_c, age_cohort_c, condition, outcome, age_cohort, prop_exit) |>
      summarize(AveragePD = mean(average_z, na.rm=T), SDPD = sd(average_z, na.rm=T), N = n()) |>
      ungroup()
  return(df.short)

  }

# Get more statistics for the df:
run_model_anova <- function(df) {
  
  if (is.data.frame(df) && n_distinct(df$condition_c) > 1 & 
      n_distinct(df$outcome_c) > 1 & n_distinct(df$age_cohort_c) > 1) {
      
    df.short <- df |>
      dplyr::filter(t_norm > 0 & t_norm < 5000) |>
      group_by(participant_lab_id, condition_c, outcome_c, age_cohort_c, condition, outcome, age_cohort) |>
      summarize(Average = mean(average_z, na.rm=T)) |>
      ungroup()
    
    # Hypothesis 1.
    # Fit model.
    df.modelFull <- lm(Average ~ condition_c * outcome_c * age_cohort_c, data = df.short)
    df.modelFull.sum <- summary(df.modelFull)
    
    # Add to df.
    df.return <- tibble(F.FullNull = df.modelFull.sum$fstatistic[1])
    
    # Get beta-coef for outcome given condition == knowledge and age_cohort == toddlers.
    df.short$condition <- as.factor(df.short$condition)
    df.short$condition <- relevel(df.short$condition, ref = "knowledge")
    df.short$age_cohort <- as.factor(df.short$age_cohort)
    df.short$age_cohort <- relevel(df.short$age_cohort, ref = "toddlers")
    
    df.modelFull2 <- lm(Average ~ condition * outcome * age_cohort, data = df.short)
    df.modelFull2 <- broom::tidy(df.modelFull2) |>
      dplyr::filter(term=="outcomeincongruent") |>
      dplyr::select(-c("statistic", "p.value"))
    
    df.return <- df.return |>
      mutate(Beta.FullCondition = as.numeric(df.modelFull2[2]), BetaSD.FullCondition = as.numeric(df.modelFull2[3]))
  
    ### 3-way interaction
    df.modelRedBy3Way <- lm(Average ~ (condition_c+outcome_c+age_cohort_c)^2, data = df.short)
    df.modelFullRed3Way <- anova(df.modelRedBy3Way, df.modelFull)
    
    Fvalue <- df.modelFullRed3Way$F[2]
    R2 <- summary(df.modelFull)$r.squared - summary(df.modelRedBy3Way)$r.squared
    
    df.return <- df.return |>
    mutate(F.FullRedBy3Way = Fvalue, R2.FullRedBy3Way = R2)
    rm("Fvalue", "R2")
    
    
    # Hypothesis 1.1 &  Hypothesis 1.2
    df.short <- df |>
     dplyr::filter(t_norm > 0) |>
      group_by(participant_lab_id, condition_c, outcome_c, age_cohort_c) |>
      summarize(Average = mean(average_z, na.rm=T)) |>
      ungroup()
    #
    df.modelFull <- lm(Average ~ condition_c * outcome_c * age_cohort_c, data = df.short)
    # reduced model removes ONLY the simple fixed effect of outcome
    df.modelRedByOutcome <- lm(Average ~ condition_c + age_cohort_c + condition_c:age_cohort_c + outcome_c:age_cohort_c + condition_c:outcome_c + condition_c:outcome_c:age_cohort_c, data = df.short)
    df.modelFullRedOutcome <- anova(df.modelRedByOutcome, df.modelFull)
    
    Fvalue <- df.modelFullRedOutcome$F[2]
    R2 <- summary(df.modelFull)$r.squared - summary(df.modelRedByOutcome)$r.squared
    
    df.return <- df.return |>
    mutate(F.FullRedByOutcome = Fvalue, R2.FullRedByOutcome = R2)
    rm("Fvalue", "R2")
    
    # Hypothesis 1.3 &  Hypothesis 1.4
    # reduced model removes ONLY the simple fixed effect of condition
    df.modelRedByCondition <- lm(Average ~ outcome_c + age_cohort_c + condition_c:age_cohort_c + outcome_c:age_cohort_c + condition_c:outcome_c + condition_c:outcome_c:age_cohort_c, data = df.short)
    df.modelFullRedCondition <- anova(df.modelRedByCondition, df.modelFull)
    
    Fvalue <- df.modelFullRedCondition$F[2]
    R2 <- summary(df.modelFull)$r.squared - summary(df.modelRedByCondition)$r.squared
    
    df.return <- df.return |>
    mutate(F.FullRedByCondition = Fvalue, R2.FullRedByCondition = R2)
    rm("Fvalue", "R2")
    
    return(df.return)
  } else {
    # Return NULL if conditions aren't met
    NULL
  }
}

dataStats.df.additional <- map(data_df5_list, run_model_anova)
dataStats.df.additional <- bind_rows(dataStats.df.additional, .id = "model_id")
dataStats.final <- inner_join(dataStats.df, dataStats.df.additional, by = "model_id")

# Create plot to visualize multiple density curves.
dataStats.final.LF <- pivot_longer(dataStats.final, cols = c("F.FullNull", "F.FullRedBy3Way", "F.FullRedByOutcome", "F.FullRedByCondition"), names_to = "FType", values_to = "FValue")

ggplot(dataStats.final.LF, aes(x = FValue, fill = FType)) +
  geom_density(size = 0.75, alpha = 0.4) +
  #geom_vline(aes(xintercept = 2.38),
  #           linetype = "dashed", size = 1) +
  scale_color_ptol() +
  scale_color_ptol() +
  theme_minimal() +
  labs(
    title = "Density Plot (Lines)",
    x = "F-Value",
    color = "FType"
  )+
  ggtitle("Main model: PD ~ Age*Outcome*Condition")
##

ggplot(dataStats.final, aes(x = LM.R2, fill = LM.R2)) +
  geom_density(size = 0.75, alpha = 0.4) +
  scale_color_ptol() +
  scale_color_ptol() +
  theme_minimal() +
  labs(
    title = "Density Plot (Lines)",
    x = "R-Squared",
    color = "R-Squared"
  )+
  ggtitle("Main model: PD ~ Age*Outcome*Condition")+
  scale_x_continuous(limits = c(0,0.25))


##

# Here look at descriptives to plot anticipatory looking and pupil dilation changes:
df.DesStats.additional <- map(data_df5_list, get_descriptives)
df.DesStats.final <- bind_rows(df.DesStats.additional, .id = "model_id")
ggplot(df.DesStats.additional[[12]], aes(x = prop_exit, y = AveragePD, col = outcome)) +
      labs(x = "F-Value",
           y = "Density") +
      geom_vline(xintercept = 0.5) +
      geom_hline(yintercept = 0) +
      geom_point(alpha=0.45) +
      scale_color_ptol() +
      scale_fill_ptol() +
      geom_smooth(method="lm") +
      facet_grid(condition ~ age_cohort) +
      ggtitle("Example from one dataframe of the multiverse")


##


```

## Specification curves for multiverse model parameters
 The following offers various plots for the specification curves of the multiverse model parameters.
```{r model parameters plot, echo=TRUE, include=TRUE, out.width='90%'}
# Create the plot
# BIC LM
ggplot(LMmodel_metrics_df, aes(x = model_order, y = BIC, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = BIC - std.error, ymax = BIC + std.error), 
            #    width = 0.2) +                  # Error bars
  #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for BIC",
       x = "Model Order",
       y = "BIC") +
      # color = "Predictor") +
  theme_minimal()
#BIC LMER
ggplot(LMERmodel_metrics_df, aes(x = model_order, y = BIC, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = BIC - std.error, ymax = BIC + std.error), 
            #    width = 0.2) +                  # Error bars
  #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for BIC",
       x = "Model Order",
       y = "BIC") +
      # color = "Predictor") +
  theme_minimal() 

#MZ removing the time model evaluation because I do not think this model is appropriate
#BIC LMER time
# ggplot(timeLMERmodel_metrics_df, aes(x = model_order, y = BIC, color = model_id)) +
#   geom_point() +                                # Points for estimates
#  # geom_errorbar(aes(ymin = BIC - std.error, ymax = BIC + std.error), 
#             #    width = 0.2) +                  # Error bars
#   #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
#   labs(title = "Specification Curve for BIC",
#        x = "Model Order",
#        y = "BIC") +
#       # color = "Predictor") +
#   theme_minimal() 


#AIC LM
ggplot(LMmodel_metrics_df, aes(x = model_order, y = AIC, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = AIC - std.error, ymax = AIC + std.error), 
            #    width = 0.2) +                  # Error bars
  #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for AIC",
       x = "Model Order",
       y = "AIC") +
      # color = "Predictor") +
  theme_minimal() 

#AIC LMER
ggplot(LMERmodel_metrics_df, aes(x = model_order, y = AIC, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = AIC - std.error, ymax = AIC + std.error), 
            #    width = 0.2) +                  # Error bars
  #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for AIC",
       x = "Model Order",
       y = "AIC") +
      # color = "Predictor") +
  theme_minimal()

#AIC LMER time
ggplot(LMERmodel_metrics_df, aes(x = model_order, y = AIC, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = AIC - std.error, ymax = AIC + std.error), 
            #    width = 0.2) +                  # Error bars
  #facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for AIC",
       x = "Model Order",
       y = "AIC") +
      # color = "Predictor") +
  theme_minimal()


#R2 LM
ggplot(LMmodel_metrics_df, aes(x = model_order, y = R_squared, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = R_squared - std.error, ymax = R_squared + std.error), 
            #    width = 0.2) +                  # Error bars
  facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for R_squared",
       x = "Model Order",
       y = "R_squared") +
      # color = "Predictor") +
  theme_minimal() 

#R2 CONDITIONAL LMER
ggplot(LMERmodel_metrics_df, aes(x = model_order, y = conditional_R2, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = R_squared - std.error, ymax = R_squared + std.error), 
            #    width = 0.2) +                  # Error bars
#  facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for R_squared",
       x = "Model Order",
       y = "R_squared") +
      # color = "Predictor") +
  theme_minimal()

#R2 CONDITIONAL LMER time
ggplot(LMERmodel_metrics_df, aes(x = model_order, y = conditional_R2, color = model_id)) +
  geom_point() +                                # Points for estimates
 # geom_errorbar(aes(ymin = R_squared - std.error, ymax = R_squared + std.error), 
            #    width = 0.2) +                  # Error bars
#  facet_wrap(~ term, scales = "free_y") +       # Separate panels for each predictor
  labs(title = "Specification Curve for R_squared",
       x = "Model Order",
       y = "R_squared") +
      # color = "Predictor") +
  theme_minimal()
```

# PART 5 - Updated Multiverse LMER Modeling Approach

# Part 5A LMER models

## Source helper functions and additional libraries

```{r}
library(lmerTest)
library(buildmer)
library(broom.mixed)
library(marginaleffects)
source(here("MB2P","MB2P-Preregistration","scripts","modelpruning.R"))

#function for fitting lmer model
run_model_lmer_re_pruning <- function(df,groups_to_include = c("adults","toddlers")) {
  if (length(groups_to_include)>1) {
    print("Fitting model across groups")
    min_age_cohort_num = 2
    lmer_model_type = "main"
  } else {
    print("Fitting group-specific models")
    min_age_cohort_num = 1
    lmer_model_type = "group"
  }
  if (is.data.frame(df) && n_distinct(df$condition_c) > 1 & 
      n_distinct(df$outcome_c) > 1 & n_distinct(df$age_cohort_c) >= min_age_cohort_num) {

    # Process data
    df.short <- df |>
      filter(t_norm >= 0 & t_norm < 5000) |>
      #filter data to group to include
      filter(age_cohort %in% groups_to_include) |> 
      group_by(participant_lab_id, condition_c, outcome_c, age_cohort,age_cohort_c, lab_id) |>
      summarize(Average = mean(average_z, na.rm=T)) |>
      ungroup() |> 
      mutate(
        age_cohort_adults = ifelse(age_cohort=="adults",0,1),
        age_cohort_toddlers =  ifelse(age_cohort=="toddlers",0,1)
        )
    
    #Fit the model if conditions are met
    prune_main_lmer_model(df.short,model_type=lmer_model_type)
  } else {
    # Return NULL if conditions aren't met
    NULL
  }
}

#helper function for extracting the random effects structure specifically
extract_outer_parentheses <- function(text) {
  start <- regexpr("\\(", text)
  if (start == -1) return(NA)
  
  depth <- 0
  for (i in seq(start, nchar(text))) {
    char <- substr(text, i, i)
    if (char == "(") depth <- depth + 1
    if (char == ")") depth <- depth - 1
    if (depth == 0) return(substr(text, start + 1, i - 1))
  }
  return(NA)
}

#extract lmer model results in a tidy fashion
extract_lmer_model_results_tidy <- function(model) {
  # Get tidy summary of fixed effects
  coefs <- broom.mixed::tidy(model, effects = "fixed") %>%
    select(term, estimate, std.error, df, statistic, p.value)

  # Extract model formula
  model_formula <- deparse(formula(model)) |> paste(collapse = "")
  #fixed_formula <- format(rlang::f_rhs(model_formula))  # remove LHS
  #random_formula <- format(findbars(model_formula))     # extract random part

  # Extract singular fit status
  singular <- isSingular(model)

  # Add model info to each row
  coefs <- coefs %>%
    mutate(
      model_formula = model_formula,
      #random_effects = deparse(random_formula),
      is_singular = singular
    ) %>%
    relocate(model_formula, is_singular) %>%
  mutate(random_effects = sapply(model_formula, extract_outer_parentheses))
  
  #compute 95% CIs
  ci_df <- as.data.frame(confint(model, level = 0.95, method = "Wald"))
  ci_df$term <- rownames(ci_df)
  ci_df <- ci_df %>% 
    filter(!is.na(`2.5 %`))
  rownames(ci_df) <- NULL
  ci_df <- ci_df %>% 
    filter(term %in% coefs$term) %>%
    rename(conf.low = `2.5 %`, conf.high = `97.5 %`)
  
  #get number of observations
  n_obs <- nobs(model)
  
  #get number of lab random effect levels
  n_labs <- ngrps(model)[["lab_id"]]
  
  coefs <- coefs %>%
    left_join(ci_df, by="term") %>%
    mutate(n_obs = n_obs,
           n_labs = n_labs)
    
}
```

## Fit models and extract results

```{r, warning=F, message=F}
#fit the lmer models with random effects pruning
models_lmer_re_pruning <- data_df5 %>%
  mutate(
    models = map(data,run_model_lmer_re_pruning)) %>%
  select(-data) 

#add results
models_lmer_re_pruning_w_results <- models_lmer_re_pruning %>%
  mutate(
    results=map(models,extract_lmer_model_results_tidy)
  )

#extract results into data frame
results_lmer_re_pruning <- models_lmer_re_pruning_w_results %>%
  select(-models) %>%
  unnest(results) 

## old strategy focused on data list
#models_lmer_re_pruning <- map(data_df5_list, extract_lmer_model_results_tidy)
#results_lmer_re_pruning <- map(models_lmer_re_pruning, extract_lmer_model_results_tidy)
# results_lmer_re_pruning_df <- results_lmer_re_pruning %>%
#   #combine list elements into one dataframe
#   bind_rows(.id = "model_id")
```

```{r}
#save the output
save(models_lmer_re_pruning_w_results, file = here(model_output_path, "pupillometry_models_lmer_re_pruning_w_results.Rds"))
save(results_lmer_re_pruning, file = here(model_output_path, "pupillometry_results_lmer_re_pruning.Rds"))
```

## Plots

### How does filtering affect number of observations?

```{r}
lmer_multiverse_combos_obs <- results_lmer_re_pruning %>%
  distinct(df1_extreme_values,df2_screen_fixation,df3_moving_average,df4_baseline_correction,df5_ppt_exclusion,n_obs,n_labs)

ggplot(lmer_multiverse_combos_obs,aes(x=df5_ppt_exclusion,y=n_obs))+
  geom_point()+
  geom_line(aes(group=1))+
  facet_grid(df3_moving_average+df4_baseline_correction ~ df1_extreme_values+df2_screen_fixation)+
  ylab("Number of observations in LMER model")+
  scale_x_discrete(limits = c("no exclusion","second test trial valid","both test trials valid"))+
  theme(axis.text.x = element_text(angle = 90, vjust=.5, hjust = 1))

ggplot(lmer_multiverse_combos_obs,aes(x=df5_ppt_exclusion,y=n_labs))+
  geom_point()+
  geom_line(aes(group=1))+
  facet_grid(df3_moving_average+df4_baseline_correction ~ df1_extreme_values+df2_screen_fixation)+
  ylab("Number of labs in LMER model")+
  scale_x_discrete(limits = c("no exclusion","second test trial valid","both test trials valid"))+
  theme(axis.text.x = element_text(angle = 90, vjust=.5, hjust = 1))

```

### Three-way-interaction

```{r}
lmer_threewayinteraction_multiverse_results <-results_lmer_re_pruning %>%
  filter(term=="condition_c:outcome_c:age_cohort_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lmer_threewayinteraction_multiverse_results,aes(x=df4_baseline_correction,y=estimate))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("Lmer Model Estimate for 3-way interaction (Condition x Outcome x Age Cohort)")

ggsave(filename = here(plot_output_path,"mv_effect_plot_lmer_pruned_threewayinteraction.png"),width = 9, height = 6, dpi = 300)
```

### Outcome by Condition Interaction

```{r}
lmer_conditionXoutcome_multiverse_results <-results_lmer_re_pruning %>%
  filter(term=="condition_c:outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )

ggplot(lmer_conditionXoutcome_multiverse_results,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("Lmer Model Estimate for 2-way interaction Condition x Outcome")

ggsave(filename = here(plot_output_path,"mv_effect_plot_lmer_pruned_conditionXoutcome.png"),width = 10, height = 6, dpi = 300)
```

## Models for each age cohort

### Toddlers

### Fit models and extract results

```{r}
#fit the lmer models with random effects pruning
models_lmer_re_pruning_toddlers <- data_df5 %>%
  mutate(
    models = map2(data,c("toddlers"), run_model_lmer_re_pruning)) %>%
  select(-data) 

#add results
models_lmer_re_pruning_w_results_toddlers <- models_lmer_re_pruning_toddlers %>%
  mutate(
    results=map(models,extract_lmer_model_results_tidy)
  )

#extract results into data frame
results_lmer_re_pruning_toddlers <- models_lmer_re_pruning_w_results_toddlers %>%
  select(-models) %>%
  unnest(results) 
```

```{r}
#save the output
save(models_lmer_re_pruning_w_results_toddlers, file = here(model_output_path, "pupillometry_models_lmer_re_pruning_w_results_toddlers.Rds"))
save(results_lmer_re_pruning_toddlers, file = here(model_output_path, "pupillometry_results_lmer_re_pruning_toddlers.Rds"))
```

#### Plot Outcome by Condition Interaction

```{r}
lmer_conditionXoutcome_multiverse_results_toddlers <-results_lmer_re_pruning_toddlers %>%
  filter(term=="condition_c:outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lmer_conditionXoutcome_multiverse_results_toddlers,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("TODDLERS\nLmer Model Estimate for 2-way interaction Condition x Outcome")

ggsave(filename = here(plot_output_path,"mv_effect_plot_lmer_pruned_conditionXoutcome_toddlers.png"),width = 10, height = 6, dpi = 300)
```

#### Plot Outcome Effect

```{r}
lmer_outcome_multiverse_results_toddlers <-results_lmer_re_pruning_toddlers %>%
  filter(term=="outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lmer_outcome_multiverse_results_toddlers,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("TODDLERS\nLmer Model Estimate for Effect of Outcome")
```

#### Plot Condition Effect

```{r}
lmer_condition_multiverse_results_toddlers <-results_lmer_re_pruning_toddlers %>%
  filter(term=="condition_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lmer_condition_multiverse_results_toddlers,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("TODDLERS\nLmer Model Estimate for Effect of Condition")
```

### Adults

### Fit models and extract results

```{r, warning=F, message=F}
#fit the lmer models with random effects pruning
models_lmer_re_pruning_adults <- data_df5 %>%
  mutate(
    models = map2(data,c("adults"), run_model_lmer_re_pruning)) %>%
  select(-data) 

#add results
models_lmer_re_pruning_w_results_adults <- models_lmer_re_pruning_adults %>%
  mutate(
    results=map(models,extract_lmer_model_results_tidy)
  )

#extract results into data frame
results_lmer_re_pruning_adults <- models_lmer_re_pruning_w_results_adults %>%
  select(-models) %>%
  unnest(results) 
```

```{r}
#save the output
save(models_lmer_re_pruning_w_results_adults, file = here(model_output_path, "pupillometry_models_lmer_re_pruning_w_results_adults.Rds"))
save(results_lmer_re_pruning_adults, file = here(model_output_path, "pupillometry_results_lmer_re_pruning_adults.Rds"))
```

#### Plot Outcome by Condition Interaction

```{r}
lmer_conditionXoutcome_multiverse_results_adults <-results_lmer_re_pruning_adults %>%
  filter(term=="condition_c:outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lmer_conditionXoutcome_multiverse_results_adults,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("ADULTS\nLmer Model Estimate for 2-way interaction Condition x Outcome")

ggsave(filename = here(plot_output_path,"mv_effect_plot_lmer_pruned_conditionXoutcome_adults.png"),width = 10, height = 6, dpi = 300)
```

#### Plot Outcome Effect

```{r}
lmer_outcome_multiverse_results_adults <-results_lmer_re_pruning_adults %>%
  filter(term=="outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lmer_outcome_multiverse_results_adults,aes(x=df4_baseline_correction,y=estimate))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("ADULTS\nLmer Model Estimate for Effect of Outcome")
```

#### Plot Condition Effect

```{r}
lmer_condition_multiverse_results_adults <-results_lmer_re_pruning_adults %>%
  filter(term=="condition_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lmer_condition_multiverse_results_adults,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("ADULTS\nLmer Model Estimate for Effect of Condition")
```

# Part 5B LM models

## Helper functions

```{r}
#function for fitting lmer model
fit_lm_main <- function(df,groups_to_include = c("adults","toddlers")) {
  if (length(groups_to_include)>1) {
    print("Fitting model across groups")
    min_age_cohort_num = 2
    lmer_model_type = "main"
  } else {
    print("Fitting group-specific models")
    min_age_cohort_num = 1
    lmer_model_type = "group"
  }
  if (is.data.frame(df) && n_distinct(df$condition_c) > 1 & 
      n_distinct(df$outcome_c) > 1 & n_distinct(df$age_cohort_c) >= min_age_cohort_num) {

    # Process data
    df.short <- df |>
      filter(t_norm >= 0 & t_norm < 5000) |>
      #filter data to group to include
      filter(age_cohort %in% groups_to_include) |> 
      group_by(participant_lab_id, condition_c, outcome_c, age_cohort,age_cohort_c, lab_id) |>
      summarize(Average = mean(average_z, na.rm=T)) |>
      ungroup() |> 
      mutate(
        age_cohort_adults = ifelse(age_cohort=="adults",0,1),
        age_cohort_toddlers =  ifelse(age_cohort=="toddlers",0,1)
        )
    
    #Fit the model if conditions are met
    m <- lm(Average ~ condition_c * outcome_c * age_cohort_c, data = df.short)
    m
  } else {
    # Return NULL if conditions aren't met
    NULL
  }
}


#extract lm model results in a tidy fashion
extract_lm_model_results_tidy <- function(model) {
  # Get tidy summary of fixed effects
  coefs <- broom::tidy(model) %>%
    select(term, estimate, std.error, statistic, p.value)

  #compute 95% CIs
  ci_df <- as.data.frame(confint(model, level = 0.95, method = "Wald"))
  ci_df$term <- rownames(ci_df)
  ci_df <- ci_df %>% 
    filter(!is.na(`2.5 %`))
  rownames(ci_df) <- NULL
  ci_df <- ci_df %>% 
    filter(term %in% coefs$term) %>%
    rename(conf.low = `2.5 %`, conf.high = `97.5 %`)
  
  #get number of observations
  n_obs <- nobs(model)
  
  coefs <- coefs %>%
    left_join(ci_df, by="term") %>%
    mutate(n_obs = n_obs)
}
```

## Fit models and extract results

```{r, warning=F, message=F}
#fit the lmer models with random effects pruning
models_lm <- data_df5 %>%
  mutate(
    models = map(data,fit_lm_main)) %>%
  select(-data) 

#add results
models_lm_w_results <- models_lm  %>%
  mutate(
    results=map(models,extract_lm_model_results_tidy)
  )

#extract results into data frame
results_lm_main <- models_lm_w_results %>%
  select(-models) %>%
  unnest(results) 
```

```{r}
#save the output
save(models_lm_w_results, file = here(model_output_path, "pupillometry_models_lm_w_results.Rds"))
save(results_lm_main, file = here(model_output_path, "pupillometry_results_lm_main.Rds"))
```

## Plots

### Three-way-interaction

```{r}
lm_threewayinteraction_multiverse_results <-results_lm_main %>%
  filter(term=="condition_c:outcome_c:age_cohort_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lm_threewayinteraction_multiverse_results,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("Lm Model Estimate for 3-way interaction (Condition x Outcome x Age Cohort)")

ggsave(filename = here(plot_output_path,"mv_effect_plot_lm_threewayinteraction.png"),width = 10, height = 6, dpi = 300)
```

### Outcome by Condition Interaction

```{r}
lm_conditionXoutcome_multiverse_results <-results_lm_main %>%
  filter(term=="condition_c:outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lm_conditionXoutcome_multiverse_results,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("Lm Model Estimate for 2-way interaction Condition x Outcome")

ggsave(filename = here(plot_output_path,"mv_effect_plot_lm_conditionXoutcome.png"),width = 10, height = 6, dpi = 300)
```

### Toddlers

### Fit models and extract results

```{r, warning=F, message=F}
#fit the lmer models with random effects pruning
models_lm_toddlers <- data_df5 %>%
  mutate(
    models = map2(data,c("toddlers"), fit_lm_main)) %>%
  select(-data) 

#add results
models_lm_w_results_toddlers <- models_lm_toddlers %>%
  mutate(
    results=map(models,extract_lm_model_results_tidy)
  )

#extract results into data frame
results_lm_main_toddlers <- models_lm_w_results_toddlers %>%
  select(-models) %>%
  unnest(results) 
```

```{r}
#save the output
save(models_lm_w_results_toddlers, file = here(model_output_path, "pupillometry_models_lm_w_results_toddlers.Rds"))
save(results_lm_main_toddlers, file = here(model_output_path, "pupillometry_results_lm_main_toddlers.Rds"))
```

#### Plot Outcome by Condition Interaction

```{r}
lm_conditionXoutcome_multiverse_results_toddlers <-results_lm_main_toddlers %>%
  filter(term=="condition_c:outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lm_conditionXoutcome_multiverse_results_toddlers,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("TODDLERS\nLm Model Estimate for 2-way interaction Condition x Outcome")

ggsave(filename = here(plot_output_path,"mv_effect_plot_lm_conditionXoutcome_toddlers.png"),width = 10, height = 6, dpi = 300)
```

#### Plot Outcome Effect

```{r}
lm_outcome_multiverse_results_toddlers <-results_lm_main_toddlers %>%
  filter(term=="outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lm_outcome_multiverse_results_toddlers,aes(x=df4_baseline_correction,y=estimate))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("TODDLERS\nLm Model Estimate for Effect of Outcome")
```

#### Plot Condition Effect

```{r}
lm_condition_multiverse_results_toddlers <-results_lm_main_toddlers %>%
  filter(term=="condition_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lm_condition_multiverse_results_toddlers,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("TODDLERS\nLm Model Estimate for Effect of Condition")
```

### Adults

### Fit models and extract results

```{r, warning=F, message=F}
#fit the lmer models with random effects pruning
models_lm_adults <- data_df5 %>%
  mutate(
    models = map2(data,c("adults"), fit_lm_main)) %>%
  select(-data) 

#add results
models_lm_w_results_adults <- models_lm_adults %>%
  mutate(
    results=map(models,extract_lm_model_results_tidy)
  )

#extract results into data frame
results_lm_main_adults <- models_lm_w_results_adults %>%
  select(-models) %>%
  unnest(results) 
```

```{r}
#save the output
save(models_lm_w_results_adults, file = here(model_output_path, "pupillometry_models_lm_w_results_adults.Rds"))
save(results_lm_main_adults, file = here(model_output_path, "pupillometry_results_lm_main_adults.Rds"))
```

#### Plot Outcome by Condition Interaction

```{r}
lm_conditionXoutcome_multiverse_results_adults <-results_lm_main_adults %>%
  filter(term=="condition_c:outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lm_conditionXoutcome_multiverse_results_adults,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("ADULTS\nLm Model Estimate for 2-way interaction Condition x Outcome")

ggsave(filename = here(plot_output_path,"mv_effect_plot_lm_conditionXoutcome_adults.png"),width = 10, height = 6, dpi = 300)
```

#### Plot Outcome Effect

```{r}
lm_outcome_multiverse_results_adults <-results_lm_main_adults %>%
  filter(term=="outcome_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lm_outcome_multiverse_results_adults,aes(x=df4_baseline_correction,y=estimate))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("ADULTS\nLm Model Estimate for Effect of Outcome")
```

#### Plot Condition Effect

```{r}
lm_condition_multiverse_results_adults <-results_lm_main_adults %>%
  filter(term=="condition_c") %>%
  mutate(
    significant = ifelse(p.value<0.05,"significant","non-significant")
  )
ggplot(lm_condition_multiverse_results_adults,aes(x=df4_baseline_correction,y=estimate,alpha=significant))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=conf.low,ymax=conf.high),width=0)+
  geom_point(size=2)+
  facet_grid(df1_extreme_values+df2_screen_fixation ~ df3_moving_average+df5_ppt_exclusion)+
  xlab("Baseline Correction Window")+
  ylab("ADULTS\nLm Model Estimate for Effect of Condition")
```